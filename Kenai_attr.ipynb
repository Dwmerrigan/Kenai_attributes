{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RCA fish species and Temperature site attributes\n",
    " * Add HUC 12 and elevation data to temperature sites\n",
    " * Add AWC species and Northern pike data to RCA\n",
    "  * all life stages/categories\n",
    " * Elevation stats for all RCAs\n",
    "   * Mean min max\n",
    "   * Mean elevation of contributing area\n",
    " * Percent Glacier cover calculation along flow acc network\n",
    " * \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules and set environments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06022020\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\n"
     ]
    }
   ],
   "source": [
    "import arcpy, os, zipfile, requests, datetime, sys, time, traceback\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "today = datetime.now()\n",
    "#Make the time stamp.  \n",
    "time_stamp = '{:%d%m%Y}'.format(today)\n",
    "print(time_stamp)\n",
    "path = os.getcwd() # temporary working directories and geodatabases will be created here\n",
    "print (path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables\n",
    " * All input data are stored on the T: so no local data are needed\n",
    "  * Temporary working directors are created in the current working directory listed above\n",
    "    * Set path = \"desired working folder\" if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables set on 2020-02-06 15:07:47.218434\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "### Variable Names/identifiers ###\n",
    "\n",
    "region = \"Anchor\" #region of interest - used to name temporary directories\n",
    "outgdbname = region + \".gdb\" #Name of output gdb\n",
    "outdirname = region + \"_Attributes_\" #Location to save outputs\n",
    "identifierfield = \"reachid\" #Name of field storing Catchment/RCA field in input stream layer ex. NHDPlus = \"NHDPLusID\", rca streams = \"reachid\"\n",
    "\n",
    "### Network Data ###\n",
    "\n",
    "instudy =  r\"T:\\\\Aquatic\\\\KFHP\\\\Landscape_Metrics_DM\\\\Anchor\\\\Source_Data\\\\Anchor_Source.gdb\\\\anch_studyarea\" #Polygon defining study area, used to extract nlcd raster\n",
    "instreams = r\"T:\\\\Aquatic\\\\KFHP\\\\Landscape_Metrics_DM\\\\Anchor\\\\Source_Data\\\\Anchor_Source.gdb\\\\anch_rca_reaches\" #Streams with RCA code\n",
    "inrca =  r\"T:\\\\Aquatic\\\\KFHP\\\\Landscape_Metrics_DM\\\\Anchor\\\\Source_Data\\\\Anchor_Source.gdb\\\\anchor_rcas\" #RCAs for region of interest\n",
    "awc_events = \"T:\\\\Aquatic\\\\KFHP\\\\AWC\\\\2018\\\\2018GDB_statewide.gdb\\\\awcEventArcs\" # AWC events \n",
    "tempsites = \"T:\\\\Aquatic\\\\KFHP\\\\Landscape_Metrics_DM\\\\Anchor\\\\Source_Data\\\\Anchor_Source.gdb\\\\tempsites_anchor\" # Temperature locations\n",
    "huc12 = r\"T:\\\\Aquatic\\\\KFHP\\\\Landscape_Metrics_DM\\\\Anchor\\\\Source_Data\\\\WBDHU12.shp\" # HUC12 from NHD gdb\n",
    "\n",
    "flowrast =  r\"T:\\\\Aquatic\\\\KFHP\\\\Landscape_Metrics_DM\\\\Anchor\\\\Source_Data\\\\AnchStar_StrBrn_ad8ContribArea.tif\" #flow accumulation raster for region of interest \n",
    "flowdirrast =  r\"T:\\\\Aquatic\\\\KFHP\\\\Landscape_Metrics_DM\\\\Anchor\\\\Source_Data\\\\AnchStar_StrBrn_d8flowdir.tif\" #flow direction raster for region of interest\n",
    "dem = \"T:\\\\Aquatic\\\\KFHP\\\\TauDEM_Outputs\\\\AnchStar\\\\Tau_out\\\\AnchStar_StrBrn_2Int.tif\" #DEM converted to Integer that matches extent and cell size of flow dir\n",
    "orig_streamrast = r\"T:\\\\Aquatic\\\\KFHP\\\\Landscape_Metrics_DM\\\\Anchor\\\\Source_Data\\\\AnchStar_StrBrn_src.tif\" #stream grid from synthetic stream network\n",
    "\n",
    "identname = region + \"_NLCD_Identity\"#name of output Identity\n",
    "tabtablename = region + \"_NLCD_Tab_Int\"#Name for output tabulate intersection table\n",
    "\n",
    "#### Final product output location ####\n",
    "networkgdb = r'T:\\\\Aquatic\\\\KFHP\\\\Geodatabases\\\\Anchor.gdb'# Location of shared geodatabase on network for final products\n",
    "\n",
    "### Generated variables ###\n",
    "\n",
    "streamdesc = arcpy.Describe(instreams)\n",
    "streams_name = streamdesc.name\n",
    "studydesc = arcpy.Describe(instudy)\n",
    "study_name = studydesc.name\n",
    "identname = streams_name + \"_NLCD_Identity\"#name of output Identity\n",
    "tabtablename = streams_name + \"_NLCD_Tab_Int\"#Name for output tabulate intersection table\n",
    "\n",
    "time = datetime.datetime.now()\n",
    "print (\"Variables set on\", time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create temporary folder and gdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output location already exists C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\\Anchor_Attributes_06022020\\Anchor.gdb\n"
     ]
    }
   ],
   "source": [
    "dirname = outdirname + str(time_stamp)\n",
    "temp_dir = os.path.join(path,dirname)\n",
    "ziploc = os.path.join(temp_dir, 'zips')\n",
    "extractloc = os.path.join(temp_dir, 'extracts')\n",
    "\n",
    "if not os.path.exists(temp_dir):\n",
    "    os.makedirs(temp_dir)\n",
    "    os.makedirs(ziploc)\n",
    "    os.makedirs(extractloc)        \n",
    "\n",
    "\n",
    "outcheck = os.path.join(temp_dir,outgdbname)\n",
    "\n",
    "if os.path.exists(outcheck):\n",
    "    print ('Output location already exists', outcheck)\n",
    "    outgdb = outcheck\n",
    "if not os.path.exists(outcheck):\n",
    "    print('Creating output GDB')\n",
    "    tempgdb = arcpy.CreateFileGDB_management(temp_dir,outgdbname)\n",
    "    print ('Output geodatabase created at',outcheck)\n",
    "    outgdb = tempgdb.getOutput(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\Watershed_Attributes\\\\Anchor\\\\Anchor_attributes\\\\Anchor_Attributes_06022020\\\\Anchor.gdb\\\\anch_studyarea', 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\Watershed_Attributes\\\\Anchor\\\\Anchor_attributes\\\\Anchor_Attributes_06022020\\\\Anchor.gdb\\\\anch_rca_reaches', 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\Watershed_Attributes\\\\Anchor\\\\Anchor_attributes\\\\Anchor_Attributes_06022020\\\\Anchor.gdb\\\\anchor_rcas', 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\Watershed_Attributes\\\\Anchor\\\\Anchor_attributes\\\\Anchor_Attributes_06022020\\\\Anchor.gdb\\\\tempsites_anchor', 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\Watershed_Attributes\\\\Anchor\\\\Anchor_attributes\\\\Anchor_Attributes_06022020\\\\Anchor.gdb\\\\awcEventArcs']\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "\n",
    "indata = []\n",
    "copylist = []\n",
    "indata = [instudy,instreams,inrca,tempsites,awc_events]\n",
    "\n",
    "for fc in indata:\n",
    "    \n",
    "    desc = arcpy.Describe(fc)\n",
    "    fieldlist = arcpy.ListFields(fc)\n",
    "    \n",
    "    copy = arcpy.CopyFeatures_management(fc,desc.name)\n",
    "    desc2 = arcpy.Describe(copy)\n",
    "    copypath = os.path.join (desc2.path, desc2.name)\n",
    "    copylist.append(copypath)\n",
    "\n",
    "print (copylist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set input variables from temporary copies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\\Anchor_Attributes_06022020\\Anchor.gdb\\anch_studyarea\n",
      "\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\\Anchor_Attributes_06022020\\Anchor.gdb\\anch_rca_reaches\n",
      "\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\\Anchor_Attributes_06022020\\Anchor.gdb\\anchor_rcas\n",
      "\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\\Anchor_Attributes_06022020\\Anchor.gdb\\tempsites_anchor\n",
      "\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\\Anchor_Attributes_06022020\\Anchor.gdb\\awcEventArcs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for path in copylist:\n",
    "    \n",
    "    if \"studyarea\" in path:      \n",
    "        studycopy = path\n",
    "        print (studycopy)\n",
    "        print (\"\")\n",
    "    \n",
    "    elif \"reaches\" in path:\n",
    "        reachcopy = path\n",
    "        print (reachcopy)\n",
    "        print (\"\")\n",
    "        \n",
    "    elif \"rcas\" in path:\n",
    "        rcacopy = path\n",
    "        print (rcacopy)\n",
    "        print (\"\")\n",
    "        \n",
    "    elif \"tempsites\" in path:\n",
    "        tempcopy = path\n",
    "        print (tempcopy)\n",
    "        print (\"\")\n",
    "    \n",
    "    elif \"awc\" in path:\n",
    "        awccopy = path\n",
    "        print (awccopy)\n",
    "        print (\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Geospatial operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join HUC12 data to RCA\n",
    "     * Format RCAs\n",
    "      * Drop all fields other than rca_id\n",
    "      * Recalculate elevation (min-mean-max)\n",
    "      * Recalculate contributing area\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Largest overlap Spatial Join\n",
    " * code from <a href = \"https://www.arcgis.com/home/item.html?id=e9cccd343bf84916bda1910c31e5eab2\">Largest Overlap</a>\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function, all functions run in SpatialJoinOverlapsCrossings\n",
    "def SpatialJoinLargestOverlap(target_features, join_features, out_fc, keep_all, spatial_rel):\n",
    "    if spatial_rel == \"largest_overlap\":\n",
    "        # Calculate intersection between Target Feature and Join Features\n",
    "        intersect = arcpy.analysis.Intersect([target_features, join_features], \"in_memory/intersect\", \"ONLY_FID\")\n",
    "        # Find which Join Feature has the largest overlap with each Target Feature\n",
    "        # Need to know the Target Features shape type, to know to read the SHAPE_AREA oR SHAPE_LENGTH property\n",
    "        geom = \"AREA\" if arcpy.Describe(target_features).shapeType.lower() == \"polygon\" and arcpy.Describe(join_features).shapeType.lower() == \"polygon\" else \"LENGTH\"\n",
    "        fields = [\"FID_{0}\".format(os.path.splitext(os.path.basename(target_features))[0]),\n",
    "                  \"FID_{0}\".format(os.path.splitext(os.path.basename(join_features))[0]),\n",
    "                  \"SHAPE@{0}\".format(geom)]\n",
    "        overlap_dict = {}\n",
    "        with arcpy.da.SearchCursor(intersect, fields) as scur:\n",
    "            for row in scur:\n",
    "                try:\n",
    "                    if row[2] > overlap_dict[row[0]][1]:\n",
    "                        overlap_dict[row[0]] = [row[1], row[2]]\n",
    "                except:\n",
    "                    overlap_dict[row[0]] = [row[1], row[2]]\n",
    "\n",
    "        # Copy the target features and write the largest overlap join feature ID to each record\n",
    "        # Set up all fields from the target features + ORIG_FID\n",
    "        fieldmappings = arcpy.FieldMappings()\n",
    "        fieldmappings.addTable(target_features)\n",
    "        fieldmap = arcpy.FieldMap()\n",
    "        fieldmap.addInputField(target_features, arcpy.Describe(target_features).OIDFieldName)\n",
    "        fld = fieldmap.outputField\n",
    "        fld.type, fld.name, fld.aliasName = \"LONG\", \"ORIG_FID\", \"ORIG_FID\"\n",
    "        fieldmap.outputField = fld\n",
    "        fieldmappings.addFieldMap(fieldmap)\n",
    "        # Perform the copy\n",
    "        arcpy.conversion.FeatureClassToFeatureClass(target_features, os.path.dirname(out_fc), os.path.basename(out_fc), \"\", fieldmappings)\n",
    "        # Add a new field JOIN_FID to contain the fid of the join feature with the largest overlap\n",
    "        arcpy.management.AddField(out_fc, \"JOIN_FID\", \"LONG\")\n",
    "        # Calculate the JOIN_FID field\n",
    "        with arcpy.da.UpdateCursor(out_fc, [\"ORIG_FID\", \"JOIN_FID\"]) as ucur:\n",
    "            for row in ucur:\n",
    "                try:\n",
    "                    row[1] = overlap_dict[row[0]][0]\n",
    "                    ucur.updateRow(row)\n",
    "                except:\n",
    "                    if not keep_all:\n",
    "                        ucur.deleteRow()\n",
    "        # Join all attributes from the join features to the output\n",
    "        joinfields = [x.name for x in arcpy.ListFields(join_features) if not x.required]\n",
    "        arcpy.management.JoinField(out_fc, \"JOIN_FID\", join_features, arcpy.Describe(join_features).OIDFieldName, joinfields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID\n",
      "Shape\n",
      "rca_id\n",
      "Shape_Length\n",
      "Shape_Area\n",
      "HUC12\n",
      "Name\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "hucjoinname = region + \"_rca_huc12_largeover_sj\"\n",
    "huccjoin = SpatialJoinLargestOverlap(rcacopy, huc12, hucjoinname, keep_all = \"TRUE\", spatial_rel = \"largest_overlap\" ) #Code from ESRI \n",
    "\n",
    "joindrop = []\n",
    "\n",
    "awcjoin = os.path.join(outgdb+ \"\\\\\" + hucjoinname)\n",
    "\n",
    "for field in arcpy.ListFields(awcjoin):\n",
    "    joindrop.append(field.name)\n",
    "\n",
    "keepfields = ['OBJECTID', 'Shape', 'rca_id','Shape_Length', 'Shape_Area','HUC12','Name']\n",
    "for field in keepfields:   \n",
    "    joindrop.remove(field)\n",
    "\n",
    "arcpy.DeleteField_management(awcjoin, joindrop)\n",
    "\n",
    "for field in arcpy.ListFields(awcjoin):\n",
    "    print (field.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all fields from reaches except reach id and shape fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJECTID', 'Shape', 'Shape_Leng', 'reachid', 'Z_Min', 'Z_Max', 'Z_Mean', 'SLength', 'Min_Slope', 'Max_Slope', 'Avg_Slope', 'length_m', 'slope_P', 'slope_D', 'Shape_Length']\n",
      "\n",
      "OBJECTID\n",
      "Shape\n",
      "reachid\n",
      "Shape_Length\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "reachfields = []\n",
    "for field in arcpy.ListFields(reachcopy):\n",
    "    reachfields.append(field.name)\n",
    "\n",
    "print (reachfields)\n",
    "print (\"\")\n",
    "\n",
    "keepfields = ['OBJECTID', 'Shape', 'reachid','Shape_Length']\n",
    "for field in keepfields:   \n",
    "    reachfields.remove(field)\n",
    "\n",
    "arcpy.DeleteField_management(reachcopy, reachfields)\n",
    "\n",
    "for field in arcpy.ListFields(reachcopy):\n",
    "    print (field.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fish data\n",
    " * Join 5 salmon species and with lifestage data to each RCA\n",
    "  * Format needs to be 3 columns for each species Spec/Lstag\n",
    "  \n",
    " * Identity awc with rca first then spatial join and concatenate or selectby and populate fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity awc with rca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\\Anchor_Attributes_06022020\\Anchor.gdb\\Anchor_awc_rca_IDENTITY\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "awcidentname = region + \"_awc_rca_IDENTITY\"\n",
    "awcclip = arcpy.Clip_analysis(awccopy,awcjoin,\"tempclip\")\n",
    "awcident = arcpy.Identity_analysis(awcclip,awcjoin,awcidentname,\"ALL\")\n",
    "\n",
    "print (awcident)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add fish species/life stage fields and delete join fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K_r', 'K_s', 'K_p', 'CH_r', 'CH_s', 'CH_p', 'CO_r', 'CO_s', 'CO_p', 'P_r', 'P_s', 'P_p', 'S_r', 'S_s', 'S_p']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\Watershed_Attributes\\\\Anchor\\\\Anchor_attributes\\\\Anchor_Attributes_06022020\\\\Anchor.gdb\\\\Anchor_rca_huc12_largeover_sj'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "lifestages = ['r','s','p']\n",
    "species = ['K','CH','CO','P','S']\n",
    "cols = []\n",
    "for s in species:\n",
    "    for l in lifestages:\n",
    "        colname = str(s) + \"_\" + str(l)\n",
    "        cols.append(colname)\n",
    "print(cols)\n",
    "\n",
    "for field in cols:\n",
    "    arcpy.AddField_management(awcjoin,field,\"SHORT\") #add awcfields to rcas\n",
    "\n",
    "deletefields = ['Join_Count','TARGET_FID','Join_Count_1','TARGET_FID_1','JOIN_FID']\n",
    "arcpy.DeleteField_management(awcjoin,deletefields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query AWC events and calculate presence, spawning, and rearing attributes for RCAs from AWC/RCA identity\n",
    " * SPECIES\n",
    "  * K: CHINOOK\n",
    "  * CH: CHUM\n",
    "  * CO: COHO\n",
    "  * P: PINK\n",
    "  * S: SOCKEYE\n",
    " \n",
    " \n",
    " * LIFE STAGE\n",
    "  * r: rearing\n",
    "  * s: spawning\n",
    "  * p: presence - Presence has been calculated such that p = 1 where present or rearing or spawning as recorded in AWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start script: 2020-02-06 14:26:49\n",
      "End script: 2020-02-06 14:27:00 Runtime = 0:00:10.740214\n"
     ]
    }
   ],
   "source": [
    "from time import strftime\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "print( \"Start script: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "fields = ['K_r', 'K_s', 'K_p', 'CH_r', 'CH_s', 'CH_p', 'CO_r', 'CO_s', 'CO_p', 'P_r', 'P_s', 'P_p', 'S_r', 'S_s', 'S_p']\n",
    "\n",
    "### Chinook Selections ###\n",
    "# \"SPECIES = 'K' And LSTAGE = 'r' OR SPECIES = 'K' And LSTAGE = 's' OR SPECIES = 'K' And LSTAGE = 'p'\" # Modify presence to include all\n",
    "\n",
    "akr = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'K' And LSTAGE = 'r'\")\n",
    "rkr = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', akr)\n",
    "arcpy.CalculateField_management(rkr,'K_r', 1)\n",
    "\n",
    "aks = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'K' And LSTAGE = 's'\")\n",
    "rks = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', aks)\n",
    "arcpy.CalculateField_management(rks,'K_s', 1)\n",
    "\n",
    "akp = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'K' And LSTAGE = 'r' OR SPECIES = 'K' And LSTAGE = 's' OR SPECIES = 'K' And LSTAGE = 'p'\")\n",
    "rkp = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', akp)\n",
    "arcpy.CalculateField_management(rkp,'K_p', 1)\n",
    "\n",
    "### Chum Selections ###\n",
    "achr = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'CH' And LSTAGE = 'r'\")\n",
    "rchr = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', achr)\n",
    "arcpy.CalculateField_management(rchr,'CH_r', 1)\n",
    "\n",
    "achs = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'CH' And LSTAGE = 's'\")\n",
    "rchs = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', achs)\n",
    "arcpy.CalculateField_management(rchs,'CH_s', 1)\n",
    "\n",
    "achp = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'CH' And LSTAGE = 'r' OR SPECIES = 'CH' And LSTAGE = 's' OR SPECIES = 'CH' And LSTAGE = 'p'\")\n",
    "rchp = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', achp)\n",
    "arcpy.CalculateField_management(rchp,'CH_p', 1)\n",
    "\n",
    "### Coho Selection ###\n",
    "acor = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'CO' And LSTAGE = 'r'\")\n",
    "rcor = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', acor)\n",
    "arcpy.CalculateField_management(rcor,'CO_r', 1)\n",
    "\n",
    "acos = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'CO' And LSTAGE = 's'\")\n",
    "rcos = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', acos)\n",
    "arcpy.CalculateField_management(rcos,'CO_s', 1)\n",
    "\n",
    "acop = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'CO' And LSTAGE = 'r' OR SPECIES = 'CO' And LSTAGE = 's' OR SPECIES = 'CO' And LSTAGE = 'p'\")\n",
    "rcop = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', acop)\n",
    "arcpy.CalculateField_management(rcop,'CO_p', 1)\n",
    "\n",
    "### Pink Selection ###\n",
    "apr = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'P' And LSTAGE = 'r'\")\n",
    "rpr = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', apr)\n",
    "arcpy.CalculateField_management(rpr,'P_r', 1)\n",
    "\n",
    "aps = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'P' And LSTAGE = 's'\")\n",
    "rps = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', aps)\n",
    "arcpy.CalculateField_management(rps,'P_s', 1)\n",
    "\n",
    "app = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'P' And LSTAGE = 'r' OR SPECIES = 'P' And LSTAGE = 's' OR SPECIES = 'P' And LSTAGE = 'p'\")\n",
    "rpp = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', app)\n",
    "arcpy.CalculateField_management(rpp,'P_p', 1)\n",
    "\n",
    "### Sockeye Selection ###\n",
    "asr = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'S' And LSTAGE = 'r'\")\n",
    "rsr = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', asr)\n",
    "arcpy.CalculateField_management(rsr,'S_r', 1)\n",
    "\n",
    "ass = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'S' And LSTAGE = 's'\")\n",
    "rss = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', ass)\n",
    "arcpy.CalculateField_management(rss,'S_s', 1)\n",
    "\n",
    "asp = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'S' And LSTAGE = 'r' OR SPECIES = 'S' And LSTAGE = 's' OR SPECIES = 'S' And LSTAGE = 'p'\")\n",
    "rsp = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', asp)\n",
    "arcpy.CalculateField_management(rsp,'S_p', 1)\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "print( \"End script: \" + strftime(\"%Y-%m-%d %H:%M:%S\") + \" Runtime = \" +  str(elapsed))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert null values in fish species columns to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "fieldList =  fields\n",
    "with arcpy.da.UpdateCursor(awcjoin, fieldList) as cursor:\n",
    "    fRange = range(len(fieldList)) # create an index 0 to the number of elements in fieldList - 1\n",
    "\n",
    "    for row in cursor:\n",
    "        \n",
    "\n",
    "        # step through each field in the row by its index\n",
    "        for index in fRange:\n",
    "            if row[index] == None:\n",
    "                row[index] = 0         #set null to zero\n",
    "            \n",
    "            \n",
    "            cursor.updateRow(row)\n",
    "\n",
    "print (\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reclassify Tau DEM flow direction to work with ESRI Flowaccumulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin process 2020-02-06 14:27:01.518077\n",
      "AnchStar_StrBrn_d8flowdir.tif\n",
      "Process complete  0:00:02.863219\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\\Anchor_Attributes_06022020\\AnchStar_StrBrn_d8flowdir.tif\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "from arcpy.sa import *\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "start= datetime.datetime.now()\n",
    "print (\"Begin process\", start)\n",
    "\n",
    "arcpy.env.workspace = temp_dir\n",
    "arcpy.env.overwriteOutput = True\n",
    "spref = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "arcpy.env.outputCoordinateSystem = spref\n",
    "\n",
    "\n",
    "rastdesc2 = arcpy.Describe(flowdirrast)\n",
    "print (rastdesc2.name)\n",
    "rastname2 = rastdesc2.name\n",
    "flowdircopy = Reclassify(flowdirrast, \"Value\", RemapValue([[1,1],[2,128],[3,64],[4,32],[5,16],[6,8],[7,4],[8,2]]))\n",
    "flowdircopy.save(rastname2)\n",
    "flowdirscribe = arcpy.Describe(flowdircopy)\n",
    "flowdirpath = os.path.join(flowdirscribe.path, flowdirscribe.name)\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "print (\"Process complete \", elapsed)\n",
    "print (flowdirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy Integer DEM from TauDEM to local\n",
    " * outputs from TauDEM have Cellsize slightly smaller than original DEM source raster\n",
    "   * This happened during the conversion of the orignal DEM from float to Integer\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processes Complete\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = temp_dir\n",
    "arcpy.env.snapRaster = flowdirpath\n",
    "arcpy.env.extent = flowdirpath\n",
    "arcpy.env.cellsize = flowdirpath\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "demdescribe = arcpy.Describe(dem)\n",
    "demname = temp_dir + demdescribe.name\n",
    "dem_copy = ExtractByMask(dem, flowdirpath)\n",
    "dem_copy.save(demname)\n",
    "\n",
    "print (\"Processes Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract stream src by reclassified flow dir\n",
    " * Probably unecessary but going to leave in for now to make sure all rasters are aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction Complete\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = temp_dir\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "arcpy.env.snapRaster = flowdirpath\n",
    "arcpy.env.extent = flowdirpath\n",
    "\n",
    "streamdescribe = arcpy.Describe(orig_streamrast)\n",
    "streamname = temp_dir + \"\\\\\" + streamdescribe.name\n",
    "streamrast = ExtractByMask(orig_streamrast, flowdirpath)\n",
    "streamrast.save(streamname)\n",
    "\n",
    "print (\"Extraction Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check rasters\n",
    " * Compare extent, cellsize, projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster name:      AnchStar_StrBrn_src.tif\n",
      "Projection:      NAD_1983_Alaska_Albers\n",
      "Compression Type: LZW\n",
      "Raster Format:    TIFF\n",
      "Height: 6559\n",
      "Width:  8047\n",
      "Cellsize:  4.999583\n",
      "Integer Raster: True\n",
      "Raster stats: min = 0.00 max = 1.00 mean = 0.01\n",
      "118738.668585699 1076858.79982803 158970.316695937 1109651.06774838 NaN NaN NaN NaN\n",
      "\n",
      "Raster name:      AnchStar_StrBrn_d8flowdir.tif\n",
      "Projection:      NAD_1983_Alaska_Albers\n",
      "Compression Type: LZW\n",
      "Raster Format:    TIFF\n",
      "Height: 6559\n",
      "Width:  8047\n",
      "Cellsize:  4.999583\n",
      "Integer Raster: True\n",
      "Raster stats: min = 1.00 max = 128.00 mean = 27.82\n",
      "118738.668585699 1076858.79982803 158970.316695937 1109651.06774838 NaN NaN NaN NaN\n",
      "\n",
      "Raster name:      Anchor_Attributes_06022020AnchStar_StrBrn_2Int.tif\n",
      "Projection:      NAD_1983_Alaska_Albers\n",
      "Compression Type: LZW\n",
      "Raster Format:    TIFF\n",
      "Height: 6559\n",
      "Width:  8047\n",
      "Cellsize:  4.999583\n",
      "Integer Raster: True\n",
      "Raster stats: min = 0.00 max = 621.00 mean = 271.84\n",
      "118738.668585699 1076858.79982803 158970.316695937 1109651.06774838 NaN NaN NaN NaN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rastlist = [streamrast, flowdirpath, dem_copy]\n",
    "for raster in rastlist:\n",
    "    desc = arcpy.Describe(raster)\n",
    "\n",
    "    \n",
    "    raster_min = arcpy.Raster(raster).minimum\n",
    "    raster_max = arcpy.Raster(raster).maximum\n",
    "    raster_mean = arcpy.Raster(raster).mean\n",
    "    extent = arcpy.Raster(raster).extent\n",
    "    \n",
    "    print(\"Raster name:      %s\" % desc.name)\n",
    "    print(\"Projection:      %s\" % desc.SpatialReference.name)\n",
    "    print(\"Compression Type: %s\" % desc.compressionType)\n",
    "    print(\"Raster Format:    %s\" % desc.format)\n",
    "    print(\"Height: %d\" % desc.height)\n",
    "    print(\"Width:  %d\" % desc.width)\n",
    "    print(\"Cellsize:  %f\" % desc.meanCellHeight)\n",
    "    print(\"Integer Raster: %s\" % desc.isInteger)\n",
    "    print(\"Raster stats: min = {:,.2f} max = {:,.2f} mean = {:,.2f}\".format(raster_min,raster_max,raster_mean))\n",
    "    print (extent)\n",
    "    print (\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Elevation data from DEM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start script: 2020-02-06 14:27:19\n",
      "\n",
      "Calculating zonal statistics\n",
      "\n",
      "Time to complete =  0:00:00.013963\n",
      "\n",
      "Joining statistics to RCAs\n",
      "\n",
      "Time to complete =  0:00:04.682639\n"
     ]
    }
   ],
   "source": [
    "from arcpy.sa import *\n",
    "start = datetime.datetime.now()\n",
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "print( \"Start script: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print (\"\")\n",
    "\n",
    "tablename = region + \"_DEM_Zonal_Table\"\n",
    "\n",
    "print (\"Calculating zonal statistics\")\n",
    "print(\"\")\n",
    "\n",
    "stop = datetime.datetime.now()  \n",
    "elapsed = stop - start  \n",
    "\n",
    "print ('Time to complete = ',elapsed)\n",
    "print(\"\")\n",
    "\n",
    "ztable = ZonalStatisticsAsTable(awcjoin, 'OBJECTID', dem_copy, tablename, 'DATA', 'MIN_MAX_MEAN')\n",
    "\n",
    "print (\"Joining statistics to RCAs\")\n",
    "print(\"\")\n",
    "\n",
    "arcpy.JoinField_management(awcjoin, 'OBJECTID', ztable, 'OBJECTID_1', ['MIN','MAX','MEAN'])\n",
    "\n",
    "\n",
    "stop = datetime.datetime.now()  \n",
    "elapsed = stop - start  \n",
    "print ('Time to complete = ',elapsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>rca_id</th>\n",
       "      <th>HUC12</th>\n",
       "      <th>Name</th>\n",
       "      <th>K_r</th>\n",
       "      <th>K_s</th>\n",
       "      <th>K_p</th>\n",
       "      <th>CH_r</th>\n",
       "      <th>CH_s</th>\n",
       "      <th>CH_p</th>\n",
       "      <th>CO_r</th>\n",
       "      <th>CO_s</th>\n",
       "      <th>CO_p</th>\n",
       "      <th>P_r</th>\n",
       "      <th>P_s</th>\n",
       "      <th>P_p</th>\n",
       "      <th>S_r</th>\n",
       "      <th>S_s</th>\n",
       "      <th>S_p</th>\n",
       "      <th>MIN</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MEAN</th>\n",
       "      <th>SHAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>190203010802</td>\n",
       "      <td>Stariski Creek</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>124</td>\n",
       "      <td>133</td>\n",
       "      <td>128.603251</td>\n",
       "      <td>{'rings': [[[132492.52273674682, 1107831.21941...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>190203010802</td>\n",
       "      <td>Stariski Creek</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>243</td>\n",
       "      <td>306</td>\n",
       "      <td>278.116076</td>\n",
       "      <td>{'rings': [[[139821.91195113584, 1104616.48718...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>190203010802</td>\n",
       "      <td>Stariski Creek</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>242</td>\n",
       "      <td>310</td>\n",
       "      <td>276.727113</td>\n",
       "      <td>{'rings': [[[139186.96485139057, 1104301.51339...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>190203010802</td>\n",
       "      <td>Stariski Creek</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>233</td>\n",
       "      <td>224.389034</td>\n",
       "      <td>{'rings': [[[136582.18201148883, 1105151.44262...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>190203010802</td>\n",
       "      <td>Stariski Creek</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>195</td>\n",
       "      <td>183.016694</td>\n",
       "      <td>{'rings': [[[135052.30944832042, 1105441.41850...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  rca_id         HUC12            Name  K_r  K_s  K_p  CH_r  CH_s  \\\n",
       "0         1     1.0  190203010802  Stariski Creek    0    0    0     0     0   \n",
       "1         2     2.0  190203010802  Stariski Creek    0    0    0     0     0   \n",
       "2         3     3.0  190203010802  Stariski Creek    0    0    0     0     0   \n",
       "3         4     4.0  190203010802  Stariski Creek    0    0    0     0     0   \n",
       "4         5     5.0  190203010802  Stariski Creek    0    0    0     0     0   \n",
       "\n",
       "   CH_p  CO_r  CO_s  CO_p  P_r  P_s  P_p  S_r  S_s  S_p  MIN  MAX        MEAN  \\\n",
       "0     0     0     0     0    0    0    0    0    0    0  124  133  128.603251   \n",
       "1     0     1     0     1    0    0    0    0    0    0  243  306  278.116076   \n",
       "2     0     1     0     1    0    0    0    0    0    0  242  310  276.727113   \n",
       "3     0     0     0     0    0    0    0    0    0    0  203  233  224.389034   \n",
       "4     0     1     0     1    0    0    0    0    0    0  173  195  183.016694   \n",
       "\n",
       "                                               SHAPE  \n",
       "0  {'rings': [[[132492.52273674682, 1107831.21941...  \n",
       "1  {'rings': [[[139821.91195113584, 1104616.48718...  \n",
       "2  {'rings': [[[139186.96485139057, 1104301.51339...  \n",
       "3  {'rings': [[[136582.18201148883, 1105151.44262...  \n",
       "4  {'rings': [[[135052.30944832042, 1105441.41850...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  \n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "from arcgis import GIS\n",
    "gis = GIS()\n",
    "sdf = pd.DataFrame.spatial.from_featureclass(awcjoin)\n",
    "sdf.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify outlets for each RCA\n",
    "  * Shrink RCAs by 15 meters shift outlet slighty upstream in order to avoid any errors that may smaller RCAs shifted into larger systems\n",
    " * Identify RCAs that were missed in the first operation and shrink by 8 meters\n",
    " * Identify any remaining RCAs missed by the first 2 operations and identify outlet\n",
    "### Merge results together and remove any duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Flow Accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06022020\n",
      "Begin process 2020-02-06 14:27:27.389508\n",
      "\n",
      "Creating  C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\\Anchor_Attributes_06022020\\Anchor_flow_accumulation_06022020.tif\n",
      "\n",
      "Process complete  0:00:35.729024\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "arcpy.env.workspace = temp_dir\n",
    "arcpy.env.snapRaster = flowdirpath \n",
    "arcpy.env.extent = flowdirpath\n",
    "\n",
    "today = datetime.now()\n",
    "# Make the time stamp.  \n",
    "time_stamp = '{:%d%m%Y}'.format(today)\n",
    "\n",
    "print(time_stamp)\n",
    "\n",
    "import datetime\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "print (\"Begin process\", start)\n",
    "print(\"\")\n",
    "\n",
    "flowrastname = temp_dir + \"\\\\\" + region + \"_flow_accumulation_\" + time_stamp + \".tif\"                \n",
    "\n",
    "print (\"Creating \",flowrastname)\n",
    "print(\"\")\n",
    "\n",
    "flowacc = FlowAccumulation(flowdirpath,\"\",  'FLOAT', 'D8') # create flow acc from flow dir\n",
    "flowacc.save(flowrastname)\n",
    "flowaccdescribe = arcpy.Describe(flowacc)\n",
    "flowaccpath = os.path.join(flowacc.path,flowacc.name)\n",
    "\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "print (\"Process complete \", elapsed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shrink RCA by 15 meters\n",
    "* Consider filtering out very small RCAs (those that would be dissolved with Inside Buffer) prior to running "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Process 2020-02-06 14:28:03.139477\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\\Anchor_Attributes_06022020\\Anchor.gdb\\Anchor_rca_huc12_largeover_sj_InsideBuffer_15\n",
      "Process complete  0:00:14.041848\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "print (\"Begin Process\", start)\n",
    "\n",
    "inrca = awcjoin\n",
    "buffval = -15 #shrink polygons by 15 meters\n",
    "rcadesc = arcpy.Describe(inrca)\n",
    "buffabs = abs(buffval)\n",
    "insidebuffname = rcadesc.name + \"_InsideBuffer_\" + str(buffabs)\n",
    "shrinkrca = arcpy.Buffer_analysis(inrca,insidebuffname,buffval)\n",
    "\n",
    "print(shrinkrca)\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "print (\"Process complete \", elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify and reclassify stream grid using TauDEM stream source grid and rca stream reaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin process 2020-02-06 14:28:17.202269\n",
      "\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\\Anchor_Attributes_06022020\\Anchor_streams_raster_06022020.tif\n",
      "Process complete  0:00:04.168900\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "arcpy.env.workspace = temp_dir\n",
    "arcpy.env.snapRaster = flowdirpath\n",
    "arcpy.env.extent = flowdirpath\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "\n",
    "today = datetime.now()\n",
    "# Make the time stamp.  \n",
    "time_stamp = '{:%d%m%Y}'.format(today)\n",
    "import datetime\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "print (\"Begin process\", start)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "outname = temp_dir + \"\\\\\" + region + \"_rcastream_src_maskextract_\" + time_stamp + \".tif\"\n",
    "streamrast2 = ExtractByMask(streamrast, reachcopy)\n",
    "streamrast2.save(outname)\n",
    "\n",
    "streamname = temp_dir + \"\\\\\" + region + \"_streams_raster_\" + time_stamp + \".tif\"\n",
    "#streamcon = Con((Con(IsNull(streamrast),0,1) + streamrast2),0,1,\"VALUE < 1\") #Identify stream network from the two input stream grids and reclassify as 1 for stream and 0 everywhere else\n",
    "streamcon = Con(IsNull(streamrast2), 0, streamrast2) #Reclassify null values in extracted stream src grid as 0\n",
    "streamcon.save(streamname)\n",
    "\n",
    "print (streamcon)\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "\n",
    "print (\"Process complete \", elapsed)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify outlets using stream accumulation grid, shrunken buffer, and zonal statistics\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating stream flow accumulation raster\n",
      "Creating max accumulation raster\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\\Anchor_Attributes_06022020\\Anchor_max_acc_zon_ALL.tif Created\n",
      "\n",
      "Identifying highest accumulation cell for each catchment\n",
      "Catchment outlets Id'd\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\\Anchor_Attributes_06022020\\Anchor_max_acc_catch_ALL.tif\n",
      "Time to complete =  0:00:12.651217\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "arcpy.env.workspace = temp_dir\n",
    "arcpy.env.snapRaster = flowdirpath\n",
    "arcpy.env.extent = flowdirpath\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "\n",
    "print (\"Creating stream flow accumulation raster\")\n",
    "\n",
    "streamflowname = temp_dir + \"\\\\\" + region + \"_stream_accumulation.tif\"                \n",
    "streamflow = SetNull(streamcon,flowaccpath,\"Value = 0\") # Create flow accumulation raster along stream network only\n",
    "streamflow.save(streamflowname)\n",
    "\n",
    "print (\"Creating max accumulation raster\")\n",
    "\n",
    "max_acczon = temp_dir +\"//\" + region + \"_max_acc_zon_ALL.tif\"\n",
    "max_acc_zon = arcpy.sa.ZonalStatistics(shrinkrca, 'OBJECTID', streamflow, 'MAXIMUM', 'DATA') #identify max flow accumulation using shrunken rca raster\n",
    "max_acc_zon.save(max_acczon)\n",
    "\n",
    "print (max_acc_zon, \"Created\")\n",
    "print(\"\")\n",
    "print (\"Identifying highest accumulation cell for each catchment\")\n",
    "\n",
    "max_accatch = temp_dir +\"//\" + region + \"_max_acc_catch_ALL.tif\"\n",
    "max_acc_catch = Con(streamflow == max_acc_zon,streamflow) # identify cell of highest accumulation for each rca along stream network\n",
    "max_acc_catch.save(max_accatch)\n",
    "\n",
    "print (\"Catchment outlets Id'd\")\n",
    "print (max_acc_catch)\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start  \n",
    "print ('Time to complete = ',elapsed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to point\n",
    " * First set of outlets, some RCAs will be missed due to shrunken buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Max accumulation cells to points\n",
      "\n",
      "Conversion COMPLETE\n",
      "\n",
      "Time to complete = 0:00:01.318479\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "print ('Converting Max accumulation cells to points')\n",
    "print ('')\n",
    "\n",
    "convers_name = outgdb + \"\\\\\" + region + \"_max_acc_outlet_FROM_ALL\"\n",
    "outlets = arcpy.RasterToPoint_conversion(max_acc_catch,convers_name)\n",
    "\n",
    "\n",
    "print ('Conversion COMPLETE')\n",
    "print ('')\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "\n",
    "print ('Time to complete =',elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify missing RCAs\n",
    " * Select missed RCAs using outlets produced from the first operation\n",
    "  * Rerun code above to create second outlet feature class using an 8 meter Inside Buffer\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting RCAs missed during buffer shrink\n",
      "\n",
      "Creating max accumulation raster\n",
      "\n",
      "Identifying highest accumulation cell for each catchment\n",
      "\n",
      "Catchment outlets Id'd\n",
      "\n",
      "Converting Max accumulation cells to points\n",
      "\n",
      "Conversion COMPLETE\n",
      "\n",
      "Merging outlets and deleting any duplicates\n",
      "\n",
      "\n",
      "Merge COMPLETE\n",
      "Time to complete = 0:00:12.985705\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "print (\"Selecting RCAs missed during buffer shrink\")\n",
    "print(\"\")\n",
    "\n",
    "missedout = arcpy.SelectLayerByLocation_management(awcjoin, 'INTERSECT', outlets, 1, 'NEW_SELECTION', 'INVERT') #Identify missed RCAs\n",
    "\n",
    "buffval = -8 #shrink missed polygons by 8 meters\n",
    "rcadesc = arcpy.Describe(inrca)\n",
    "buffabs = abs(buffval)\n",
    "insidebuffname = rcadesc.name + \"_InsideBuffer_\" + str(buffabs)\n",
    "shrinkrca2 = arcpy.Buffer_analysis(missedout, insidebuffname,buffval)\n",
    "\n",
    "print (\"Creating max accumulation raster\")\n",
    "print(\"\")\n",
    "\n",
    "max_acczon2 = temp_dir +\"//\" + region + \"_max_acc_zon_ALL2.tif\"\n",
    "max_acc_zon2 = arcpy.sa.ZonalStatistics(shrinkrca2, 'OBJECTID', streamflow, 'MAXIMUM', 'DATA') #identify max flow accumulation using shrunken rca raster\n",
    "max_acc_zon2.save(max_acczon2)\n",
    "\n",
    "print (\"Identifying highest accumulation cell for each catchment\")\n",
    "print(\"\")\n",
    "\n",
    "max_accatch2 = temp_dir +\"//\" + region + \"_max_acc_catch_ALL2.tif\"\n",
    "max_acc_catch2 = Con(streamflow == max_acc_zon2,streamflow) # identify cell of highest accumulation for each rca along stream network\n",
    "max_acc_catch2.save(max_accatch2)\n",
    "\n",
    "print (\"Catchment outlets Id'd\")\n",
    "print(\"\")\n",
    "\n",
    "print ('Converting Max accumulation cells to points')\n",
    "print(\"\")\n",
    "\n",
    "convers_name = outgdb + \"\\\\\" + region + \"_max_acc_outlet_FROM_ALL2\"\n",
    "outlets2 = arcpy.RasterToPoint_conversion(max_acc_catch2,convers_name)\n",
    "\n",
    "print ('Conversion COMPLETE')\n",
    "print('')\n",
    "\n",
    "print(\"Merging outlets and deleting any duplicates\")\n",
    "print (\"\")\n",
    "\n",
    "pointmergename = outgdb + \"\\\\\" + region + \"_outlets_Merge1\"\n",
    "outletmerge = arcpy.Merge_management([outlets,outlets2 ],pointmergename)\n",
    "\n",
    "print('')\n",
    "print ('Merge COMPLETE')\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "print ('Time to complete =',elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a third time without inside buffer on any missed outlets\n",
    " * Tend to be very small RCAs near the confluence of larger systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting RCAs missed during buffer shrink\n",
      "\n",
      "final selection of 10 missed RCAs\n",
      "Creating max accumulation raster\n",
      "\n",
      "Identifying highest accumulation cell for each catchment\n",
      "\n",
      "Catchment outlets Id'd\n",
      "\n",
      "Converting Max accumulation cells to points\n",
      "\n",
      "Conversion COMPLETE\n",
      "\n",
      "Merging outlets\n",
      "\n",
      "\n",
      "Merge COMPLETE\n",
      "Join Complete...deleting duplicates\n",
      "\n",
      "Extracting flow accumulation to outlet\n",
      "\n",
      "Process complete\n",
      "1211 Outlets created\n",
      "Time to complete = 0:00:16.331894\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "print (\"Selecting RCAs missed during buffer shrink\")\n",
    "print(\"\")\n",
    "\n",
    "missedout2 = arcpy.SelectLayerByLocation_management(awcjoin, 'INTERSECT', outletmerge, 1, 'NEW_SELECTION', 'INVERT') #Identify missed RCAs\n",
    "miss2 = arcpy.GetCount_management(missedout2)\n",
    "print (\"final selection of \" + str(miss2) + \" missed RCAs\")\n",
    "\n",
    "print (\"Creating max accumulation raster\")\n",
    "print(\"\")\n",
    "\n",
    "max_acczon3 = temp_dir +\"//\" + region + \"_max_acc_zon_ALL3.tif\"\n",
    "max_acc_zon3 = arcpy.sa.ZonalStatistics(missedout2, 'OBJECTID', streamflow, 'MAXIMUM', 'DATA') #identify max flow accumulation using shrunken rca raster\n",
    "max_acc_zon3.save(max_acczon3)\n",
    "\n",
    "print (\"Identifying highest accumulation cell for each catchment\")\n",
    "print(\"\")\n",
    "\n",
    "max_accatch3 = temp_dir +\"//\" + region + \"_max_acc_catch_ALL3.tif\"\n",
    "max_acc_catch3 = Con(streamflow == max_acc_zon3,streamflow) # identify cell of highest accumulation for each rca along stream network\n",
    "max_acc_catch3.save(max_accatch3)\n",
    "\n",
    "print (\"Catchment outlets Id'd\")\n",
    "print(\"\")\n",
    "\n",
    "print ('Converting Max accumulation cells to points')\n",
    "print(\"\")\n",
    "\n",
    "convers_name = outgdb + \"\\\\\" + region + \"_max_acc_outlet_FROM_ALL3\"\n",
    "outlets3 = arcpy.RasterToPoint_conversion(max_acc_catch3,convers_name)\n",
    "\n",
    "print ('Conversion COMPLETE')\n",
    "print('')\n",
    "\n",
    "print(\"Merging outlets\")\n",
    "print (\"\")\n",
    "\n",
    "pointmergename2 = outgdb + \"\\\\\" + region + \"_outlets_Merge2\"\n",
    "outletmerge2 = arcpy.Merge_management([outletmerge, outlets3],pointmergename2)\n",
    "\n",
    "print('')\n",
    "print ('Merge COMPLETE')\n",
    "\n",
    "joinname = outgdb + \"\\\\\" + region + \"_RCA_Outlets_\" + time_stamp\n",
    "idjoin2 = arcpy.SpatialJoin_analysis(outletmerge2, awcjoin, joinname, 'JOIN_ONE_TO_ONE', 'KEEP_ALL',\"\", 'INTERSECT')\n",
    "\n",
    "print (\"Join Complete...deleting duplicates\")\n",
    "print (\"\")\n",
    "\n",
    "arcpy.DeleteIdentical_management(idjoin2,'SHAPE')\n",
    "\n",
    "print (\"Extracting flow accumulation to outlet\")\n",
    "print (\"\")\n",
    "\n",
    "ExtractMultiValuesToPoints(idjoin2,[[streamflow, \"Flow_Accumulation\"]])\n",
    "\n",
    "print (\"Process complete\")\n",
    "\n",
    "count = arcpy.GetCount_management(idjoin2)\n",
    "\n",
    "print (str(count) + \" Outlets created\")\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "print ('Time to complete =',elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Mean Elevation for RCA + all upstream contributing area\n",
    " * Create elevation weighted flow accumulation and divide by flow accumulation\n",
    " * Extract to outlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin process 2020-02-06 14:29:04.757200\n",
      "\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\\Anchor_Attributes_06022020\\Anchor_elevation_weighted_flowacc.tif\n",
      "\n",
      "Process complete  0:00:37.548543\n",
      "\n",
      "Calculate Mean Elevation along stream network\n",
      "\n",
      "Process complete  0:00:10.724643\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\\Anchor_Attributes_06022020\\Anchorstream_MEAN_elev.tif\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = temp_dir\n",
    "arcpy.env.snapRaster = flowdirpath\n",
    "arcpy.env.extent = flowdirpath\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "print (\"Begin process\", start)\n",
    "print(\"\")\n",
    "\n",
    "elevw8name = temp_dir + \"\\\\\" + region + \"_elevation_weighted_flowacc.tif\"\n",
    "elevw8flow = FlowAccumulation(flowdirpath, dem_copy, 'FLOAT', 'D8') # create glacially weighted flow accumulation\n",
    "elevw8flow.save(elevw8name)\n",
    "\n",
    "print(elevw8flow)\n",
    "print (\"\")\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "\n",
    "print (\"Process complete \", elapsed)\n",
    "print (\"\")\n",
    "print (\"Calculate Mean Elevation along stream network\")\n",
    "print (\"\")\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "meanelevname = temp_dir + \"\\\\\" + region + \"stream_MEAN_elev.tif\"                \n",
    "meanelev = SetNull(streamflow,(elevw8flow / flowaccpath ),\"Value = 0\") #Limit output to stream network\n",
    "meanelev.save(meanelevname)\n",
    "\n",
    "ExtractMultiValuesToPoints(idjoin2,[[meanelev, \"Mean_Elev_Contributing_Area\"]])\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "\n",
    "print (\"Process complete \", elapsed)\n",
    "print(meanelev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Final attributed RCA on local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting elevation at temperature site\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\\Anchor_Attributes_06022020\\Anchor.gdb\\anchor_rcas_temp_sites_attributed_06022020\n",
      "\n",
      "1210 Outlets created\n",
      "\n",
      "1210 RCAs created in the Anchorstudy area\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\Watershed_Attributes\\\\Anchor\\\\Anchor_attributes\\\\Anchor_Attributes_06022020\\\\Anchor.gdb\\\\anchor_rcas_attributed_06022020'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "rcadesc = arcpy.Describe(rcacopy)\n",
    "name = rcadesc.name\n",
    "rcacopyname = name +\"_attributed_\" + time_stamp\n",
    "finalrca = arcpy.CopyFeatures_management(rcacopy, rcacopyname)\n",
    "\n",
    "for field in arcpy.ListFields(finalrca):\n",
    "    joindrop.append(field.name)\n",
    "    \n",
    "keepfields = ['OBJECTID', 'Shape', 'rca_id','Shape_Length', 'Shape_Area']\n",
    "for field in keepfields:\n",
    "    joindrop.remove(field)\n",
    "\n",
    "arcpy.DeleteField_management(finalrca, joindrop)\n",
    "\n",
    "tempdesc = arcpy.Describe(tempsites)\n",
    "tempcopyname = name + \"_temp_sites_attributed_\" + time_stamp\n",
    "tempfinal = arcpy.CopyFeatures_management(tempsites,tempcopyname)\n",
    "ExtractMultiValuesToPoints(tempfinal,[[dem_copy, \"Elevation_meters\"]])\n",
    "\n",
    "print(\"Extracting elevation at temperature site\")\n",
    "print(tempfinal)\n",
    "print (\"\")\n",
    "\n",
    "outletcopyname = region + \"_rca_outlets_attributed_\" + time_stamp\n",
    "outcopy = arcpy.CopyFeatures_management(idjoin2, outletcopyname)\n",
    "arcpy.DeleteIdentical_management(outcopy,'rca_id')\n",
    "count = arcpy.GetCount_management(outcopy)\n",
    "\n",
    "print (str(count) + \" Outlets created\")\n",
    "print(\"\")\n",
    "\n",
    "count2 = arcpy.GetCount_management(finalrca)\n",
    "\n",
    "print (str(count2) + \" RCAs created in the \" + str(region) + \"study area\")\n",
    "print (\"\")\n",
    "\n",
    "arcpy.JoinField_management(finalrca,\"rca_id\",outcopy, \"rca_id\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recalculate slope percent reaches\n",
    " * (rise/run*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Surface information to rca reaches\n",
      "\n",
      "Adding Surface info fields\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\Watershed_Attributes\\\\Anchor\\\\Anchor_attributes\\\\Anchor_Attributes_06022020\\\\Anchor.gdb\\\\anch_rca_reaches'>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arcpy.sa import * \n",
    "method = \"BILINEAR\"\n",
    "prop = \"Z_MIN;Z_MAX;Z_MEAN;SURFACE_LENGTH\"\n",
    "perc_calc = '(!Z_Max!-!Z_Min!)/!SLength!*100'\n",
    "\n",
    "print (\"Adding Surface information to rca reaches\")\n",
    "print (\"\")\n",
    "\n",
    "arcpy.ddd.AddSurfaceInformation(reachcopy,dem_copy,prop,method)\n",
    "\n",
    "print (\"Adding Surface info fields\")\n",
    "print (\"\")\n",
    "\n",
    "arcpy.AddField_management(reachcopy,\"reach_length\", \"DOUBLE\",\"\",\"\",\"\", \"Reach Length in meters\")\n",
    "arcpy.AddField_management(reachcopy,\"reach_slope\", 'DOUBLE',\"\",\"\",\"\",\"Reach slope in percent\")\n",
    "arcpy.CalculateField_management(reachcopy,\"reach_slope\", perc_calc)\n",
    "arcpy.CalculateField_management(reachcopy,\"reach_length\", '!SLength!')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcute percent land cover metrics in 30meter buffered area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download NLCD\n",
    " * NLCD is currently the best available landcover dataset with coverage for the entire state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ak_nlcd_2011_landcover_1_15_15.zip\n",
      "\n",
      "ALL DOWNLOADS COMPLETE\n",
      "Time to complete =  0:00:29.009184\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "wurl = r\"https://prd-tnm.s3.amazonaws.com/StagedProducts/NLCD2011/Land_Cover/Alaska/ak_nlcd_2011_landcover_1_15_15.zip\"\n",
    "start = datetime.datetime.now() \n",
    "wname = wurl[-34:]\n",
    "print ('Downloading',wname)\n",
    "\n",
    "wzippath = str(ziploc) + '/'+ str(wname) #path to save download to plus name of download\n",
    "# headers = {\"Range\": \"bytes=0-100\"}  # first 100 bytes\n",
    "# rh= requests.get(wurl, headers)\n",
    "# print(rh.status_code)\n",
    "# print(rh.headers['content-type'])\n",
    "# print(rh.encoding)\n",
    "r = requests.get(wurl)\n",
    "if not os.path.exists(wzippath):\n",
    "    with open(wzippath,'wb') as f:\n",
    "        f.write(r.content)\n",
    "        \n",
    "print('')\n",
    "print ('ALL DOWNLOADS COMPLETE')\n",
    "stop = datetime.datetime.now()  \n",
    "elapsed = stop - start  \n",
    "print ('Time to complete = ',elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip NLCD\n",
    "#### Must have 7zip installed and located in the path below, change if necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping  C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\\Anchor_Attributes_06022020\\zips\\ak_nlcd_2011_landcover_1_15_15.zip\n",
      "Finished extracting AK NLCD\n",
      "\n",
      "Unzipping complete\n",
      "Time to complete =  0:00:29.054064\n"
     ]
    }
   ],
   "source": [
    "### Unzip landcover data\n",
    "\n",
    "import subprocess\n",
    "os.chdir(ziploc)\n",
    "for dir in os.listdir():\n",
    "    if \"ak_nlcd_2011\" in dir:\n",
    "        wzip = os.path.abspath(dir)\n",
    "        print ('Unzipping ', wzip)\n",
    "        #wzip = zipfile.ZipFile(file_name) # create zipfile object\n",
    "        #wzip.extractall(extractloc) # extract file to dir\n",
    "        #wzip.close() # close file\n",
    "        #os.remove(file_name) # delete zipped file if required\n",
    "        wuz = subprocess.call(r'\"C:\\Program Files\\7-Zip\\7z.exe\" x ' + wzip + ' -o' + extractloc)\n",
    "        print ('Finished extracting AK NLCD')\n",
    "print('')\n",
    "print ('Unzipping complete')\n",
    "stop = datetime.datetime.now()  \n",
    "elapsed = stop - start  \n",
    "print ('Time to complete = ',elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Glacier data - KENAI ONLY\n",
    " * approx 1 gb download as of 20200117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# wurl = r\"http://www.glims.org/download/latest\" #latest glims data\n",
    "# start = datetime.datetime.now() \n",
    "# wname = \"GLIMS_Data.zip\"\n",
    "# print ('Downloading',wname)\n",
    "\n",
    "\n",
    "# wzippath = str(ziploc) + '/'+ str(wname) #path to save download to plus name of download\n",
    "# # headers = {\"Range\": \"bytes=0-100\"}  # first 100 bytes\n",
    "# # rh= requests.get(wurl, headers)\n",
    "# # print(rh.status_code)\n",
    "# # print(rh.headers['content-type'])\n",
    "# # print(rh.encoding)\n",
    "# r = requests.get(wurl)\n",
    "# if not os.path.exists(wzippath):\n",
    "#     with open(wzippath,'wb') as f:\n",
    "#         f.write(r.content)\n",
    "        \n",
    "# print('')\n",
    "# print ('ALL DOWNLOADS COMPLETE')\n",
    "# stop = datetime.datetime.now()  \n",
    "# elapsed = stop - start  \n",
    "# print ('Time to complete = ',elapsed)\n",
    "\n",
    "# os.chdir(ziploc)\n",
    "# start = datetime.datetime.now()\n",
    "# for item in os.listdir():\n",
    "#     if \"GLIMS\" in item:\n",
    "#         file_name = os.path.abspath(item) # get full path of files\n",
    "#         zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
    "#         zip_ref.extractall(extractloc) # extract file to dir\n",
    "#         zip_ref.close() # close file\n",
    "#         #os.remove(file_name) # delete zipped file if required   \n",
    "#         print ('Unzipping..', file_name)\n",
    "#         print('')\n",
    "\n",
    "# print ('Unzipping complete')\n",
    "# stop = datetime.datetime.now()  \n",
    "# elapsed = stop - start  \n",
    "# print ('Time to complete = ',elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buffer by 30 meters and clip to study area\n",
    " * Buffers will overlap but this is not an issue\n",
    "  * Adding text field to copy NHDPLUSID (Using Float field may cause issues with panda display) and add and calc shape area in square meters as a check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\Watershed_Attributes\\\\Anchor\\\\Anchor_attributes\\\\Anchor_Attributes_06022020\\\\Anchor.gdb\\\\anch_rca_reaches_buff30'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "reachdesc = arcpy.Describe(reachcopy)\n",
    "streambuffname = reachdesc.name + \"_buff30\"\n",
    "riv_buff30 = arcpy.Buffer_analysis(reachcopy,streambuffname,30, 'FULL', 'FLAT', 'NONE')\n",
    "arcpy.AddField_management(riv_buff30,\"Buff_Area_Sqm\", 'DOUBLE')\n",
    "arcpy.CalculateField_management(riv_buff30, 'Buff_Area_Sqm','!shape.area@squaremeters!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Shrub and Forest Layers\n",
    " * Buffer study area by 60 meters to ensure no cells are missed in extraction\n",
    "  * Extract NLCD raster by Study Watershed polygon mask and convert to Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watershed Buffer complete C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\\Anchor_Attributes_06022020\\Anchor.gdb\\Anchor_buff60\n",
      "\n",
      "ak_nlcd_2011_landcover_1_15_15.img\n",
      "\n",
      "Extracting raster  ak_nlcd_2011_landcover_1_15_15\n",
      "\n",
      "Extraction Complete\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\\Anchor_Attributes_06022020\\ak_nlcd_2011_landcover_1_15_15_extract.tif\n",
      "\n",
      "Process complete  0:00:00.614981\n",
      "\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\\Anchor_Attributes_06022020\\Anchor.gdb\\Anchor_nlcd_poly\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "arcpy.env.extent = flowdirpath\n",
    "arcpy.env.snapRaster = flowdirpath\n",
    "\n",
    "studybuffname = region + \"_buff60\"\n",
    "study_buff = arcpy.Buffer_analysis(studycopy,studybuffname,60, 'FULL', 'ROUND', 'ALL')\n",
    "\n",
    "print (\"Watershed Buffer complete\", study_buff)\n",
    "print (\"\")\n",
    "\n",
    "from arcpy.sa import *\n",
    "os.chdir(extractloc)\n",
    "arcpy.env.workspace = extractloc\n",
    "raster_list = arcpy.ListRasters()\n",
    "start = datetime.datetime.now()\n",
    "for raster in raster_list:\n",
    "    if \"ak_nlcd_2011\" in raster:\n",
    "        \n",
    "        print (raster)\n",
    "        print (\"\")\n",
    "        \n",
    "        desc = arcpy.Describe(raster)\n",
    "        name = desc.baseName\n",
    "        outname = temp_dir + \"\\\\\" + name + \"_extract.tif\"\n",
    "        \n",
    "        print (\"Extracting raster \", name)\n",
    "        print (\"\")\n",
    "        \n",
    "        extract = ExtractByMask(raster, study_buff)\n",
    "        extract.save(outname)\n",
    "        \n",
    "        print (\"Extraction Complete\")\n",
    "        print (extract)\n",
    "        print (\"\")\n",
    "                \n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "\n",
    "print (\"Process complete \", elapsed)\n",
    "print (\"\")\n",
    "\n",
    "arcpy.env.workspace = outgdb\n",
    "nlcdpolyname = region + \"_nlcd_poly\"\n",
    "nlcd_poly = arcpy.RasterToPolygon_conversion(extract,nlcdpolyname, 'NO_SIMPLIFY', 'Land_Cover')\n",
    "\n",
    "print (nlcd_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add and calc area in sq meters as check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\Watershed_Attributes\\\\Anchor\\\\Anchor_attributes\\\\Anchor_Attributes_06022020\\\\Anchor.gdb\\\\Anchor_nlcd_poly'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.AddField_management(nlcd_poly,\"Area_Sqm\", 'DOUBLE')\n",
    "arcpy.CalculateField_management(nlcd_poly, 'Area_Sqm','!shape.area@squaremeters!')\n",
    "arcpy.AddField_management(nlcd_poly,\"Land_Cover_Reclass\", 'TEXT')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add field and reclass cover types using following dictionary\n",
    " * Use update cursor and dictionary to reclassify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process complete  0:00:03.179511\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "d = {'Barren Land':'Barren',\n",
    "'Cultivated Crops':'Crops',\n",
    "'Deciduous Forest':'Forest',\n",
    "'Mixed Forest':'Forest',\n",
    "'Evergreen Forest':'Forest',\n",
    "'Grassland/Herbaceous':'Herbaceous',\n",
    "'Sedge/Herbaceous':'Herbaceous',\n",
    "'Developed, High Intensity':'High intensity',\n",
    "'Developed, Low Intensity':'Low intensity',\n",
    "'Developed, Medium Intensity':'Medium intensity',\n",
    "'Developed, Open Space':'Open space',\n",
    "'Pasture/Hay':'Pasture',\n",
    "'Perennial Ice/Snow':'Perennial Ice',\n",
    "'Shrub/Scrub':'Shrub',\n",
    "'Dwarf Shrub':'Shrub',\n",
    "'Open Water':'Water',\n",
    "'Emergent Herbaceous Wetlands':'Wetlands',\n",
    "'Woody Wetlands':'Wetlands'}\n",
    "\n",
    "fields = ['Land_Cover','Land_Cover_Reclass']\n",
    "with arcpy.da.UpdateCursor(nlcd_poly, (fields)) as rows:\n",
    "    for row in rows:\n",
    "        if row[0] not in d.keys():\n",
    "            print (\"{} not in list\".format(row[0]))\n",
    "        else:\n",
    "            row[1] = d[row[0]]\n",
    "            rows.updateRow(row)\n",
    "    del row \n",
    "del rows\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "\n",
    "print (\"Process complete \", elapsed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabulate intersection between 30m buffered river segments (defined by nhdplusid or reachid) and nlcd polygon created above\n",
    " \n",
    " * Table output of land cover percent and total area for each land cover type within the buffered river segment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# start = datetime.datetime.now()\n",
    "# arcpy.env.workspace = outgdb\n",
    "# tab_int = arcpy.TabulateIntersection_analysis(riv_buff30, identifierfield, nlcd_poly,tabtablename, ['Land_Cover','Land_Cover_Reclass'], 'Area_Sqm')\n",
    "\n",
    "# print (tab_int)\n",
    "# print (\"\")\n",
    "\n",
    "# stop = datetime.datetime.now()\n",
    "# elapsed = stop - start\n",
    "\n",
    "# print (\"Process complete \", elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Anchor\\Anchor_attributes\\Anchor_Attributes_06022020\\Anchor.gdb\\Reclassified_anch_rca_reaches_NLCD_Tab_Int\n",
      "\n",
      "Process complete  0:00:27.526089\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "arcpy.env.workspace = outgdb\n",
    "tab2name = \"Reclassified_\" + tabtablename\n",
    "tab_int2 = arcpy.TabulateIntersection_analysis(riv_buff30, identifierfield, nlcd_poly,tab2name, ['Land_Cover_Reclass'], 'Area_Sqm')\n",
    "\n",
    "print (tab_int2)\n",
    "print (\"\")\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "\n",
    "print (\"Process complete \", elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Identity and dissolve to check against tabulate intersection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = datetime.datetime.now()\n",
    "# arcpy.env.workspace = outgdb\n",
    "# riv_nlcd_id = arcpy.Identity_analysis(riv_buff30, nlcd_poly,identname, 'ALL')\n",
    "# end = datetime.datetime.now()\n",
    "# elapsed = end-start\n",
    "\n",
    "# print (\"Time to complete\",elapsed)\n",
    "# print (riv_nlcd_id)\n",
    "# print (\"\")\n",
    "\n",
    "# idcount = arcpy.GetCount_management(riv_nlcd_id)\n",
    "\n",
    "# print (idcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dissolve Identity\n",
    " * Keep ID, landcover, reclass, and buffered area\n",
    " * Add/calculate area in sqm and percent cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = datetime.datetime.now()\n",
    "# arcpy.env.workspace = outgdb\n",
    "# disname = identname + \"_All_Land_Dissolve\"\n",
    "\n",
    "# print(\"Begin Dissolve\", start)\n",
    "# print(\"\")\n",
    "\n",
    "# riv_nlcd_i0.d_dis = arcpy.Dissolve_management(riv_nlcd_id,disname, [identifierfield,'Land_Cover','Land_Cover_Reclass','Buff_Area_Sqm'], '', 'MULTI_PART', 'DISSOLVE_LINES')\n",
    "# arcpy.AddField_management(riv_nlcd_id_dis,\"Percent_Cover\", 'DOUBLE')\n",
    "# arcpy.AddField_management(riv_nlcd_id_dis,'Shape_Area_Sqm', 'DOUBLE')\n",
    "# arcpy.CalculateField_management(riv_nlcd_id_dis, 'Shape_Area_Sqm','!shape.area@squaremeters!')\n",
    "# percent_calc = \"!Shape_Area_Sqm!/!Buff_Area_Sqm!*100\"\n",
    "# arcpy.CalculateField_management(riv_nlcd_id_dis, 'Percent_Cover',percent_calc)\n",
    "# end = datetime.datetime.now()\n",
    "# elapsed = end-start\n",
    "\n",
    "# print (\"Time to complete\",elapsed)\n",
    "# print (riv_nlcd_id_dis)\n",
    "# print (\"\")\n",
    "\n",
    "# disscount = arcpy.GetCount_management(riv_nlcd_id_dis)\n",
    "\n",
    "# print (disscount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = datetime.datetime.now()\n",
    "# arcpy.env.workspace = outgdb\n",
    "# disname2 = identname + \"_Land_Reclass_Dissolve\"\n",
    "\n",
    "# print(\"Begin Dissolve\", start)\n",
    "# print(\"\")\n",
    "\n",
    "# riv_nlcd_id_dis2 = arcpy.Dissolve_management(riv_nlcd_id,disname2, [identifierfield, 'Land_Cover_Reclass','Buff_Area_Sqm'], '', 'MULTI_PART', 'DISSOLVE_LINES')\n",
    "# arcpy.AddField_management(riv_nlcd_id_dis2,\"Percent_Cover\", 'DOUBLE')\n",
    "# arcpy.AddField_management(riv_nlcd_id_dis2,'Shape_Area_Sqm', 'DOUBLE')\n",
    "# arcpy.CalculateField_management(riv_nlcd_id_dis2, 'Shape_Area_Sqm','!shape.area@squaremeters!')\n",
    "# percent_calc = \"!Shape_Area_Sqm!/!Buff_Area_Sqm!*100\"\n",
    "# arcpy.CalculateField_management(riv_nlcd_id_dis2, 'Percent_Cover',percent_calc)\n",
    "# end = datetime.datetime.now()\n",
    "# elapsed = end-start\n",
    "\n",
    "# print (\"Time to complete\",elapsed)\n",
    "# print (riv_nlcd_id_dis2)\n",
    "# print (\"\")\n",
    "\n",
    "# disscount = arcpy.GetCount_management(riv_nlcd_id_dis2)\n",
    "\n",
    "# print (disscount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert table to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>reachid</th>\n",
       "      <th>Land_Cover_Reclass</th>\n",
       "      <th>Area_Sqm</th>\n",
       "      <th>AREA</th>\n",
       "      <th>PERCENTAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Forest</td>\n",
       "      <td>14627.22</td>\n",
       "      <td>14627.22</td>\n",
       "      <td>26.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Shrub</td>\n",
       "      <td>7029.21</td>\n",
       "      <td>7029.21</td>\n",
       "      <td>12.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Wetlands</td>\n",
       "      <td>33426.76</td>\n",
       "      <td>33426.76</td>\n",
       "      <td>60.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>Forest</td>\n",
       "      <td>34313.47</td>\n",
       "      <td>34313.47</td>\n",
       "      <td>95.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Shrub</td>\n",
       "      <td>1799.23</td>\n",
       "      <td>1799.23</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2934</td>\n",
       "      <td>2935</td>\n",
       "      <td>1211</td>\n",
       "      <td>Forest</td>\n",
       "      <td>19691.05</td>\n",
       "      <td>19691.05</td>\n",
       "      <td>65.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2935</td>\n",
       "      <td>2936</td>\n",
       "      <td>1211</td>\n",
       "      <td>Shrub</td>\n",
       "      <td>10476.18</td>\n",
       "      <td>10476.18</td>\n",
       "      <td>34.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2936</td>\n",
       "      <td>2937</td>\n",
       "      <td>1211</td>\n",
       "      <td>Wetlands</td>\n",
       "      <td>103.10</td>\n",
       "      <td>103.10</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2937</td>\n",
       "      <td>2938</td>\n",
       "      <td>1212</td>\n",
       "      <td>Forest</td>\n",
       "      <td>8402.58</td>\n",
       "      <td>8402.58</td>\n",
       "      <td>23.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2938</td>\n",
       "      <td>2939</td>\n",
       "      <td>1212</td>\n",
       "      <td>Shrub</td>\n",
       "      <td>27979.62</td>\n",
       "      <td>27979.62</td>\n",
       "      <td>76.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2939 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      OBJECTID  reachid Land_Cover_Reclass  Area_Sqm     AREA  PERCENTAGE\n",
       "0            1        1             Forest  14627.22 14627.22       26.55\n",
       "1            2        1              Shrub   7029.21  7029.21       12.76\n",
       "2            3        1           Wetlands  33426.76 33426.76       60.68\n",
       "3            4        2             Forest  34313.47 34313.47       95.02\n",
       "4            5        2              Shrub   1799.23  1799.23        4.98\n",
       "...        ...      ...                ...       ...      ...         ...\n",
       "2934      2935     1211             Forest  19691.05 19691.05       65.05\n",
       "2935      2936     1211              Shrub  10476.18 10476.18       34.61\n",
       "2936      2937     1211           Wetlands    103.10   103.10        0.34\n",
       "2937      2938     1212             Forest   8402.58  8402.58       23.10\n",
       "2938      2939     1212              Shrub  27979.62 27979.62       76.90\n",
       "\n",
       "[2939 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.2f}'.format # only display 2 decimal places\n",
    "field_list = []\n",
    "for field in arcpy.ListFields(tab_int2):\n",
    "    field_list.append(field.name)\n",
    "tabint_arr = arcpy.da.TableToNumPyArray(tab_int2,field_list)\n",
    "df = pd.DataFrame(tabint_arr)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of unique land cover classes from tabulate intersection\n",
    " * All land cover types that are present in the study area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barren', 'Crops', 'Forest', 'Low intensity', 'Medium intensity', 'Open space', 'Pasture', 'Shrub', 'Water', 'Wetlands']\n"
     ]
    }
   ],
   "source": [
    "lancov = df['Land_Cover_Reclass'].unique()\n",
    "print (sorted(lancov))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape dataframe and set index\n",
    " * Easier to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Area_Sqm</th>\n",
       "      <th>PERCENTAGE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reachid</th>\n",
       "      <th>Land_Cover_Reclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">1</td>\n",
       "      <td>Forest</td>\n",
       "      <td>14627.22</td>\n",
       "      <td>26.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Shrub</td>\n",
       "      <td>7029.21</td>\n",
       "      <td>12.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Wetlands</td>\n",
       "      <td>33426.76</td>\n",
       "      <td>60.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">2</td>\n",
       "      <td>Forest</td>\n",
       "      <td>34313.47</td>\n",
       "      <td>95.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Shrub</td>\n",
       "      <td>1799.23</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">1211</td>\n",
       "      <td>Forest</td>\n",
       "      <td>19691.05</td>\n",
       "      <td>65.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Shrub</td>\n",
       "      <td>10476.18</td>\n",
       "      <td>34.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Wetlands</td>\n",
       "      <td>103.10</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">1212</td>\n",
       "      <td>Forest</td>\n",
       "      <td>8402.58</td>\n",
       "      <td>23.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Shrub</td>\n",
       "      <td>27979.62</td>\n",
       "      <td>76.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2939 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Area_Sqm  PERCENTAGE\n",
       "reachid Land_Cover_Reclass                      \n",
       "1       Forest              14627.22       26.55\n",
       "        Shrub                7029.21       12.76\n",
       "        Wetlands            33426.76       60.68\n",
       "2       Forest              34313.47       95.02\n",
       "        Shrub                1799.23        4.98\n",
       "...                              ...         ...\n",
       "1211    Forest              19691.05       65.05\n",
       "        Shrub               10476.18       34.61\n",
       "        Wetlands              103.10        0.34\n",
       "1212    Forest               8402.58       23.10\n",
       "        Shrub               27979.62       76.90\n",
       "\n",
       "[2939 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.drop([\"OBJECTID\",\"AREA\"],axis=1)\n",
    "df2 = df2.set_index([identifierfield,'Land_Cover_Reclass'])\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Dissolve to Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.set_option('display.max_columns', None)  \n",
    "# from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "# from arcgis import GIS\n",
    "# gis = GIS()\n",
    "# sdf = pd.DataFrame.spatial.from_featureclass(riv_nlcd_id_dis2)\n",
    "# sdf[[identifierfield,'Land_Cover_Reclass','Buff_Area_Sqm','Shape_Area_Sqm','Percent_Cover']].sort_values(by=[identifierfield])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot Tab Intersection table and join to rca reaches\n",
    " * Turn land cover classes stored in rows to fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete\n",
      "OBJECTID\n",
      "Shape\n",
      "reachid\n",
      "Shape_Length\n",
      "Z_Min\n",
      "Z_Max\n",
      "Z_Mean\n",
      "SLength\n",
      "reach_length\n",
      "reach_slope\n",
      "Forest\n",
      "Shrub\n",
      "Wetlands\n",
      "Riparian\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "pivname = region + \"Landcover_Pivot_Table\"\n",
    "tabpivot = arcpy.PivotTable_management(tab_int2,\"reachid\",\"Land_Cover_Reclass\",\"PERCENTAGE\",pivname)\n",
    "arcpy.JoinField_management(reachcopy,\"reachid\",tabpivot,\"reachid\",[\"Forest\",\"Shrub\",\"Wetlands\"])\n",
    "arcpy.AddField_management(reachcopy,\"Riparian\", 'TEXT',\"\",\"\",250,\"Percent riparian (forest + shrub) cover in 30 meter buffer surrounding reach\")\n",
    "\n",
    "fieldList = [\"Forest\",\"Shrub\",\"Wetlands\"]\n",
    "with arcpy.da.UpdateCursor(reachcopy, fieldList) as cursor:\n",
    "        for row in cursor:\n",
    "            Urow = row\n",
    "            for i in range (len(fieldList)):\n",
    "                if Urow[i] == None:\n",
    "                    Urow[i] = 0\n",
    "                \n",
    "            cursor.updateRow(Urow)\n",
    "\n",
    "print (\"Processing complete\")\n",
    "ripcalc = \"!Forest!+!Shrub!\"\n",
    "arcpy.CalculateField_management(reachcopy,\"Riparian\", ripcalc)\n",
    "\n",
    "for field in arcpy.ListFields(reachcopy):\n",
    "    print (field.name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Glacier layer and calculate percent cover by RCA - KENAI ONLY\n",
    " * Use <a href = \"http://glims.colorado.edu/glacierdata/\">GLIMS</a> for glacier data - may require manual download\n",
    "  * Large dataset that needs to be converted to feature class, projected, and clipped to study area\n",
    "    * Returned void poly error when initially clipped so these steps may resolve the issue.  Try repair geometry if it does not.\n",
    "    * Create a raster layer with 1 for glacier and 0 for no-glacier. Use the flow accumulation tool to get additive value for upstream contributing area for each RCA and then divide by flow accumulation value for each RCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "####add kenai glacier code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Rename Fields and delete unecessary joins\n",
    " * create dictionary to store oldname/new name alias combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcaDict = {'rca_id': ('rca_id', 'Unique ID associated with each reach contributing area (rca)'),\n",
    "'HUC12': ('HUC12', '12th digit hydrologic unit code associated with rca'),\n",
    "'Name': ('HUC_name', 'name of 12th digit hydrologic unit code associated with rca'),\n",
    "'K_r': ('K_r', 'Presence/absence of Chinook salmon rearing habitat in rca'),\n",
    "'K_s': ('K_s', 'Presence/absence of Chinook salmon spawning habitat in rca'),\n",
    "'K_p': ('K_p', 'Presence/absence of Chinook salmon in rca'),\n",
    "'CH_r': ('CH_r', 'Presence/absence of chum salmon rearing habitat in rca'),\n",
    "'CH_s': ('CH_s', 'Presence/absence of chum salmon spawning habitat in rca'),\n",
    "'CH_p': ('CH_p', 'Presence/absence of chum salmon in rca'),\n",
    "'CO_r': ('CO_r', 'Presence/absence of coho salmon rearing habitat in rca'),\n",
    "'CO_s': ('CO_s', 'Presence/absence of coho salmon spawning habitat in rca'),\n",
    "'CO_p': ('CO_p', 'Presence/absence of coho salmon in rca'),\n",
    "'P_r': ('P_r', 'Presence/absence of pink salmon rearing habitat in rca'),\n",
    "'P_s': ('P_s', 'Presence/absence of pink salmon spawning habitat in rca'),\n",
    "'P_p': ('P_p', 'Presence/absence of pink salmon in rca'),\n",
    "'S_r': ('S_r', 'Presence/absence of sockeye salmon rearing habitat in rca'),\n",
    "'S_s': ('S_s', 'Presence/absence of sockeye salmon spawning habitat in rca'),\n",
    "'S_p': ('S_p', 'Presence/absence of sockeye salmon in rca'),\n",
    "'MIN': ('rca_elev_min', 'Minimum rca elevation '),\n",
    "'MAX': ('rca_elev_max', 'Maximum rca elevation '),\n",
    "'MEAN': ('rca_elev_mn', 'Mean rca elevation '),\n",
    "'Flow_Accumulation': ('flowacc', 'Number of upstream cells draining to rca pour point'),\n",
    "'Mean_Elev_Contributing_Area': ('ca_elev_mn', 'Mean elevation of upstream contributing area draining to rca pour point')}\n",
    "\n",
    "reachDict = {'reachid': ('reach_id', 'Unique ID associated with each confluence to confluence reach '), 'Forest': ('Forest', 'Percent forest cover in 30 meter buffer surrounding reach'),\n",
    "                         'Shrub': ('Shrub', 'Percent shrub cover in 30 meter buffer surrounding reach'),\n",
    "                         'Wetlands': ('Wetland', 'Percent wetland cover in 30 meter buffer surrounding reach')}\n",
    "tempDict = {}\n",
    "outletDict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reach_id Unique ID associated with each confluence to confluence reach \n",
      "\n",
      "Forest Percent forest cover in 30 meter buffer surrounding reach\n",
      "\n",
      "Shrub Percent shrub cover in 30 meter buffer surrounding reach\n",
      "\n",
      "Wetland Percent wetland cover in 30 meter buffer surrounding reach\n",
      "\n",
      "rca_id Unique ID associated with each reach contributing area (rca)\n",
      "\n",
      "HUC12 12th digit hydrologic unit code associated with rca\n",
      "\n",
      "HUC_name name of 12th digit hydrologic unit code associated with rca\n",
      "\n",
      "K_r Presence/absence of Chinook salmon rearing habitat in rca\n",
      "\n",
      "K_s Presence/absence of Chinook salmon spawning habitat in rca\n",
      "\n",
      "K_p Presence/absence of Chinook salmon in rca\n",
      "\n",
      "CH_r Presence/absence of chum salmon rearing habitat in rca\n",
      "\n",
      "CH_s Presence/absence of chum salmon spawning habitat in rca\n",
      "\n",
      "CH_p Presence/absence of chum salmon in rca\n",
      "\n",
      "CO_r Presence/absence of coho salmon rearing habitat in rca\n",
      "\n",
      "CO_s Presence/absence of coho salmon spawning habitat in rca\n",
      "\n",
      "CO_p Presence/absence of coho salmon in rca\n",
      "\n",
      "P_r Presence/absence of pink salmon rearing habitat in rca\n",
      "\n",
      "P_s Presence/absence of pink salmon spawning habitat in rca\n",
      "\n",
      "P_p Presence/absence of pink salmon in rca\n",
      "\n",
      "S_r Presence/absence of sockeye salmon rearing habitat in rca\n",
      "\n",
      "S_s Presence/absence of sockeye salmon spawning habitat in rca\n",
      "\n",
      "S_p Presence/absence of sockeye salmon in rca\n",
      "\n",
      "rca_elev_min Minimum rca elevation \n",
      "\n",
      "rca_elev_max Maximum rca elevation \n",
      "\n",
      "rca_elev_mn Mean rca elevation \n",
      "\n",
      "flowacc Number of upstream cells draining to rca pour point\n",
      "\n",
      "ca_elev_mn Mean elevation of upstream contributing area draining to rca pour point\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for field in arcpy.ListFields(reachcopy):\n",
    "    keyval = field.name\n",
    "    if keyval in reachDict:\n",
    "        newname = reachDict[keyval][0]\n",
    "        newalias = reachDict[keyval][1]\n",
    "        \n",
    "        print (newname, newalias)\n",
    "        print (\"\")\n",
    "        \n",
    "        arcpy.AlterField_management(reachcopy, keyval, newname, newalias)\n",
    "\n",
    "for field in arcpy.ListFields(finalrca):       \n",
    "    keyval = field.name\n",
    "    if keyval in rcaDict:\n",
    "        newname = rcaDict[keyval][0]\n",
    "        newalias = rcaDict[keyval][1]\n",
    "\n",
    "        print (newname, newalias)\n",
    "        print(\"\")\n",
    "\n",
    "        arcpy.AlterField_management(finalrca, keyval, newname, newalias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete unecessary fields\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID\n",
      "Shape\n",
      "reach_id\n",
      "Shape_Length\n",
      "reach_length\n",
      "reach_slope\n",
      "Forest\n",
      "Shrub\n",
      "Wetland\n",
      "Riparian\n",
      "\n",
      "OBJECTID\n",
      "Shape\n",
      "rca_id\n",
      "Shape_Length\n",
      "Shape_Area\n",
      "HUC12\n",
      "HUC_name\n",
      "K_r\n",
      "K_s\n",
      "K_p\n",
      "CH_r\n",
      "CH_s\n",
      "CH_p\n",
      "CO_r\n",
      "CO_s\n",
      "CO_p\n",
      "P_r\n",
      "P_s\n",
      "P_p\n",
      "S_r\n",
      "S_s\n",
      "S_p\n",
      "rca_elev_min\n",
      "rca_elev_max\n",
      "rca_elev_mn\n",
      "flowacc\n",
      "ca_elev_mn\n"
     ]
    }
   ],
   "source": [
    "rcadrops = [\"Join_Count\",\"TARGET_FID\",\"pointid\",\"grid_code\",\"rca_id_1\"]\n",
    "reachdrops =[\"Z_Min\",\"Z_Max\",\"Z_Mean\",\"SLength\"] \n",
    "\n",
    "for field in rcadrops:\n",
    "    arcpy.DeleteField_management(finalrca,field)\n",
    "\n",
    "for field in reachdrops:\n",
    "    arcpy.DeleteField_management(reachcopy,field)\n",
    "\n",
    "for field in arcpy.ListFields(reachcopy):\n",
    "    \n",
    "    print (field.name)\n",
    "    \n",
    "print (\"\")\n",
    "\n",
    "for field in arcpy.ListFields(finalrca):\n",
    "    \n",
    "    print (field.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy to Network GDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "ExecuteError",
     "evalue": "Failed to execute. Parameters are not valid.\nERROR 002852: Output Feature Class: T:\\\\Aquatic\\\\KFHP\\\\Geodatabases\\\\Anchor.gdb\\anchor_rcas_temp_sites_attributed_06022020 exists within geodatabase as T:\\Aquatic\\KFHP\\Geodatabases\\Anchor.gdb\\Watersheds\\anchor_rcas_temp_sites_attributed_06022020\nFailed to execute (CopyFeatures).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mExecuteError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-f202a556a01d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexportfcs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdesc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCopyFeatures_management\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdesc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mreachdesc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreachcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\management.py\u001b[0m in \u001b[0;36mCopyFeatures\u001b[1;34m(in_features, out_feature_class, config_keyword, spatial_grid_1, spatial_grid_2, spatial_grid_3)\u001b[0m\n\u001b[0;32m   3230\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3231\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3232\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3234\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mgptooldoc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DeleteFeatures_management'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\management.py\u001b[0m in \u001b[0;36mCopyFeatures\u001b[1;34m(in_features, out_feature_class, config_keyword, spatial_grid_1, spatial_grid_2, spatial_grid_3)\u001b[0m\n\u001b[0;32m   3227\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0marcpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marcobjects\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marcobjectconversion\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconvertArcObjectToPythonObject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3228\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3229\u001b[1;33m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvertArcObjectToPythonObject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCopyFeatures_management\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgp_fixargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_feature_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig_keyword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspatial_grid_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspatial_grid_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspatial_grid_3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3230\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3231\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\ArcGIS\\Pro\\Resources\\ArcPy\\arcpy\\geoprocessing\\_base.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mgp_fixargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mconvertArcObjectToPythonObject\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mExecuteError\u001b[0m: Failed to execute. Parameters are not valid.\nERROR 002852: Output Feature Class: T:\\\\Aquatic\\\\KFHP\\\\Geodatabases\\\\Anchor.gdb\\anchor_rcas_temp_sites_attributed_06022020 exists within geodatabase as T:\\Aquatic\\KFHP\\Geodatabases\\Anchor.gdb\\Watersheds\\anchor_rcas_temp_sites_attributed_06022020\nFailed to execute (CopyFeatures).\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = networkgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "spref = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "exportfcs= []\n",
    "exportfcs = [tempfinal,finalrca,outcopy]\n",
    "\n",
    "for fc in exportfcs:\n",
    "    desc = arcpy.Describe(fc)\n",
    "    arcpy.CopyFeatures_management(fc,desc.name)\n",
    "reachdesc = arcpy.Describe(reachcopy)\n",
    "\n",
    "reachcopyname = reachdesc.name + \"_attributed_\" + str(time_stamp)\n",
    "arcpy.CopyFeatures_management(reachcopy,reachcopyname)\n",
    "\n",
    "print (\"copy complete\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
