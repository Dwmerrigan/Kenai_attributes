{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## </a>Jump to [bottom](#bottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RCA fish species and Temperature site attributes\n",
    " * Add HUC 12 and elevation data to temperature sites\n",
    " * Add AWC species and Northern pike data to RCA\n",
    "  * all life stages/categories\n",
    " * Elevation stats for all RCAs\n",
    "   * Mean min max\n",
    "   * Mean elevation of contributing area\n",
    " * Percent Glacier cover calculation along flow acc network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules and set environments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07022020\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\n"
     ]
    }
   ],
   "source": [
    "import arcpy, os, zipfile, requests, datetime, sys, time, traceback\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "from datetime import datetime\n",
    "today = datetime.now()\n",
    "#Make the time stamp.  \n",
    "time_stamp = '{:%d%m%Y}'.format(today)\n",
    "print(time_stamp)\n",
    "path = os.getcwd() # temporary working directories and geodatabases will be created here\n",
    "print (path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set variables\n",
    " * All input data are stored on the T: so no local data are needed\n",
    "  * Temporary working directors are created in the current working directory listed above\n",
    "    * Set path = \"desired working folder\" if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables set on 2020-02-07 16:21:51.249202\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "### Variable Names/identifiers ###\n",
    "\n",
    "region = \"Kenai\" #region of interest - used to name temporary directories\n",
    "outgdbname = region + \".gdb\" #Name of output gdb\n",
    "outdirname = region + \"_Attributes_\" #Location to save outputs\n",
    "identifierfield = \"reachid\" #Name of field storing Catchment/RCA field in input stream layer ex. NHDPlus = \"NHDPLusID\", rca streams = \"reachid\"\n",
    "\n",
    "### Network Data ###\n",
    "\n",
    "instudy =  r\"T:\\\\Aquatic\\\\KFHP\\\\Landscape_Metrics_DM\\\\Kenai\\\\Source_Data\\\\Kenai_Source.gdb\\\\kenai_studyarea\" #Polygon defining study area, used to extract nlcd raster\n",
    "instreams = r\"T:\\\\Aquatic\\\\KFHP\\\\Landscape_Metrics_DM\\\\Kenai\\\\Source_Data\\\\Kenai_Source.gdb\\\\kenai_rca_reaches\" #Streams with RCA code\n",
    "inrca =  r\"T:\\\\Aquatic\\\\KFHP\\\\Landscape_Metrics_DM\\\\Kenai\\\\Source_Data\\\\Kenai_Source.gdb\\\\kenai_rcas\" #RCAs for region of interest\n",
    "awc_events = \"T:\\\\Aquatic\\\\KFHP\\\\AWC\\\\2018\\\\2018GDB_statewide.gdb\\\\awcEventArcs\" # AWC events \n",
    "tempsites = \"T:\\\\Aquatic\\\\KFHP\\\\Landscape_Metrics_DM\\\\Kenai\\\\Source_Data\\\\Kenai_Source.gdb\\\\tempsites_Kenai\" # Temperature locations\n",
    "huc12 = r\"T:\\\\Aquatic\\\\KFHP\\\\Landscape_Metrics_DM\\\\Kenai\\\\Source_Data\\\\WBDHU12.shp\" # HUC12 from NHD gdb\n",
    "\n",
    "#flowrast =  r\"T:\\\\Aquatic\\\\KFHP\\\\Landscape_Metrics_DM\\\\Kenai\\\\Source_Data\\\\Kenai_StrBrn_ad8ContribArea.tif\" #flow accumulation raster for region of interest \n",
    "flowdirrast =  r\"T:\\\\Aquatic\\\\KFHP\\\\Landscape_Metrics_DM\\\\Kenai\\\\Source_Data\\\\Kenai_StrBrn_d8flowdir.tif\" #flow direction raster for region of interest\n",
    "dem = \"T:\\\\Aquatic\\\\KFHP\\\\TauDEM_Outputs\\\\Kenai\\\\Tau_out\\\\Kenai_StrBrn_2Int.tif\" #DEM converted to Integer that matches extent and cell size of flow dir\n",
    "orig_streamrast = r\"T:\\\\Aquatic\\\\KFHP\\\\Landscape_Metrics_DM\\\\Kenai\\\\Source_Data\\\\Kenai_StrBrn_src.tif\" #stream grid from synthetic stream network\n",
    "\n",
    "identname = region + \"_NLCD_Identity\"#name of output Identity\n",
    "tabtablename = region + \"_NLCD_Tab_Int\"#Name for output tabulate intersection table\n",
    "\n",
    "#### Final product output location ####\n",
    "networkgdb = r'T:\\\\Aquatic\\\\KFHP\\\\Geodatabases\\\\Kenai.gdb' # Location of shared geodatabase on network for final products\n",
    "networkgdbfd = r'T:\\\\Aquatic\\\\KFHP\\\\Geodatabases\\\\Kenai.gdb\\\\Hydrology' # location of Hydrology feature dataset \n",
    "\n",
    "### Generated variables ###\n",
    "\n",
    "streamdesc = arcpy.Describe(instreams)\n",
    "streams_name = streamdesc.name\n",
    "studydesc = arcpy.Describe(instudy)\n",
    "study_name = studydesc.name\n",
    "identname = streams_name + \"_NLCD_Identity\"#name of output Identity\n",
    "tabtablename = streams_name + \"_NLCD_Tab_Int\"#Name for output tabulate intersection table\n",
    "\n",
    "time = datetime.datetime.now()\n",
    "print (\"Variables set on\", time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create temporary folder and gdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating output GDB\n",
      "Output geodatabase created at C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenai.gdb\n"
     ]
    }
   ],
   "source": [
    "dirname = outdirname + str(time_stamp)\n",
    "temp_dir = os.path.join(path,dirname)\n",
    "ziploc = os.path.join(temp_dir, 'zips')\n",
    "extractloc = os.path.join(temp_dir, 'extracts')\n",
    "\n",
    "if not os.path.exists(temp_dir):\n",
    "    os.makedirs(temp_dir)\n",
    "    os.makedirs(ziploc)\n",
    "    os.makedirs(extractloc)        \n",
    "\n",
    "\n",
    "outcheck = os.path.join(temp_dir,outgdbname)\n",
    "\n",
    "if os.path.exists(outcheck):\n",
    "    print ('Output location already exists', outcheck)\n",
    "    outgdb = outcheck\n",
    "if not os.path.exists(outcheck):\n",
    "    print('Creating output GDB')\n",
    "    tempgdb = arcpy.CreateFileGDB_management(temp_dir,outgdbname)\n",
    "    print ('Output geodatabase created at',outcheck)\n",
    "    outgdb = tempgdb.getOutput(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T:\\\\\\\\Aquatic\\\\\\\\KFHP\\\\\\\\Landscape_Metrics_DM\\\\\\\\Kenai\\\\\\\\Source_Data\\\\\\\\Kenai_Source.gdb\\\\kenai_studyarea', 'T:\\\\\\\\Aquatic\\\\\\\\KFHP\\\\\\\\Landscape_Metrics_DM\\\\\\\\Kenai\\\\\\\\Source_Data\\\\\\\\Kenai_Source.gdb\\\\kenai_rca_reaches', 'T:\\\\\\\\Aquatic\\\\\\\\KFHP\\\\\\\\Landscape_Metrics_DM\\\\\\\\Kenai\\\\\\\\Source_Data\\\\\\\\Kenai_Source.gdb\\\\kenai_rcas', 'T:\\\\Aquatic\\\\KFHP\\\\Landscape_Metrics_DM\\\\Kenai\\\\Source_Data\\\\Kenai_Source.gdb\\\\tempsites_Kenai', 'T:\\\\Aquatic\\\\KFHP\\\\AWC\\\\2018\\\\2018GDB_statewide.gdb\\\\awcEventArcs']\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "indata = []\n",
    "copylist = []\n",
    "indata = [instudy,instreams,inrca,tempsites,awc_events]\n",
    "\n",
    "studdesc = arcpy.Describe(instudy)\n",
    "arcpy.CopyFeatures_management(instudy,studdesc.name)\n",
    "studycopy = os.path.join(studdesc.path,studdesc.name)\n",
    "copylist.append(studycopy)\n",
    "\n",
    "reachdesc = studdesc = arcpy.Describe(instreams)\n",
    "arcpy.CopyFeatures_management(instreams,reachdesc.name)\n",
    "reachcopy = os.path.join(reachdesc.path,reachdesc.name)\n",
    "copylist.append(reachcopy)\n",
    "\n",
    "rcadesc = arcpy.Describe(inrca)\n",
    "arcpy.CopyFeatures_management(inrca,rcadesc.name)\n",
    "rcacopy = os.path.join(rcadesc.path,rcadesc.name)\n",
    "copylist.append(rcacopy)\n",
    "\n",
    "tempdesc = arcpy.Describe(tempsites)\n",
    "arcpy.CopyFeatures_management(tempsites,tempdesc.name)\n",
    "tempcopy = os.path.join(tempdesc.path,tempdesc.name)\n",
    "copylist.append(tempcopy)\n",
    "\n",
    "awcdesc = arcpy.Describe(awc_events)\n",
    "arcpy.CopyFeatures_management(awc_events,awcdesc.name)\n",
    "awccopy = os.path.join(awcdesc.path,awcdesc.name)\n",
    "copylist.append(awccopy)   \n",
    "\n",
    "print (copylist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin Geospatial operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join HUC12 data to RCA\n",
    "     * Format RCAs\n",
    "      * Drop all fields other than rca_id\n",
    "      * Recalculate elevation (min-mean-max)\n",
    "      * Recalculate contributing area\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Largest overlap Spatial Join\n",
    " * code from <a href = \"https://www.arcgis.com/home/item.html?id=e9cccd343bf84916bda1910c31e5eab2\">Largest Overlap</a>\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function, all functions run in SpatialJoinOverlapsCrossings\n",
    "def SpatialJoinLargestOverlap(target_features, join_features, out_fc, keep_all, spatial_rel):\n",
    "    if spatial_rel == \"largest_overlap\":\n",
    "        # Calculate intersection between Target Feature and Join Features\n",
    "        intersect = arcpy.analysis.Intersect([target_features, join_features], \"in_memory/intersect\", \"ONLY_FID\")\n",
    "        # Find which Join Feature has the largest overlap with each Target Feature\n",
    "        # Need to know the Target Features shape type, to know to read the SHAPE_AREA oR SHAPE_LENGTH property\n",
    "        geom = \"AREA\" if arcpy.Describe(target_features).shapeType.lower() == \"polygon\" and arcpy.Describe(join_features).shapeType.lower() == \"polygon\" else \"LENGTH\"\n",
    "        fields = [\"FID_{0}\".format(os.path.splitext(os.path.basename(target_features))[0]),\n",
    "                  \"FID_{0}\".format(os.path.splitext(os.path.basename(join_features))[0]),\n",
    "                  \"SHAPE@{0}\".format(geom)]\n",
    "        overlap_dict = {}\n",
    "        with arcpy.da.SearchCursor(intersect, fields) as scur:\n",
    "            for row in scur:\n",
    "                try:\n",
    "                    if row[2] > overlap_dict[row[0]][1]:\n",
    "                        overlap_dict[row[0]] = [row[1], row[2]]\n",
    "                except:\n",
    "                    overlap_dict[row[0]] = [row[1], row[2]]\n",
    "\n",
    "        # Copy the target features and write the largest overlap join feature ID to each record\n",
    "        # Set up all fields from the target features + ORIG_FID\n",
    "        fieldmappings = arcpy.FieldMappings()\n",
    "        fieldmappings.addTable(target_features)\n",
    "        fieldmap = arcpy.FieldMap()\n",
    "        fieldmap.addInputField(target_features, arcpy.Describe(target_features).OIDFieldName)\n",
    "        fld = fieldmap.outputField\n",
    "        fld.type, fld.name, fld.aliasName = \"LONG\", \"ORIG_FID\", \"ORIG_FID\"\n",
    "        fieldmap.outputField = fld\n",
    "        fieldmappings.addFieldMap(fieldmap)\n",
    "        # Perform the copy\n",
    "        arcpy.conversion.FeatureClassToFeatureClass(target_features, os.path.dirname(out_fc), os.path.basename(out_fc), \"\", fieldmappings)\n",
    "        # Add a new field JOIN_FID to contain the fid of the join feature with the largest overlap\n",
    "        arcpy.management.AddField(out_fc, \"JOIN_FID\", \"LONG\")\n",
    "        # Calculate the JOIN_FID field\n",
    "        with arcpy.da.UpdateCursor(out_fc, [\"ORIG_FID\", \"JOIN_FID\"]) as ucur:\n",
    "            for row in ucur:\n",
    "                try:\n",
    "                    row[1] = overlap_dict[row[0]][0]\n",
    "                    ucur.updateRow(row)\n",
    "                except:\n",
    "                    if not keep_all:\n",
    "                        ucur.deleteRow()\n",
    "        # Join all attributes from the join features to the output\n",
    "        joinfields = [x.name for x in arcpy.ListFields(join_features) if not x.required]\n",
    "        arcpy.management.JoinField(out_fc, \"JOIN_FID\", join_features, arcpy.Describe(join_features).OIDFieldName, joinfields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID\n",
      "Shape\n",
      "rca_id\n",
      "Shape_Length\n",
      "Shape_Area\n",
      "HUC12\n",
      "Name\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "hucjoinname = region + \"_rca_huc12_largeover_sj\"\n",
    "huccjoin = SpatialJoinLargestOverlap(rcacopy, huc12, hucjoinname, keep_all = \"TRUE\", spatial_rel = \"largest_overlap\" ) #Code from ESRI \n",
    "\n",
    "joindrop = []\n",
    "\n",
    "awcjoin = os.path.join(outgdb+ \"\\\\\" + hucjoinname)\n",
    "\n",
    "for field in arcpy.ListFields(awcjoin):\n",
    "    joindrop.append(field.name)\n",
    "\n",
    "keepfields = ['OBJECTID', 'Shape', 'rca_id','Shape_Length', 'Shape_Area','HUC12','Name']\n",
    "for field in keepfields:   \n",
    "    joindrop.remove(field)\n",
    "\n",
    "arcpy.DeleteField_management(awcjoin, joindrop)\n",
    "\n",
    "for field in arcpy.ListFields(awcjoin):\n",
    "    print (field.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove all fields from reaches except reach id and shape fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OBJECTID_1', 'Shape', 'OBJECTID', 'Id', 'Shape_Leng', 'rid', 'reachid', 'Z_Min', 'Z_Max', 'Z_Mean', 'SLength', 'slope_P', 'slope_D', 'Shape_Length']\n",
      "\n",
      "OBJECTID_1\n",
      "Shape\n",
      "OBJECTID\n",
      "reachid\n",
      "Shape_Length\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "reachfields = []\n",
    "for field in arcpy.ListFields(reachcopy):\n",
    "    reachfields.append(field.name)\n",
    "\n",
    "print (reachfields)\n",
    "print (\"\")\n",
    "\n",
    "keepfields = ['OBJECTID','OBJECTID_1', 'Shape', 'reachid','Shape_Length']\n",
    "for field in keepfields:   \n",
    "    reachfields.remove(field)\n",
    "\n",
    "arcpy.DeleteField_management(reachcopy, reachfields)\n",
    "\n",
    "for field in arcpy.ListFields(reachcopy):\n",
    "    print (field.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fish data\n",
    " * Join 5 salmon species and with lifestage data to each RCA\n",
    "  * Format needs to be 3 columns for each species Spec/Lstag\n",
    "  \n",
    " * Identity awc with rca first then spatial join and concatenate or selectby and populate fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity awc with rca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenai.gdb\\Kenai_awc_rca_IDENTITY\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "awcidentname = region + \"_awc_rca_IDENTITY\"\n",
    "awcclip = arcpy.Clip_analysis(awccopy,awcjoin,\"tempclip\")\n",
    "awcident = arcpy.Identity_analysis(awcclip,awcjoin,awcidentname,\"ALL\")\n",
    "\n",
    "print (awcident)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add fish species/life stage fields and delete join fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K_r', 'K_s', 'K_p', 'CH_r', 'CH_s', 'CH_p', 'CO_r', 'CO_s', 'CO_p', 'P_r', 'P_s', 'P_p', 'S_r', 'S_s', 'S_p']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\Watershed_Attributes\\\\Kenai\\\\Kenai_attributes\\\\Kenai_Attributes_07022020\\\\Kenai.gdb\\\\Kenai_rca_huc12_largeover_sj'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "lifestages = ['r','s','p']\n",
    "species = ['K','CH','CO','P','S']\n",
    "cols = []\n",
    "for s in species:\n",
    "    for l in lifestages:\n",
    "        colname = str(s) + \"_\" + str(l)\n",
    "        cols.append(colname)\n",
    "print(cols)\n",
    "\n",
    "for field in cols:\n",
    "    arcpy.AddField_management(awcjoin,field,\"SHORT\") #add awcfields to rcas\n",
    "\n",
    "deletefields = ['Join_Count','TARGET_FID','Join_Count_1','TARGET_FID_1','JOIN_FID']\n",
    "arcpy.DeleteField_management(awcjoin,deletefields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query AWC events and calculate presence, spawning, and rearing attributes for RCAs from AWC/RCA identity\n",
    " * SPECIES\n",
    "  * K: CHINOOK\n",
    "  * CH: CHUM\n",
    "  * CO: COHO\n",
    "  * P: PINK\n",
    "  * S: SOCKEYE\n",
    " \n",
    " \n",
    " * LIFE STAGE\n",
    "  * r: rearing\n",
    "  * s: spawning\n",
    "  * p: presence - Presence has been calculated such that p = 1 where present or rearing or spawning as recorded in AWC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start script: 2020-02-07 15:44:32\n",
      "End script: 2020-02-07 15:44:45 Runtime = 0:00:13.009900\n"
     ]
    }
   ],
   "source": [
    "from time import strftime\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "print( \"Start script: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "fields = ['K_r', 'K_s', 'K_p', 'CH_r', 'CH_s', 'CH_p', 'CO_r', 'CO_s', 'CO_p', 'P_r', 'P_s', 'P_p', 'S_r', 'S_s', 'S_p']\n",
    "\n",
    "### Chinook Selections ###\n",
    "# \"SPECIES = 'K' And LSTAGE = 'r' OR SPECIES = 'K' And LSTAGE = 's' OR SPECIES = 'K' And LSTAGE = 'p'\" # Modify presence to include all\n",
    "\n",
    "akr = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'K' And LSTAGE = 'r'\")\n",
    "rkr = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', akr)\n",
    "arcpy.CalculateField_management(rkr,'K_r', 1)\n",
    "\n",
    "aks = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'K' And LSTAGE = 's'\")\n",
    "rks = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', aks)\n",
    "arcpy.CalculateField_management(rks,'K_s', 1)\n",
    "\n",
    "akp = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'K' And LSTAGE = 'r' OR SPECIES = 'K' And LSTAGE = 's' OR SPECIES = 'K' And LSTAGE = 'p'\")\n",
    "rkp = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', akp)\n",
    "arcpy.CalculateField_management(rkp,'K_p', 1)\n",
    "\n",
    "### Chum Selections ###\n",
    "achr = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'CH' And LSTAGE = 'r'\")\n",
    "rchr = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', achr)\n",
    "arcpy.CalculateField_management(rchr,'CH_r', 1)\n",
    "\n",
    "achs = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'CH' And LSTAGE = 's'\")\n",
    "rchs = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', achs)\n",
    "arcpy.CalculateField_management(rchs,'CH_s', 1)\n",
    "\n",
    "achp = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'CH' And LSTAGE = 'r' OR SPECIES = 'CH' And LSTAGE = 's' OR SPECIES = 'CH' And LSTAGE = 'p'\")\n",
    "rchp = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', achp)\n",
    "arcpy.CalculateField_management(rchp,'CH_p', 1)\n",
    "\n",
    "### Coho Selection ###\n",
    "acor = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'CO' And LSTAGE = 'r'\")\n",
    "rcor = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', acor)\n",
    "arcpy.CalculateField_management(rcor,'CO_r', 1)\n",
    "\n",
    "acos = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'CO' And LSTAGE = 's'\")\n",
    "rcos = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', acos)\n",
    "arcpy.CalculateField_management(rcos,'CO_s', 1)\n",
    "\n",
    "acop = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'CO' And LSTAGE = 'r' OR SPECIES = 'CO' And LSTAGE = 's' OR SPECIES = 'CO' And LSTAGE = 'p'\")\n",
    "rcop = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', acop)\n",
    "arcpy.CalculateField_management(rcop,'CO_p', 1)\n",
    "\n",
    "### Pink Selection ###\n",
    "apr = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'P' And LSTAGE = 'r'\")\n",
    "rpr = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', apr)\n",
    "arcpy.CalculateField_management(rpr,'P_r', 1)\n",
    "\n",
    "aps = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'P' And LSTAGE = 's'\")\n",
    "rps = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', aps)\n",
    "arcpy.CalculateField_management(rps,'P_s', 1)\n",
    "\n",
    "app = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'P' And LSTAGE = 'r' OR SPECIES = 'P' And LSTAGE = 's' OR SPECIES = 'P' And LSTAGE = 'p'\")\n",
    "rpp = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', app)\n",
    "arcpy.CalculateField_management(rpp,'P_p', 1)\n",
    "\n",
    "### Sockeye Selection ###\n",
    "asr = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'S' And LSTAGE = 'r'\")\n",
    "rsr = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', asr)\n",
    "arcpy.CalculateField_management(rsr,'S_r', 1)\n",
    "\n",
    "ass = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'S' And LSTAGE = 's'\")\n",
    "rss = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', ass)\n",
    "arcpy.CalculateField_management(rss,'S_s', 1)\n",
    "\n",
    "asp = arcpy.SelectLayerByAttribute_management(awcident, \"NEW_SELECTION\", \"SPECIES = 'S' And LSTAGE = 'r' OR SPECIES = 'S' And LSTAGE = 's' OR SPECIES = 'S' And LSTAGE = 'p'\")\n",
    "rsp = arcpy.SelectLayerByLocation_management(awcjoin,'CONTAINS_CLEMENTINI', asp)\n",
    "arcpy.CalculateField_management(rsp,'S_p', 1)\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "print( \"End script: \" + strftime(\"%Y-%m-%d %H:%M:%S\") + \" Runtime = \" +  str(elapsed))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert null values in fish species columns to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "fieldList =  fields\n",
    "with arcpy.da.UpdateCursor(awcjoin, fieldList) as cursor:\n",
    "    fRange = range(len(fieldList)) # create an index 0 to the number of elements in fieldList - 1\n",
    "\n",
    "    for row in cursor:\n",
    "        \n",
    "\n",
    "        # step through each field in the row by its index\n",
    "        for index in fRange:\n",
    "            if row[index] == None:\n",
    "                row[index] = 0         #set null to zero\n",
    "            \n",
    "            \n",
    "            cursor.updateRow(row)\n",
    "\n",
    "print (\"Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reclassify Tau DEM flow direction to work with ESRI Flowaccumulation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Esri_flowdir](https://user-images.githubusercontent.com/36055691/74059969-7891d780-4995-11ea-9eeb-2ab8f31dbb31.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin process 2020-02-07 15:44:48.042993\n",
      "Kenai_StrBrn_d8flowdir.tif\n",
      "Process complete  0:00:24.181861\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenai_StrBrn_d8flowdir.tif\n"
     ]
    }
   ],
   "source": [
    "import arcpy\n",
    "from arcpy.sa import *\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "start= datetime.datetime.now()\n",
    "print (\"Begin process\", start)\n",
    "\n",
    "arcpy.env.workspace = temp_dir\n",
    "arcpy.env.overwriteOutput = True\n",
    "spref = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "arcpy.env.outputCoordinateSystem = spref\n",
    "\n",
    "\n",
    "rastdesc2 = arcpy.Describe(flowdirrast)\n",
    "print (rastdesc2.name)\n",
    "rastname2 = rastdesc2.name\n",
    "flowdircopy = Reclassify(flowdirrast, \"Value\", RemapValue([[1,1],[2,128],[3,64],[4,32],[5,16],[6,8],[7,4],[8,2]]))\n",
    "flowdircopy.save(rastname2)\n",
    "flowdirscribe = arcpy.Describe(flowdircopy)\n",
    "flowdirpath = os.path.join(flowdirscribe.path, flowdirscribe.name)\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "print (\"Process complete \", elapsed)\n",
    "print (flowdirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy Integer DEM from TauDEM to local\n",
    " * outputs from TauDEM have Cellsize slightly smaller than original DEM source raster\n",
    "   * This happened during the conversion of the orignal DEM from float to Integer\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processes Complete\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = temp_dir\n",
    "arcpy.env.snapRaster = flowdirpath\n",
    "arcpy.env.extent = flowdirpath\n",
    "arcpy.env.cellsize = flowdirpath\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "demdescribe = arcpy.Describe(dem)\n",
    "demname = temp_dir + \"\\\\\" + demdescribe.name\n",
    "dem_copy = ExtractByMask(dem, flowdirpath)\n",
    "dem_copy.save(demname)\n",
    "\n",
    "print (\"Processes Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract stream src by reclassified flow dir\n",
    " * Probably unecessary but going to leave in for now to make sure all rasters are aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction Complete\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = temp_dir\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "arcpy.env.snapRaster = flowdirpath\n",
    "arcpy.env.extent = flowdirpath\n",
    "\n",
    "streamdescribe = arcpy.Describe(orig_streamrast)\n",
    "streamname = temp_dir + \"\\\\\" + streamdescribe.name\n",
    "streamrast = ExtractByMask(orig_streamrast, flowdirpath)\n",
    "streamrast.save(streamname)\n",
    "\n",
    "print (\"Extraction Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check rasters\n",
    " * Compare extent, cellsize, projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster name:      Kenai_StrBrn_src.tif\n",
      "Projection:      NAD_1983_Alaska_Albers\n",
      "Compression Type: LZW\n",
      "Raster Format:    TIFF\n",
      "Height: 18755\n",
      "Width:  27650\n",
      "Cellsize:  5.000000\n",
      "Integer Raster: True\n",
      "Raster stats: min = 0.00 max = 1.00 mean = 0.01\n",
      "147477.63147271 1116160.30748062 285727.63147271 1209935.30748062 NaN NaN NaN NaN\n",
      "\n",
      "Raster name:      Kenai_StrBrn_d8flowdir.tif\n",
      "Projection:      NAD_1983_Alaska_Albers\n",
      "Compression Type: LZW\n",
      "Raster Format:    TIFF\n",
      "Height: 18755\n",
      "Width:  27650\n",
      "Cellsize:  5.000000\n",
      "Integer Raster: True\n",
      "Raster stats: min = 1.00 max = 128.00 mean = 33.07\n",
      "147477.63147271 1116160.30748062 285727.63147271 1209935.30748062 NaN NaN NaN NaN\n",
      "\n",
      "Raster name:      Kenai_StrBrn_2Int.tif\n",
      "Projection:      NAD_1983_Alaska_Albers\n",
      "Compression Type: LZW\n",
      "Raster Format:    TIFF\n",
      "Height: 18755\n",
      "Width:  27650\n",
      "Cellsize:  5.000000\n",
      "Integer Raster: True\n",
      "Raster stats: min = 0.00 max = 1,974.00 mean = 521.31\n",
      "147477.63147271 1116160.30748062 285727.63147271 1209935.30748062 NaN NaN NaN NaN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rastlist = [streamrast, flowdirpath, dem_copy]\n",
    "for raster in rastlist:\n",
    "    desc = arcpy.Describe(raster)\n",
    "\n",
    "    \n",
    "    raster_min = arcpy.Raster(raster).minimum\n",
    "    raster_max = arcpy.Raster(raster).maximum\n",
    "    raster_mean = arcpy.Raster(raster).mean\n",
    "    extent = arcpy.Raster(raster).extent\n",
    "    \n",
    "    print(\"Raster name:      %s\" % desc.name)\n",
    "    print(\"Projection:      %s\" % desc.SpatialReference.name)\n",
    "    print(\"Compression Type: %s\" % desc.compressionType)\n",
    "    print(\"Raster Format:    %s\" % desc.format)\n",
    "    print(\"Height: %d\" % desc.height)\n",
    "    print(\"Width:  %d\" % desc.width)\n",
    "    print(\"Cellsize:  %f\" % desc.meanCellHeight)\n",
    "    print(\"Integer Raster: %s\" % desc.isInteger)\n",
    "    print(\"Raster stats: min = {:,.2f} max = {:,.2f} mean = {:,.2f}\".format(raster_min,raster_max,raster_mean))\n",
    "    print (extent)\n",
    "    print (\"\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Elevation data from DEM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start script: 2020-02-07 15:48:40\n",
      "\n",
      "Calculating zonal statistics\n",
      "\n",
      "Time to complete =  0:00:00.013962\n",
      "\n",
      "Joining statistics to RCAs\n",
      "\n",
      "Time to complete =  0:00:22.530401\n"
     ]
    }
   ],
   "source": [
    "from arcpy.sa import *\n",
    "start = datetime.datetime.now()\n",
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "print( \"Start script: \" + strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print (\"\")\n",
    "\n",
    "tablename = region + \"_DEM_Zonal_Table\"\n",
    "\n",
    "print (\"Calculating zonal statistics\")\n",
    "print(\"\")\n",
    "\n",
    "stop = datetime.datetime.now()  \n",
    "elapsed = stop - start  \n",
    "\n",
    "print ('Time to complete = ',elapsed)\n",
    "print(\"\")\n",
    "\n",
    "ztable = ZonalStatisticsAsTable(awcjoin, 'OBJECTID', dem_copy, tablename, 'DATA', 'MIN_MAX_MEAN')\n",
    "\n",
    "print (\"Joining statistics to RCAs\")\n",
    "print(\"\")\n",
    "\n",
    "arcpy.JoinField_management(awcjoin, 'OBJECTID', ztable, 'OBJECTID_1', ['MIN','MAX','MEAN'])\n",
    "\n",
    "\n",
    "stop = datetime.datetime.now()  \n",
    "elapsed = stop - start  \n",
    "print ('Time to complete = ',elapsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>rca_id</th>\n",
       "      <th>HUC12</th>\n",
       "      <th>Name</th>\n",
       "      <th>K_r</th>\n",
       "      <th>K_s</th>\n",
       "      <th>K_p</th>\n",
       "      <th>CH_r</th>\n",
       "      <th>CH_s</th>\n",
       "      <th>CH_p</th>\n",
       "      <th>CO_r</th>\n",
       "      <th>CO_s</th>\n",
       "      <th>CO_p</th>\n",
       "      <th>P_r</th>\n",
       "      <th>P_s</th>\n",
       "      <th>P_p</th>\n",
       "      <th>S_r</th>\n",
       "      <th>S_s</th>\n",
       "      <th>S_p</th>\n",
       "      <th>MIN</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MEAN</th>\n",
       "      <th>SHAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>190203021001</td>\n",
       "      <td>Headwaters Trail Creek</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>231</td>\n",
       "      <td>227.496154</td>\n",
       "      <td>{'rings': [[[267552.6314670332, 1187445.307535...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>190203021001</td>\n",
       "      <td>Headwaters Trail Creek</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>261</td>\n",
       "      <td>307</td>\n",
       "      <td>272.822581</td>\n",
       "      <td>{'rings': [[[268957.6314515844, 1189145.307505...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>190203021001</td>\n",
       "      <td>Headwaters Trail Creek</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>265</td>\n",
       "      <td>438</td>\n",
       "      <td>300.738371</td>\n",
       "      <td>{'rings': [[[269757.6314552445, 1189390.307459...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>190203021602</td>\n",
       "      <td>Middle Moose River</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>76</td>\n",
       "      <td>57.763341</td>\n",
       "      <td>{'rings': [[[187427.63152244315, 1188305.30747...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>190203021607</td>\n",
       "      <td>Muskrat Lake</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>84</td>\n",
       "      <td>74.382605</td>\n",
       "      <td>{'rings': [[[193722.63148560934, 1195020.30750...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  rca_id         HUC12                    Name  K_r  K_s  K_p  \\\n",
       "0         1     1.0  190203021001  Headwaters Trail Creek    0    0    0   \n",
       "1         2     2.0  190203021001  Headwaters Trail Creek    0    0    0   \n",
       "2         3     3.0  190203021001  Headwaters Trail Creek    0    0    0   \n",
       "3         4     5.0  190203021602      Middle Moose River    0    0    0   \n",
       "4         5     6.0  190203021607            Muskrat Lake    0    0    0   \n",
       "\n",
       "   CH_r  CH_s  CH_p  CO_r  CO_s  CO_p  P_r  P_s  P_p  S_r  S_s  S_p  MIN  MAX  \\\n",
       "0     0     0     0     0     0     0    0    0    0    0    0    0  224  231   \n",
       "1     0     0     0     0     0     0    0    0    0    0    0    0  261  307   \n",
       "2     0     0     0     0     0     0    0    0    0    0    0    0  265  438   \n",
       "3     0     0     0     0     1     1    0    0    0    0    0    0   54   76   \n",
       "4     0     0     0     0     0     0    0    0    0    0    0    0   64   84   \n",
       "\n",
       "         MEAN                                              SHAPE  \n",
       "0  227.496154  {'rings': [[[267552.6314670332, 1187445.307535...  \n",
       "1  272.822581  {'rings': [[[268957.6314515844, 1189145.307505...  \n",
       "2  300.738371  {'rings': [[[269757.6314552445, 1189390.307459...  \n",
       "3   57.763341  {'rings': [[[187427.63152244315, 1188305.30747...  \n",
       "4   74.382605  {'rings': [[[193722.63148560934, 1195020.30750...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)  \n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "from arcgis import GIS\n",
    "gis = GIS()\n",
    "sdf = pd.DataFrame.spatial.from_featureclass(awcjoin)\n",
    "sdf.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify outlets for each RCA\n",
    "  * Shrink RCAs by 15 meters shift outlet slighty upstream in order to avoid any errors that may smaller RCAs shifted into larger systems\n",
    " * Identify RCAs that were missed in the first operation and shrink by 8 meters\n",
    " * Identify any remaining RCAs missed by the first 2 operations and identify outlet\n",
    "### Merge results together and remove any duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Flow Accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07022020\n",
      "Begin process 2020-02-07 15:49:08.577757\n",
      "\n",
      "Creating  C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenai_flow_accumulation_07022020.tif\n",
      "\n",
      "Process complete  0:01:36.277028\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "arcpy.env.workspace = temp_dir\n",
    "arcpy.env.snapRaster = flowdirpath \n",
    "arcpy.env.extent = flowdirpath\n",
    "\n",
    "today = datetime.now()\n",
    "# Make the time stamp.  \n",
    "time_stamp = '{:%d%m%Y}'.format(today)\n",
    "\n",
    "print(time_stamp)\n",
    "\n",
    "import datetime\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "print (\"Begin process\", start)\n",
    "print(\"\")\n",
    "\n",
    "flowrastname = temp_dir + \"\\\\\" + region + \"_flow_accumulation_\" + time_stamp + \".tif\"                \n",
    "\n",
    "print (\"Creating \",flowrastname)\n",
    "print(\"\")\n",
    "\n",
    "flowacc = FlowAccumulation(flowdirpath,\"\",  'FLOAT', 'D8') # create flow acc from flow dir\n",
    "flowacc.save(flowrastname)\n",
    "flowaccdescribe = arcpy.Describe(flowacc)\n",
    "flowaccpath = os.path.join(flowacc.path,flowacc.name)\n",
    "\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "print (\"Process complete \", elapsed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shrink RCA by 15 meters\n",
    "* Consider filtering out very small RCAs (those that would be dissolved with Inside Buffer) prior to running "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Process 2020-02-07 15:50:44.875729\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenai.gdb\\Kenai_rca_huc12_largeover_sj_InsideBuffer_15\n",
      "Process complete  0:00:53.603825\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "print (\"Begin Process\", start)\n",
    "\n",
    "inrca2 = awcjoin\n",
    "buffval = -15 #shrink polygons by 15 meters\n",
    "rcadesc = arcpy.Describe(inrca2)\n",
    "buffabs = abs(buffval)\n",
    "insidebuffname = rcadesc.name + \"_InsideBuffer_\" + str(buffabs)\n",
    "shrinkrca = arcpy.Buffer_analysis(inrca2,insidebuffname,buffval)\n",
    "\n",
    "print(shrinkrca)\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "print (\"Process complete \", elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify and reclassify stream grid using TauDEM stream source grid and rca stream reaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin process 2020-02-07 15:51:38.502493\n",
      "\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenai_streams_raster_07022020.tif\n",
      "Process complete  0:00:33.414781\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "arcpy.env.workspace = temp_dir\n",
    "arcpy.env.snapRaster = flowdirpath\n",
    "arcpy.env.extent = flowdirpath\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "\n",
    "today = datetime.now()\n",
    "# Make the time stamp.  \n",
    "time_stamp = '{:%d%m%Y}'.format(today)\n",
    "import datetime\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "print (\"Begin process\", start)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "outname = temp_dir + \"\\\\\" + region + \"_rcastream_src_maskextract_\" + time_stamp + \".tif\"\n",
    "streamrast2 = ExtractByMask(streamrast, reachcopy)\n",
    "streamrast2.save(outname)\n",
    "\n",
    "streamname = temp_dir + \"\\\\\" + region + \"_streams_raster_\" + time_stamp + \".tif\"\n",
    "#streamcon = Con((Con(IsNull(streamrast),0,1) + streamrast2),0,1,\"VALUE < 1\") #Identify stream network from the two input stream grids and reclassify as 1 for stream and 0 everywhere else\n",
    "streamcon = Con(IsNull(streamrast2), 0, streamrast2) #Reclassify null values in extracted stream src grid as 0\n",
    "streamcon.save(streamname)\n",
    "\n",
    "print (streamcon)\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "\n",
    "print (\"Process complete \", elapsed)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify outlets using stream accumulation grid, shrunken buffer, and zonal statistics\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating stream flow accumulation raster\n",
      "Creating max accumulation raster\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenai_max_acc_zon_ALL.tif Created\n",
      "\n",
      "Identifying highest accumulation cell for each catchment\n",
      "Catchment outlets Id'd\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenai_max_acc_catch_ALL.tif\n",
      "Time to complete =  0:01:08.744366\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "arcpy.env.workspace = temp_dir\n",
    "arcpy.env.snapRaster = flowdirpath\n",
    "arcpy.env.extent = flowdirpath\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "\n",
    "print (\"Creating stream flow accumulation raster\")\n",
    "\n",
    "streamflowname = temp_dir + \"\\\\\" + region + \"_stream_accumulation.tif\"                \n",
    "streamflow = SetNull(streamcon,flowaccpath,\"Value = 0\") # Create flow accumulation raster along stream network only\n",
    "streamflow.save(streamflowname)\n",
    "\n",
    "print (\"Creating max accumulation raster\")\n",
    "\n",
    "max_acczon = temp_dir +\"//\" + region + \"_max_acc_zon_ALL.tif\"\n",
    "max_acc_zon = arcpy.sa.ZonalStatistics(shrinkrca, 'OBJECTID', streamflow, 'MAXIMUM', 'DATA') #identify max flow accumulation using shrunken rca raster\n",
    "max_acc_zon.save(max_acczon)\n",
    "\n",
    "print (max_acc_zon, \"Created\")\n",
    "print(\"\")\n",
    "print (\"Identifying highest accumulation cell for each catchment\")\n",
    "\n",
    "max_accatch = temp_dir +\"//\" + region + \"_max_acc_catch_ALL.tif\"\n",
    "max_acc_catch = Con(streamflow == max_acc_zon,streamflow) # identify cell of highest accumulation for each rca along stream network\n",
    "max_acc_catch.save(max_accatch)\n",
    "\n",
    "print (\"Catchment outlets Id'd\")\n",
    "print (max_acc_catch)\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start  \n",
    "print ('Time to complete = ',elapsed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to point\n",
    " * First set of outlets, some RCAs will be missed due to shrunken buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting Max accumulation cells to points\n",
      "\n",
      "Conversion COMPLETE\n",
      "\n",
      "Time to complete = 0:00:04.850974\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "print ('Converting Max accumulation cells to points')\n",
    "print ('')\n",
    "\n",
    "convers_name = outgdb + \"\\\\\" + region + \"_max_acc_outlet_FROM_ALL\"\n",
    "outlets = arcpy.RasterToPoint_conversion(max_acc_catch,convers_name)\n",
    "\n",
    "\n",
    "print ('Conversion COMPLETE')\n",
    "print ('')\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "\n",
    "print ('Time to complete =',elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify missing RCAs\n",
    " * Select missed RCAs using outlets produced from the first operation\n",
    "  * Rerun code above to create second outlet feature class using an 8 meter Inside Buffer\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting RCAs missed during buffer shrink\n",
      "\n",
      "Creating max accumulation raster\n",
      "\n",
      "Identifying highest accumulation cell for each catchment\n",
      "\n",
      "Catchment outlets Id'd\n",
      "\n",
      "Converting Max accumulation cells to points\n",
      "\n",
      "Conversion COMPLETE\n",
      "\n",
      "Merging outlets and deleting any duplicates\n",
      "\n",
      "\n",
      "Merge COMPLETE\n",
      "Time to complete = 0:00:55.278051\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "print (\"Selecting RCAs missed during buffer shrink\")\n",
    "print(\"\")\n",
    "\n",
    "missedout = arcpy.SelectLayerByLocation_management(awcjoin, 'INTERSECT', outlets, 1, 'NEW_SELECTION', 'INVERT') #Identify missed RCAs\n",
    "\n",
    "buffval = -8 #shrink missed polygons by 8 meters\n",
    "rcadesc = arcpy.Describe(inrca2)\n",
    "buffabs = abs(buffval)\n",
    "insidebuffname = rcadesc.name + \"_InsideBuffer_\" + str(buffabs)\n",
    "shrinkrca2 = arcpy.Buffer_analysis(missedout, insidebuffname,buffval)\n",
    "\n",
    "print (\"Creating max accumulation raster\")\n",
    "print(\"\")\n",
    "\n",
    "max_acczon2 = temp_dir +\"//\" + region + \"_max_acc_zon_ALL2.tif\"\n",
    "max_acc_zon2 = arcpy.sa.ZonalStatistics(shrinkrca2, 'OBJECTID', streamflow, 'MAXIMUM', 'DATA') #identify max flow accumulation using shrunken rca raster\n",
    "max_acc_zon2.save(max_acczon2)\n",
    "\n",
    "print (\"Identifying highest accumulation cell for each catchment\")\n",
    "print(\"\")\n",
    "\n",
    "max_accatch2 = temp_dir +\"//\" + region + \"_max_acc_catch_ALL2.tif\"\n",
    "max_acc_catch2 = Con(streamflow == max_acc_zon2,streamflow) # identify cell of highest accumulation for each rca along stream network\n",
    "max_acc_catch2.save(max_accatch2)\n",
    "\n",
    "print (\"Catchment outlets Id'd\")\n",
    "print(\"\")\n",
    "\n",
    "print ('Converting Max accumulation cells to points')\n",
    "print(\"\")\n",
    "\n",
    "convers_name = outgdb + \"\\\\\" + region + \"_max_acc_outlet_FROM_ALL2\"\n",
    "outlets2 = arcpy.RasterToPoint_conversion(max_acc_catch2,convers_name)\n",
    "\n",
    "print ('Conversion COMPLETE')\n",
    "print('')\n",
    "\n",
    "print(\"Merging outlets and deleting any duplicates\")\n",
    "print (\"\")\n",
    "\n",
    "pointmergename = outgdb + \"\\\\\" + region + \"_outlets_Merge1\"\n",
    "outletmerge = arcpy.Merge_management([outlets,outlets2 ],pointmergename)\n",
    "\n",
    "print('')\n",
    "print ('Merge COMPLETE')\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "print ('Time to complete =',elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a third time without inside buffer on any missed outlets\n",
    " * Tend to be very small RCAs near the confluence of larger systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting RCAs missed during buffer shrink\n",
      "\n",
      "final selection of 39 missed RCAs\n",
      "Creating max accumulation raster\n",
      "\n",
      "Identifying highest accumulation cell for each catchment\n",
      "\n",
      "Catchment outlets Id'd\n",
      "\n",
      "Converting Max accumulation cells to points\n",
      "\n",
      "Conversion COMPLETE\n",
      "\n",
      "Merging outlets\n",
      "\n",
      "\n",
      "Merge COMPLETE\n",
      "Join Complete...deleting duplicates\n",
      "\n",
      "Extracting flow accumulation to outlet\n",
      "\n",
      "Process complete\n",
      "3333 Outlets created\n",
      "Time to complete = 0:00:59.938259\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "print (\"Selecting RCAs missed during buffer shrink\")\n",
    "print(\"\")\n",
    "\n",
    "missedout2 = arcpy.SelectLayerByLocation_management(awcjoin, 'INTERSECT', outletmerge, 1, 'NEW_SELECTION', 'INVERT') #Identify missed RCAs\n",
    "miss2 = arcpy.GetCount_management(missedout2)\n",
    "print (\"final selection of \" + str(miss2) + \" missed RCAs\")\n",
    "\n",
    "print (\"Creating max accumulation raster\")\n",
    "print(\"\")\n",
    "\n",
    "max_acczon3 = temp_dir +\"//\" + region + \"_max_acc_zon_ALL3.tif\"\n",
    "max_acc_zon3 = arcpy.sa.ZonalStatistics(missedout2, 'OBJECTID', streamflow, 'MAXIMUM', 'DATA') #identify max flow accumulation using shrunken rca raster\n",
    "max_acc_zon3.save(max_acczon3)\n",
    "\n",
    "print (\"Identifying highest accumulation cell for each catchment\")\n",
    "print(\"\")\n",
    "\n",
    "max_accatch3 = temp_dir +\"//\" + region + \"_max_acc_catch_ALL3.tif\"\n",
    "max_acc_catch3 = Con(streamflow == max_acc_zon3,streamflow) # identify cell of highest accumulation for each rca along stream network\n",
    "max_acc_catch3.save(max_accatch3)\n",
    "\n",
    "print (\"Catchment outlets Id'd\")\n",
    "print(\"\")\n",
    "\n",
    "print ('Converting Max accumulation cells to points')\n",
    "print(\"\")\n",
    "\n",
    "convers_name = outgdb + \"\\\\\" + region + \"_max_acc_outlet_FROM_ALL3\"\n",
    "outlets3 = arcpy.RasterToPoint_conversion(max_acc_catch3,convers_name)\n",
    "\n",
    "print ('Conversion COMPLETE')\n",
    "print('')\n",
    "\n",
    "print(\"Merging outlets\")\n",
    "print (\"\")\n",
    "\n",
    "pointmergename2 = outgdb + \"\\\\\" + region + \"_outlets_Merge2\"\n",
    "outletmerge2 = arcpy.Merge_management([outletmerge, outlets3],pointmergename2)\n",
    "\n",
    "print('')\n",
    "print ('Merge COMPLETE')\n",
    "\n",
    "joinname = outgdb + \"\\\\\" + region + \"_RCA_Outlets_\" + time_stamp\n",
    "idjoin2 = arcpy.SpatialJoin_analysis(outletmerge2, awcjoin, joinname, 'JOIN_ONE_TO_ONE', 'KEEP_ALL',\"\", 'INTERSECT')\n",
    "\n",
    "print (\"Join Complete...deleting duplicates\")\n",
    "print (\"\")\n",
    "\n",
    "arcpy.DeleteIdentical_management(idjoin2,'SHAPE')\n",
    "\n",
    "print (\"Extracting flow accumulation to outlet\")\n",
    "print (\"\")\n",
    "\n",
    "ExtractMultiValuesToPoints(idjoin2,[[streamflow, \"Flow_Accumulation\"]])\n",
    "\n",
    "print (\"Process complete\")\n",
    "\n",
    "count = arcpy.GetCount_management(idjoin2)\n",
    "\n",
    "print (str(count) + \" Outlets created\")\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "print ('Time to complete =',elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Mean Elevation for RCA + all upstream contributing area\n",
    " * Create elevation weighted flow accumulation and divide by flow accumulation\n",
    " * Extract to outlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin process 2020-02-07 15:55:20.824672\n",
      "\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenai_elevation_weighted_flowacc.tif\n",
      "\n",
      "Process complete  0:01:43.709087\n",
      "\n",
      "Calculate Mean Elevation along stream network\n",
      "\n",
      "Process complete  0:01:13.545438\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenaistream_MEAN_elev.tif\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = temp_dir\n",
    "arcpy.env.snapRaster = flowdirpath\n",
    "arcpy.env.extent = flowdirpath\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "print (\"Begin process\", start)\n",
    "print(\"\")\n",
    "\n",
    "elevw8name = temp_dir + \"\\\\\" + region + \"_elevation_weighted_flowacc.tif\"\n",
    "elevw8flow = FlowAccumulation(flowdirpath, dem_copy, 'FLOAT', 'D8') # create glacially weighted flow accumulation\n",
    "elevw8flow.save(elevw8name)\n",
    "\n",
    "print(elevw8flow)\n",
    "print (\"\")\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "\n",
    "print (\"Process complete \", elapsed)\n",
    "print (\"\")\n",
    "print (\"Calculate Mean Elevation along stream network\")\n",
    "print (\"\")\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "meanelevname = temp_dir + \"\\\\\" + region + \"stream_MEAN_elev.tif\"                \n",
    "meanelev = SetNull(streamflow,(elevw8flow / flowaccpath ),\"Value = 0\") #Limit output to stream network\n",
    "meanelev.save(meanelevname)\n",
    "\n",
    "ExtractMultiValuesToPoints(idjoin2,[[meanelev, \"Mean_Elev_Contributing_Area\"]])\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "\n",
    "print (\"Process complete \", elapsed)\n",
    "print(meanelev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Final attributed RCA on local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='deleteid'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting elevation at temperature site\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenai.gdb\\kenai_rcas_temp_sites_attributed_07022020\n",
      "\n",
      "3325 Outlets created\n",
      "\n",
      "3325 RCAs created in the Kenaistudy area\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\Watershed_Attributes\\\\Kenai\\\\Kenai_attributes\\\\Kenai_Attributes_07022020\\\\Kenai.gdb\\\\kenai_rcas_attributed_07022020'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "rcadesc = arcpy.Describe(rcacopy)\n",
    "name = rcadesc.name\n",
    "rcacopyname = name +\"_attributed_\" + time_stamp\n",
    "finalrca = arcpy.CopyFeatures_management(rcacopy, rcacopyname)\n",
    "\n",
    "for field in arcpy.ListFields(finalrca):\n",
    "    joindrop.append(field.name)\n",
    "    \n",
    "keepfields = ['OBJECTID', 'Shape', 'rca_id','Shape_Length', 'Shape_Area']\n",
    "for field in keepfields:\n",
    "    joindrop.remove(field)\n",
    "\n",
    "arcpy.DeleteField_management(finalrca, joindrop)\n",
    "\n",
    "tempdesc = arcpy.Describe(tempsites)\n",
    "tempcopyname = name + \"_temp_sites_attributed_\" + time_stamp\n",
    "tempfinal = arcpy.CopyFeatures_management(tempsites,tempcopyname)\n",
    "ExtractMultiValuesToPoints(tempfinal,[[dem_copy, \"Elevation_meters\"]])\n",
    "\n",
    "print(\"Extracting elevation at temperature site\")\n",
    "print(tempfinal)\n",
    "print (\"\")\n",
    "\n",
    "outletcopyname = region + \"_rca_outlets_attributed_\" + time_stamp\n",
    "outcopy = arcpy.CopyFeatures_management(idjoin2, outletcopyname)\n",
    "arcpy.DeleteIdentical_management(outcopy,'rca_id')\n",
    "count = arcpy.GetCount_management(outcopy)\n",
    "\n",
    "print (str(count) + \" Outlets created\")\n",
    "print(\"\")\n",
    "\n",
    "count2 = arcpy.GetCount_management(finalrca)\n",
    "\n",
    "print (str(count2) + \" RCAs created in the \" + str(region) + \"study area\")\n",
    "print (\"\")\n",
    "\n",
    "arcpy.JoinField_management(finalrca,\"rca_id\",outcopy, \"rca_id\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recalculate slope percent reaches\n",
    " * (rise/run*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding Surface information to rca reaches\n",
      "\n",
      "Adding Surface info fields\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result 'T:\\\\\\\\Aquatic\\\\\\\\KFHP\\\\\\\\Landscape_Metrics_DM\\\\\\\\Kenai\\\\\\\\Source_Data\\\\\\\\Kenai_Source.gdb\\\\kenai_rca_reaches'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from arcpy.sa import * \n",
    "method = \"BILINEAR\"\n",
    "prop = \"Z_MIN;Z_MAX;Z_MEAN;SURFACE_LENGTH\"\n",
    "perc_calc = '(!Z_Max!-!Z_Min!)/!SLength!*100'\n",
    "\n",
    "print (\"Adding Surface information to rca reaches\")\n",
    "print (\"\")\n",
    "\n",
    "arcpy.ddd.AddSurfaceInformation(reachcopy,dem_copy,prop,method)\n",
    "\n",
    "print (\"Adding Surface info fields\")\n",
    "print (\"\")\n",
    "\n",
    "arcpy.AddField_management(reachcopy,\"reach_length\", \"DOUBLE\",\"\",\"\",\"\", \"Reach Length in meters\")\n",
    "arcpy.AddField_management(reachcopy,\"reach_slope\", 'DOUBLE',\"\",\"\",\"\",\"Reach slope in percent\")\n",
    "arcpy.CalculateField_management(reachcopy,\"reach_slope\", perc_calc)\n",
    "arcpy.CalculateField_management(reachcopy,\"reach_length\", '!SLength!')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcute percent land cover metrics in 30meter buffered area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download NLCD\n",
    " * NLCD is currently the best available landcover dataset with coverage for the entire state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ak_nlcd_2011_landcover_1_15_15.zip\n",
      "\n",
      "ALL DOWNLOADS COMPLETE\n",
      "Time to complete =  0:00:31.195683\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "wurl = r\"https://prd-tnm.s3.amazonaws.com/StagedProducts/NLCD2011/Land_Cover/Alaska/ak_nlcd_2011_landcover_1_15_15.zip\"\n",
    "start = datetime.datetime.now() \n",
    "wname = wurl[-34:]\n",
    "print ('Downloading',wname)\n",
    "\n",
    "wzippath = str(ziploc) + '/'+ str(wname) #path to save download to plus name of download\n",
    "# headers = {\"Range\": \"bytes=0-100\"}  # first 100 bytes\n",
    "# rh= requests.get(wurl, headers)\n",
    "# print(rh.status_code)\n",
    "# print(rh.headers['content-type'])\n",
    "# print(rh.encoding)\n",
    "r = requests.get(wurl)\n",
    "if not os.path.exists(wzippath):\n",
    "    with open(wzippath,'wb') as f:\n",
    "        f.write(r.content)\n",
    "        \n",
    "print('')\n",
    "print ('ALL DOWNLOADS COMPLETE')\n",
    "stop = datetime.datetime.now()  \n",
    "elapsed = stop - start  \n",
    "print ('Time to complete = ',elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip NLCD\n",
    "#### Must have 7zip installed and located in the path below, change if necessary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unzipping  C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\zips\\ak_nlcd_2011_landcover_1_15_15.zip\n",
      "Finished extracting AK NLCD\n",
      "\n",
      "Unzipping complete\n",
      "Time to complete =  0:00:49.937943\n"
     ]
    }
   ],
   "source": [
    "### Unzip landcover data\n",
    "\n",
    "import subprocess\n",
    "os.chdir(ziploc)\n",
    "for dir in os.listdir():\n",
    "    if \"ak_nlcd_2011\" in dir:\n",
    "        wzip = os.path.abspath(dir)\n",
    "        print ('Unzipping ', wzip)\n",
    "        #wzip = zipfile.ZipFile(file_name) # create zipfile object\n",
    "        #wzip.extractall(extractloc) # extract file to dir\n",
    "        #wzip.close() # close file\n",
    "        #os.remove(file_name) # delete zipped file if required\n",
    "        wuz = subprocess.call(r'\"C:\\Program Files\\7-Zip\\7z.exe\" x ' + wzip + ' -o' + extractloc)\n",
    "        print ('Finished extracting AK NLCD')\n",
    "print('')\n",
    "print ('Unzipping complete')\n",
    "stop = datetime.datetime.now()  \n",
    "elapsed = stop - start  \n",
    "print ('Time to complete = ',elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Glacier data - KENAI ONLY\n",
    " * approx 1 gb download as of 20200117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading GLIMS_Data.zip\n",
      "\n",
      "ALL DOWNLOADS COMPLETE\n",
      "Time to complete =  0:05:19.005568\n",
      "Unzipping.. C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\zips\\GLIMS_Data.zip\n",
      "\n",
      "Unzipping complete\n",
      "Time to complete =  0:00:18.996854\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "wurl = r\"http://www.glims.org/download/latest\" #latest glims data\n",
    "start = datetime.datetime.now() \n",
    "wname = \"GLIMS_Data.zip\"\n",
    "print ('Downloading',wname)\n",
    "\n",
    "\n",
    "wzippath = str(ziploc) + '/'+ str(wname) #path to save download to plus name of download\n",
    "# headers = {\"Range\": \"bytes=0-100\"}  # first 100 bytes\n",
    "# rh= requests.get(wurl, headers)\n",
    "# print(rh.status_code)\n",
    "# print(rh.headers['content-type'])\n",
    "# print(rh.encoding)\n",
    "r = requests.get(wurl)\n",
    "if not os.path.exists(wzippath):\n",
    "    with open(wzippath,'wb') as f:\n",
    "        f.write(r.content)\n",
    "        \n",
    "print('')\n",
    "print ('ALL DOWNLOADS COMPLETE')\n",
    "stop = datetime.datetime.now()  \n",
    "elapsed = stop - start  \n",
    "print ('Time to complete = ',elapsed)\n",
    "\n",
    "os.chdir(ziploc)\n",
    "start = datetime.datetime.now()\n",
    "for item in os.listdir():\n",
    "    if \"GLIMS\" in item:\n",
    "        file_name = os.path.abspath(item) # get full path of files\n",
    "        zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
    "        zip_ref.extractall(extractloc) # extract file to dir\n",
    "        zip_ref.close() # close file\n",
    "        #os.remove(file_name) # delete zipped file if required   \n",
    "        print ('Unzipping..', file_name)\n",
    "        print('')\n",
    "\n",
    "print ('Unzipping complete')\n",
    "stop = datetime.datetime.now()  \n",
    "elapsed = stop - start  \n",
    "print ('Time to complete = ',elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Buffer by 30 meters and clip to study area\n",
    " * Buffers will overlap but this is not an issue\n",
    "  * Adding text field to copy NHDPLUSID (Using Float field may cause issues with panda display) and add and calc shape area in square meters as a check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\Watershed_Attributes\\\\Kenai\\\\Kenai_attributes\\\\Kenai_Attributes_07022020\\\\Kenai.gdb\\\\kenai_rca_reaches_buff30'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "reachdesc = arcpy.Describe(reachcopy)\n",
    "streambuffname = reachdesc.name + \"_buff30\"\n",
    "riv_buff30 = arcpy.Buffer_analysis(reachcopy,streambuffname,30, 'FULL', 'FLAT', 'NONE')\n",
    "arcpy.AddField_management(riv_buff30,\"Buff_Area_Sqm\", 'DOUBLE')\n",
    "arcpy.CalculateField_management(riv_buff30, 'Buff_Area_Sqm','!shape.area@squaremeters!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Shrub and Forest Layers\n",
    " * Buffer study area by 60 meters to ensure no cells are missed in extraction\n",
    "  * Extract NLCD raster by Study Watershed polygon mask and convert to Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watershed Buffer complete C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenai.gdb\\Kenai_buff60\n",
      "\n",
      "ak_nlcd_2011_landcover_1_15_15.img\n",
      "\n",
      "Extracting raster  ak_nlcd_2011_landcover_1_15_15\n",
      "\n",
      "Extraction Complete\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\ak_nlcd_2011_landcover_1_15_15_extract.tif\n",
      "\n",
      "Process complete  0:00:01.761297\n",
      "\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenai.gdb\\Kenai_nlcd_poly\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "arcpy.env.extent = flowdirpath\n",
    "arcpy.env.snapRaster = flowdirpath\n",
    "\n",
    "studybuffname = region + \"_buff60\"\n",
    "study_buff = arcpy.Buffer_analysis(studycopy,studybuffname,60, 'FULL', 'ROUND', 'ALL')\n",
    "\n",
    "print (\"Watershed Buffer complete\", study_buff)\n",
    "print (\"\")\n",
    "\n",
    "from arcpy.sa import *\n",
    "os.chdir(extractloc)\n",
    "arcpy.env.workspace = extractloc\n",
    "raster_list = arcpy.ListRasters()\n",
    "start = datetime.datetime.now()\n",
    "for raster in raster_list:\n",
    "    if \"ak_nlcd_2011\" in raster:\n",
    "        \n",
    "        print (raster)\n",
    "        print (\"\")\n",
    "        \n",
    "        desc = arcpy.Describe(raster)\n",
    "        name = desc.baseName\n",
    "        outname = temp_dir + \"\\\\\" + name + \"_extract.tif\"\n",
    "        \n",
    "        print (\"Extracting raster \", name)\n",
    "        print (\"\")\n",
    "        \n",
    "        extract = ExtractByMask(raster, study_buff)\n",
    "        extract.save(outname)\n",
    "        \n",
    "        print (\"Extraction Complete\")\n",
    "        print (extract)\n",
    "        print (\"\")\n",
    "                \n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "\n",
    "print (\"Process complete \", elapsed)\n",
    "print (\"\")\n",
    "\n",
    "arcpy.env.workspace = outgdb\n",
    "nlcdpolyname = region + \"_nlcd_poly\"\n",
    "nlcd_poly = arcpy.RasterToPolygon_conversion(extract,nlcdpolyname, 'NO_SIMPLIFY', 'Land_Cover')\n",
    "\n",
    "print (nlcd_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add and calc area in sq meters as check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Result 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\Watershed_Attributes\\\\Kenai\\\\Kenai_attributes\\\\Kenai_Attributes_07022020\\\\Kenai.gdb\\\\Kenai_nlcd_poly'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.AddField_management(nlcd_poly,\"Area_Sqm\", 'DOUBLE')\n",
    "arcpy.CalculateField_management(nlcd_poly, 'Area_Sqm','!shape.area@squaremeters!')\n",
    "arcpy.AddField_management(nlcd_poly,\"Land_Cover_Reclass\", 'TEXT')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add field and reclass cover types using following dictionary\n",
    " * Use update cursor and dictionary to reclassify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process complete  0:00:14.306883\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "d = {'Barren Land':'Barren',\n",
    "'Cultivated Crops':'Crops',\n",
    "'Deciduous Forest':'Forest',\n",
    "'Mixed Forest':'Forest',\n",
    "'Evergreen Forest':'Forest',\n",
    "'Grassland/Herbaceous':'Herbaceous',\n",
    "'Sedge/Herbaceous':'Herbaceous',\n",
    "'Developed, High Intensity':'High intensity',\n",
    "'Developed, Low Intensity':'Low intensity',\n",
    "'Developed, Medium Intensity':'Medium intensity',\n",
    "'Developed, Open Space':'Open space',\n",
    "'Pasture/Hay':'Pasture',\n",
    "'Perennial Ice/Snow':'Perennial Ice',\n",
    "'Shrub/Scrub':'Shrub',\n",
    "'Dwarf Shrub':'Shrub',\n",
    "'Open Water':'Water',\n",
    "'Emergent Herbaceous Wetlands':'Wetlands',\n",
    "'Woody Wetlands':'Wetlands'}\n",
    "\n",
    "fields = ['Land_Cover','Land_Cover_Reclass']\n",
    "with arcpy.da.UpdateCursor(nlcd_poly, (fields)) as rows:\n",
    "    for row in rows:\n",
    "        if row[0] not in d.keys():\n",
    "            print (\"{} not in list\".format(row[0]))\n",
    "        else:\n",
    "            row[1] = d[row[0]]\n",
    "            rows.updateRow(row)\n",
    "    del row \n",
    "del rows\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "\n",
    "print (\"Process complete \", elapsed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Glacier layer and calculate percent cover by RCA\n",
    " * Use <a href = \"http://glims.colorado.edu/glacierdata/\">GLIMS</a> for glacier data - may require manual download\n",
    "  * Large dataset that needs to be converted to feature class, projected, and clipped to study area\n",
    "    * Returned void poly error when initially clipped so these steps may resolve the issue.  Try repair geometry if it does not.\n",
    "    * Create a raster layer with 1 for glacier and 0 for no-glacier. Use the flow accumulation tool to get additive value for upstream contributing area for each RCA and then divide by flow accumulation value for each RCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\extracts\\glims_download_56134\\glims_polygons.shp\n",
      "Time to complete 0:00:19.990724\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenai.gdb\\glims_data\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "for dirpath, dirnames, filenames in arcpy.da.Walk(extractloc, datatype = \"FEATURECLASS\"):  \n",
    "    for filename in filenames:  \n",
    "        if \"glims_polygons\" in filename:\n",
    "            glacierdata = os.path.join(dirpath,filename)\n",
    "            print (glacierdata)\n",
    "            \n",
    "glims_copy = arcpy.FeatureClassToFeatureClass_conversion(glacierdata,outgdb,\"glims_data\") #make a copy to output gdb so that projections match and hopefully avoid void poly error in clip\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "elapsed = end-start\n",
    "print (\"Time to complete\",elapsed)\n",
    "\n",
    "print (glims_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to repair geometry or the next process will fail due to incomplete void poly error\n",
    "* Must repair geometry on entire dataset prior to clip or clip will fail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin process 2020-02-07 16:07:13.123022\n",
      "Time to complete 0:00:48.462915\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "start= datetime.datetime.now()\n",
    "\n",
    "print (\"Begin process\", start)\n",
    "\n",
    "glarepair = arcpy.RepairGeometry_management(glacierdata,'DELETE_NULL') #repair void poly errors in original dataset \n",
    "\n",
    "end = datetime.datetime.now()\n",
    "elapsed = end-start\n",
    "print (\"Time to complete\",elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clip glacier to buffered study area\n",
    " * buffered by 60 meters to ensure no data are missed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin process 2020-02-07 16:08:01.603889\n",
      "\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenai.gdb\\glims_clip\n",
      "\n",
      "Time to complete 0:00:21.547570\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "start= datetime.datetime.now()\n",
    "\n",
    "print (\"Begin process\", start)\n",
    "print(\"\")\n",
    "\n",
    "glaclip = arcpy.Clip_analysis(glarepair,study_buff,\"glims_clip\") #Clip glacier data to buffered study area\n",
    "\n",
    "print (glaclip)\n",
    "print(\"\")\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "elapsed = end-start\n",
    "print (\"Time to complete\",elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Glacier Polygon to raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin process 2020-02-07 16:08:23.168416\n",
      "\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\glims_poly2rast.tif\n",
      "\n",
      "Process complete  0:00:08.303975\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = temp_dir\n",
    "arcpy.env.snapRaster = flowdirpath \n",
    "arcpy.env.extent = flowdirpath\n",
    "arcpy.env.cellSize = flowdirpath\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "print (\"Begin process\", start)\n",
    "print(\"\")\n",
    "\n",
    "glimsrast = arcpy.PolygonToRaster_conversion(glaclip, 'glac_stat',\"glims_poly2rast.tif\",\"\",\"\",5) # convert polygon to raster and match cell size\n",
    "arcpy.CalculateStatistics_management(glimsrast)\n",
    "\n",
    "print(glimsrast)\n",
    "print(\"\")\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "\n",
    "print (\"Process complete \", elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Null values in glacier raster to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin process 2020-02-07 16:08:31.488348\n",
      "\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenai_glims_raster.tif\n",
      "\n",
      "Process complete  0:00:14.585024\n"
     ]
    }
   ],
   "source": [
    "from arcpy.sa import *\n",
    "arcpy.env.workspace = temp_dir\n",
    "arcpy.env.snapRaster = flowdirpath\n",
    "arcpy.env.extent = flowdirpath\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "print (\"Begin process\", start)\n",
    "print(\"\")\n",
    "\n",
    "glimsname = temp_dir + \"\\\\\" + region + \"_glims_raster.tif\"\n",
    "glimscon = Con(IsNull(glimsrast),0,glimsrast) # Convert all null values to 0\n",
    "glimscon.save(glimsname)\n",
    "\n",
    "print(glimscon)\n",
    "print (\"\")\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "\n",
    "print (\"Process complete \", elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create glacially weighted flow acc raster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin process 2020-02-07 16:08:46.097309\n",
      "\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenai_glacial_weighted_flowacc.tif\n",
      "\n",
      "Process complete  0:01:12.177864\n",
      "\n",
      "Calculate Percent Glacier along stream network\n",
      "\n",
      "Process complete  0:01:12.544677\n",
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenaistream_per_glacier.tif\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Result 'C:\\\\Users\\\\dwmerrigan\\\\Documents\\\\GitHub\\\\Watershed_Attributes\\\\Kenai\\\\Kenai_attributes\\\\Kenai_Attributes_07022020\\\\Kenai.gdb\\\\kenai_rcas_attributed_07022020'>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.workspace = temp_dir\n",
    "arcpy.env.snapRaster = flowdirpath\n",
    "arcpy.env.extent = flowdirpath\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "print (\"Begin process\", start)\n",
    "print(\"\")\n",
    "\n",
    "glimsw8name = temp_dir + \"\\\\\" + region + \"_glacial_weighted_flowacc.tif\"\n",
    "glimsw8flow = FlowAccumulation(flowdirpath, glimscon, 'FLOAT', 'D8') # create glacially weighted flow accumulation\n",
    "glimsw8flow.save(glimsw8name)\n",
    "\n",
    "print(glimsw8flow)\n",
    "print (\"\")\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "\n",
    "print (\"Process complete \", elapsed)\n",
    "print (\"\")\n",
    "print (\"Calculate Percent Glacier along stream network\")\n",
    "print (\"\")\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "\n",
    "glimspername = temp_dir + \"\\\\\" + region + \"stream_per_glacier.tif\"                \n",
    "glimsper = SetNull(streamflow,((glimsw8flow / flowaccpath)*100 ),\"Value = 0\") #Limit output to stream network\n",
    "glimsper.save(glimspername)\n",
    "\n",
    "ExtractMultiValuesToPoints(outcopy,[[glimsper, \"glacier_per\"]])\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "\n",
    "print (\"Process complete \", elapsed)\n",
    "print(glimsper)\n",
    "\n",
    "arcpy.JoinField_management(finalrca,\"rca_id\",outcopy, \"rca_id\",\"glacier_per\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabulate intersection between 30m buffered river segments (defined by nhdplusid or reachid) and nlcd polygon created above\n",
    " \n",
    " * Table output of land cover percent and total area for each land cover type within the buffered river segment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID\n",
      "Shape\n",
      "rca_id\n",
      "Shape_Length\n",
      "Shape_Area\n",
      "Join_Count\n",
      "TARGET_FID\n",
      "pointid\n",
      "grid_code\n",
      "rca_id_1\n",
      "HUC12\n",
      "Name\n",
      "K_r\n",
      "K_s\n",
      "K_p\n",
      "CH_r\n",
      "CH_s\n",
      "CH_p\n",
      "CO_r\n",
      "CO_s\n",
      "CO_p\n",
      "P_r\n",
      "P_s\n",
      "P_p\n",
      "S_r\n",
      "S_s\n",
      "S_p\n",
      "MIN\n",
      "MAX\n",
      "MEAN\n",
      "Flow_Accumulation\n",
      "Mean_Elev_Contributing_Area\n",
      "glacier_per\n"
     ]
    }
   ],
   "source": [
    "for field in arcpy.ListFields(finalrca):\n",
    "    print (field.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenai.gdb\\Reclassified_kenai_rca_reaches_NLCD_Tab_Int\n",
      "\n",
      "Process complete  0:01:54.098093\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "arcpy.env.workspace = outgdb\n",
    "tab2name = \"Reclassified_\" + tabtablename\n",
    "tab_int2 = arcpy.TabulateIntersection_analysis(riv_buff30, identifierfield, nlcd_poly,tab2name, ['Land_Cover_Reclass'], 'Area_Sqm')\n",
    "\n",
    "print (tab_int2)\n",
    "print (\"\")\n",
    "\n",
    "stop = datetime.datetime.now()\n",
    "elapsed = stop - start\n",
    "\n",
    "print (\"Process complete \", elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# start = datetime.datetime.now()\n",
    "# arcpy.env.workspace = outgdb\n",
    "# tab_int = arcpy.TabulateIntersection_analysis(riv_buff30, identifierfield, nlcd_poly,tabtablename, ['Land_Cover','Land_Cover_Reclass'], 'Area_Sqm')\n",
    "\n",
    "# print (tab_int)\n",
    "# print (\"\")\n",
    "\n",
    "# stop = datetime.datetime.now()\n",
    "# elapsed = stop - start\n",
    "\n",
    "# print (\"Process complete \", elapsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Identity and dissolve to check against tabulate intersection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = datetime.datetime.now()\n",
    "# arcpy.env.workspace = outgdb\n",
    "# riv_nlcd_id = arcpy.Identity_analysis(riv_buff30, nlcd_poly,identname, 'ALL')\n",
    "# end = datetime.datetime.now()\n",
    "# elapsed = end-start\n",
    "\n",
    "# print (\"Time to complete\",elapsed)\n",
    "# print (riv_nlcd_id)\n",
    "# print (\"\")\n",
    "\n",
    "# idcount = arcpy.GetCount_management(riv_nlcd_id)\n",
    "\n",
    "# print (idcount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dissolve Identity\n",
    " * Keep ID, landcover, reclass, and buffered area\n",
    " * Add/calculate area in sqm and percent cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = datetime.datetime.now()\n",
    "# arcpy.env.workspace = outgdb\n",
    "# disname = identname + \"_All_Land_Dissolve\"\n",
    "\n",
    "# print(\"Begin Dissolve\", start)\n",
    "# print(\"\")\n",
    "\n",
    "# riv_nlcd_i0.d_dis = arcpy.Dissolve_management(riv_nlcd_id,disname, [identifierfield,'Land_Cover','Land_Cover_Reclass','Buff_Area_Sqm'], '', 'MULTI_PART', 'DISSOLVE_LINES')\n",
    "# arcpy.AddField_management(riv_nlcd_id_dis,\"Percent_Cover\", 'DOUBLE')\n",
    "# arcpy.AddField_management(riv_nlcd_id_dis,'Shape_Area_Sqm', 'DOUBLE')\n",
    "# arcpy.CalculateField_management(riv_nlcd_id_dis, 'Shape_Area_Sqm','!shape.area@squaremeters!')\n",
    "# percent_calc = \"!Shape_Area_Sqm!/!Buff_Area_Sqm!*100\"\n",
    "# arcpy.CalculateField_management(riv_nlcd_id_dis, 'Percent_Cover',percent_calc)\n",
    "# end = datetime.datetime.now()\n",
    "# elapsed = end-start\n",
    "\n",
    "# print (\"Time to complete\",elapsed)\n",
    "# print (riv_nlcd_id_dis)\n",
    "# print (\"\")\n",
    "\n",
    "# disscount = arcpy.GetCount_management(riv_nlcd_id_dis)\n",
    "\n",
    "# print (disscount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = datetime.datetime.now()\n",
    "# arcpy.env.workspace = outgdb\n",
    "# disname2 = identname + \"_Land_Reclass_Dissolve\"\n",
    "\n",
    "# print(\"Begin Dissolve\", start)\n",
    "# print(\"\")\n",
    "\n",
    "# riv_nlcd_id_dis2 = arcpy.Dissolve_management(riv_nlcd_id,disname2, [identifierfield, 'Land_Cover_Reclass','Buff_Area_Sqm'], '', 'MULTI_PART', 'DISSOLVE_LINES')\n",
    "# arcpy.AddField_management(riv_nlcd_id_dis2,\"Percent_Cover\", 'DOUBLE')\n",
    "# arcpy.AddField_management(riv_nlcd_id_dis2,'Shape_Area_Sqm', 'DOUBLE')\n",
    "# arcpy.CalculateField_management(riv_nlcd_id_dis2, 'Shape_Area_Sqm','!shape.area@squaremeters!')\n",
    "# percent_calc = \"!Shape_Area_Sqm!/!Buff_Area_Sqm!*100\"\n",
    "# arcpy.CalculateField_management(riv_nlcd_id_dis2, 'Percent_Cover',percent_calc)\n",
    "# end = datetime.datetime.now()\n",
    "# elapsed = end-start\n",
    "\n",
    "# print (\"Time to complete\",elapsed)\n",
    "# print (riv_nlcd_id_dis2)\n",
    "# print (\"\")\n",
    "\n",
    "# disscount = arcpy.GetCount_management(riv_nlcd_id_dis2)\n",
    "\n",
    "# print (disscount)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert table to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>reachid</th>\n",
       "      <th>Land_Cover_Reclass</th>\n",
       "      <th>Area_Sqm</th>\n",
       "      <th>AREA</th>\n",
       "      <th>PERCENTAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Barren</td>\n",
       "      <td>11243.60</td>\n",
       "      <td>11243.60</td>\n",
       "      <td>74.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Forest</td>\n",
       "      <td>3.97</td>\n",
       "      <td>3.97</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Shrub</td>\n",
       "      <td>3258.09</td>\n",
       "      <td>3258.09</td>\n",
       "      <td>21.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Water</td>\n",
       "      <td>580.87</td>\n",
       "      <td>580.87</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>Barren</td>\n",
       "      <td>11453.72</td>\n",
       "      <td>11453.72</td>\n",
       "      <td>58.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8839</td>\n",
       "      <td>8840</td>\n",
       "      <td>3543</td>\n",
       "      <td>Shrub</td>\n",
       "      <td>63870.63</td>\n",
       "      <td>63870.63</td>\n",
       "      <td>21.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8840</td>\n",
       "      <td>8841</td>\n",
       "      <td>3543</td>\n",
       "      <td>Water</td>\n",
       "      <td>76409.43</td>\n",
       "      <td>76409.43</td>\n",
       "      <td>25.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8841</td>\n",
       "      <td>8842</td>\n",
       "      <td>3544</td>\n",
       "      <td>Forest</td>\n",
       "      <td>24346.13</td>\n",
       "      <td>24346.13</td>\n",
       "      <td>12.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8842</td>\n",
       "      <td>8843</td>\n",
       "      <td>3544</td>\n",
       "      <td>Shrub</td>\n",
       "      <td>172529.44</td>\n",
       "      <td>172529.44</td>\n",
       "      <td>85.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8843</td>\n",
       "      <td>8844</td>\n",
       "      <td>3544</td>\n",
       "      <td>Wetlands</td>\n",
       "      <td>4200.84</td>\n",
       "      <td>4200.84</td>\n",
       "      <td>2.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8844 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      OBJECTID  reachid Land_Cover_Reclass  Area_Sqm      AREA  PERCENTAGE\n",
       "0            1        1             Barren  11243.60  11243.60       74.53\n",
       "1            2        1             Forest      3.97      3.97        0.03\n",
       "2            3        1              Shrub   3258.09   3258.09       21.60\n",
       "3            4        1              Water    580.87    580.87        3.85\n",
       "4            5        2             Barren  11453.72  11453.72       58.41\n",
       "...        ...      ...                ...       ...       ...         ...\n",
       "8839      8840     3543              Shrub  63870.63  63870.63       21.20\n",
       "8840      8841     3543              Water  76409.43  76409.43       25.36\n",
       "8841      8842     3544             Forest  24346.13  24346.13       12.11\n",
       "8842      8843     3544              Shrub 172529.44 172529.44       85.80\n",
       "8843      8844     3544           Wetlands   4200.84   4200.84        2.09\n",
       "\n",
       "[8844 rows x 6 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.float_format = '{:.2f}'.format # only display 2 decimal places\n",
    "field_list = []\n",
    "for field in arcpy.ListFields(tab_int2):\n",
    "    field_list.append(field.name)\n",
    "tabint_arr = arcpy.da.TableToNumPyArray(tab_int2,field_list)\n",
    "df = pd.DataFrame(tabint_arr)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of unique land cover classes from tabulate intersection\n",
    " * All land cover types that are present in the study area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barren', 'Crops', 'Forest', 'Herbaceous', 'High intensity', 'Low intensity', 'Medium intensity', 'Open space', 'Pasture', 'Perennial Ice', 'Shrub', 'Water', 'Wetlands']\n"
     ]
    }
   ],
   "source": [
    "lancov = df['Land_Cover_Reclass'].unique()\n",
    "print (sorted(lancov))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape dataframe and set index\n",
    " * Easier to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Area_Sqm</th>\n",
       "      <th>PERCENTAGE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reachid</th>\n",
       "      <th>Land_Cover_Reclass</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"4\" valign=\"top\">1</td>\n",
       "      <td>Barren</td>\n",
       "      <td>11243.60</td>\n",
       "      <td>74.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Forest</td>\n",
       "      <td>3.97</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Shrub</td>\n",
       "      <td>3258.09</td>\n",
       "      <td>21.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Water</td>\n",
       "      <td>580.87</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Barren</td>\n",
       "      <td>11453.72</td>\n",
       "      <td>58.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"2\" valign=\"top\">3543</td>\n",
       "      <td>Shrub</td>\n",
       "      <td>63870.63</td>\n",
       "      <td>21.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Water</td>\n",
       "      <td>76409.43</td>\n",
       "      <td>25.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">3544</td>\n",
       "      <td>Forest</td>\n",
       "      <td>24346.13</td>\n",
       "      <td>12.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Shrub</td>\n",
       "      <td>172529.44</td>\n",
       "      <td>85.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Wetlands</td>\n",
       "      <td>4200.84</td>\n",
       "      <td>2.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8844 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Area_Sqm  PERCENTAGE\n",
       "reachid Land_Cover_Reclass                      \n",
       "1       Barren              11243.60       74.53\n",
       "        Forest                  3.97        0.03\n",
       "        Shrub                3258.09       21.60\n",
       "        Water                 580.87        3.85\n",
       "2       Barren              11453.72       58.41\n",
       "...                              ...         ...\n",
       "3543    Shrub               63870.63       21.20\n",
       "        Water               76409.43       25.36\n",
       "3544    Forest              24346.13       12.11\n",
       "        Shrub              172529.44       85.80\n",
       "        Wetlands             4200.84        2.09\n",
       "\n",
       "[8844 rows x 2 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.drop([\"OBJECTID\",\"AREA\"],axis=1)\n",
    "df2 = df2.set_index([identifierfield,'Land_Cover_Reclass'])\n",
    "df2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Dissolve to Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.set_option('display.max_columns', None)  \n",
    "# from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "# from arcgis import GIS\n",
    "# gis = GIS()\n",
    "# sdf = pd.DataFrame.spatial.from_featureclass(riv_nlcd_id_dis2)\n",
    "# sdf[[identifierfield,'Land_Cover_Reclass','Buff_Area_Sqm','Shape_Area_Sqm','Percent_Cover']].sort_values(by=[identifierfield])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot Tab Intersection table and join to rca reaches\n",
    " * Turn land cover classes stored in rows to fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBJECTID_1\n",
      "Shape\n",
      "OBJECTID\n",
      "reachid\n",
      "Shape_Length\n",
      "Z_Min\n",
      "Z_Max\n",
      "Z_Mean\n",
      "SLength\n",
      "reach_length\n",
      "reach_slope\n"
     ]
    }
   ],
   "source": [
    "for field in arcpy.ListFields(reachcopy):\n",
    "    print (field.name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete\n",
      "\n",
      "OBJECTID_1\n",
      "Shape\n",
      "OBJECTID\n",
      "reachid\n",
      "Shape_Length\n",
      "Z_Min\n",
      "Z_Max\n",
      "Z_Mean\n",
      "SLength\n",
      "reach_length\n",
      "reach_slope\n",
      "Forest\n",
      "Shrub\n",
      "Wetlands\n",
      "Riparian\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = outgdb\n",
    "pivname = region + \"Landcover_Pivot_Table\"\n",
    "tabpivot = arcpy.PivotTable_management(tab_int2,\"reachid\",\"Land_Cover_Reclass\",\"PERCENTAGE\",pivname)\n",
    "arcpy.JoinField_management(reachcopy,\"reachid\",tabpivot,\"reachid\",[\"Forest\",\"Shrub\",\"Wetlands\"])\n",
    "arcpy.AddField_management(reachcopy,\"Riparian\", 'TEXT',\"\",\"\",250,\"Percent riparian (forest + shrub) cover in 30 meter buffer surrounding reach\")\n",
    "\n",
    "fieldList = [\"Forest\",\"Shrub\",\"Wetlands\"]\n",
    "with arcpy.da.UpdateCursor(reachcopy, fieldList) as cursor:\n",
    "        for row in cursor:\n",
    "            Urow = row\n",
    "            for i in range (len(fieldList)):\n",
    "                if Urow[i] == None:\n",
    "                    Urow[i] = 0\n",
    "                \n",
    "            cursor.updateRow(Urow)\n",
    "\n",
    "print (\"Processing complete\")\n",
    "print(\"\")\n",
    "\n",
    "ripcalc = \"!Forest!+!Shrub!\"\n",
    "arcpy.CalculateField_management(reachcopy,\"Riparian\", ripcalc)\n",
    "\n",
    "for field in arcpy.ListFields(reachcopy):\n",
    "    print (field.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Rename Fields and delete unecessary joins\n",
    " * create dictionary to store oldname/new name alias combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcaDict = {'rca_id': ('rca_id', 'Unique ID associated with each reach contributing area (rca)'),\n",
    "'HUC12': ('HUC12', '12th digit hydrologic unit code associated with rca'),\n",
    "'Name': ('HUC_name', 'name of 12th digit hydrologic unit code associated with rca'),\n",
    "'K_r': ('K_r', 'Presence/absence of Chinook salmon rearing habitat in rca'),\n",
    "'K_s': ('K_s', 'Presence/absence of Chinook salmon spawning habitat in rca'),\n",
    "'K_p': ('K_p', 'Presence/absence of Chinook salmon in rca'),\n",
    "'CH_r': ('CH_r', 'Presence/absence of chum salmon rearing habitat in rca'),\n",
    "'CH_s': ('CH_s', 'Presence/absence of chum salmon spawning habitat in rca'),\n",
    "'CH_p': ('CH_p', 'Presence/absence of chum salmon in rca'),\n",
    "'CO_r': ('CO_r', 'Presence/absence of coho salmon rearing habitat in rca'),\n",
    "'CO_s': ('CO_s', 'Presence/absence of coho salmon spawning habitat in rca'),\n",
    "'CO_p': ('CO_p', 'Presence/absence of coho salmon in rca'),\n",
    "'P_r': ('P_r', 'Presence/absence of pink salmon rearing habitat in rca'),\n",
    "'P_s': ('P_s', 'Presence/absence of pink salmon spawning habitat in rca'),\n",
    "'P_p': ('P_p', 'Presence/absence of pink salmon in rca'),\n",
    "'S_r': ('S_r', 'Presence/absence of sockeye salmon rearing habitat in rca'),\n",
    "'S_s': ('S_s', 'Presence/absence of sockeye salmon spawning habitat in rca'),\n",
    "'S_p': ('S_p', 'Presence/absence of sockeye salmon in rca'),\n",
    "'MIN': ('rca_elev_min', 'Minimum rca elevation '),\n",
    "'MAX': ('rca_elev_max', 'Maximum rca elevation '),\n",
    "'MEAN': ('rca_elev_mn', 'Mean rca elevation '),\n",
    "'Flow_Accumulation': ('flowacc', 'Number of upstream cells draining to rca pour point'),\n",
    "'Mean_Elev_Contributing_Area': ('ca_elev_mn', 'Mean elevation of upstream contributing area draining to rca pour point')}\n",
    "\n",
    "reachDict = {'reachid': ('reach_id', 'Unique ID associated with each confluence to confluence reach '), 'Forest': ('Forest', 'Percent forest cover in 30 meter buffer surrounding reach'),\n",
    "                         'Shrub': ('Shrub', 'Percent shrub cover in 30 meter buffer surrounding reach'),\n",
    "                         'Wetlands': ('Wetland', 'Percent wetland cover in 30 meter buffer surrounding reach')}\n",
    "tempDict = {}\n",
    "\n",
    "outletDict = {'rca_id': ('rca_id', 'Unique ID associated with each reach contributing area (rca)'),\n",
    "'HUC12': ('HUC12', '12th digit hydrologic unit code associated with rca'),\n",
    "'Name': ('HUC_name', 'name of 12th digit hydrologic unit code associated with rca'),\n",
    "'K_r': ('K_r', 'Presence/absence of Chinook salmon rearing habitat in rca'),\n",
    "'K_s': ('K_s', 'Presence/absence of Chinook salmon spawning habitat in rca'),\n",
    "'K_p': ('K_p', 'Presence/absence of Chinook salmon in rca'),\n",
    "'CH_r': ('CH_r', 'Presence/absence of chum salmon rearing habitat in rca'),\n",
    "'CH_s': ('CH_s', 'Presence/absence of chum salmon spawning habitat in rca'),\n",
    "'CH_p': ('CH_p', 'Presence/absence of chum salmon in rca'),\n",
    "'CO_r': ('CO_r', 'Presence/absence of coho salmon rearing habitat in rca'),\n",
    "'CO_s': ('CO_s', 'Presence/absence of coho salmon spawning habitat in rca'),\n",
    "'CO_p': ('CO_p', 'Presence/absence of coho salmon in rca'),\n",
    "'P_r': ('P_r', 'Presence/absence of pink salmon rearing habitat in rca'),\n",
    "'P_s': ('P_s', 'Presence/absence of pink salmon spawning habitat in rca'),\n",
    "'P_p': ('P_p', 'Presence/absence of pink salmon in rca'),\n",
    "'S_r': ('S_r', 'Presence/absence of sockeye salmon rearing habitat in rca'),\n",
    "'S_s': ('S_s', 'Presence/absence of sockeye salmon spawning habitat in rca'),\n",
    "'S_p': ('S_p', 'Presence/absence of sockeye salmon in rca'),\n",
    "'MIN': ('rca_elev_min', 'Minimum rca elevation '),\n",
    "'MAX': ('rca_elev_max', 'Maximum rca elevation '),\n",
    "'MEAN': ('rca_elev_mn', 'Mean rca elevation '),\n",
    "'Flow_Accumulation': ('flowacc', 'Number of upstream cells draining to rca pour point'),\n",
    "'Mean_Elev_Contributing_Area': ('ca_elev_mn', 'Mean elevation of upstream contributing area draining to rca pour point')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field renaming complete\n"
     ]
    }
   ],
   "source": [
    "for field in arcpy.ListFields(reachcopy):\n",
    "    keyval = field.name\n",
    "    if keyval in reachDict:\n",
    "        newname = reachDict[keyval][0]\n",
    "        newalias = reachDict[keyval][1]\n",
    "               \n",
    "        arcpy.AlterField_management(reachcopy, keyval, newname, newalias)\n",
    "\n",
    "for field in arcpy.ListFields(finalrca):       \n",
    "    keyval = field.name\n",
    "    if keyval in rcaDict:\n",
    "        newname = rcaDict[keyval][0]\n",
    "        newalias = rcaDict[keyval][1]\n",
    "\n",
    "        arcpy.AlterField_management(finalrca, keyval, newname, newalias)\n",
    "        \n",
    "for field in arcpy.ListFields(outcopy):\n",
    "    keyval = field.name\n",
    "    if keyval in outletDict:\n",
    "        newname = outletDict[keyval][0]\n",
    "        newalias = outletDict[keyval][1]\n",
    "           \n",
    "        arcpy.AlterField_management(outcopy, keyval, newname, newalias)\n",
    "        \n",
    "print (\"Field renaming complete\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete unecessary fields\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields cleaned\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rcadrops = [\"Join_Count\",\"TARGET_FID\",\"pointid\",\"grid_code\",\"rca_id_1\"]\n",
    "reachdrops =[\"Z_Min\",\"Z_Max\",\"Z_Mean\",\"SLength\"] \n",
    "\n",
    "for field in rcadrops:\n",
    "    arcpy.DeleteField_management(finalrca,field)\n",
    "\n",
    "for field in reachdrops:\n",
    "    arcpy.DeleteField_management(reachcopy,field)\n",
    "\n",
    "for field in rcadrops:\n",
    "    arcpy.DeleteField_management(outcopy,field)\n",
    "    \n",
    "print (\"Fields cleaned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check extent of Rasters against input flow direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow Direction Raster Information\n",
      "\n",
      "Raster name:      Kenai_StrBrn_d8flowdir.tif\n",
      "Projection:      NAD_1983_Alaska_Albers\n",
      "Compression Type: LZW\n",
      "Raster Format:    TIFF\n",
      "Height: 18755\n",
      "Width:  27650\n",
      "Cellsize:  5.000000\n",
      "Integer Raster: True\n",
      "Raster stats: min = 0.00 max = 1,974.00 mean = 521.31\n",
      "147477.63147271 1116160.30748062 285727.63147271 1209935.30748062 NaN NaN NaN NaN\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XMin</th>\n",
       "      <th>YMin</th>\n",
       "      <th>XMax</th>\n",
       "      <th>YMax</th>\n",
       "      <th>Cell Size</th>\n",
       "      <th>Spatial Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Kenai_StrBrn_src.tif</td>\n",
       "      <td>147477.63</td>\n",
       "      <td>1116160.31</td>\n",
       "      <td>285727.63</td>\n",
       "      <td>1209935.31</td>\n",
       "      <td>5.00</td>\n",
       "      <td>NAD_1983_Alaska_Albers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kenai_StrBrn_2Int.tif</td>\n",
       "      <td>147477.63</td>\n",
       "      <td>1116160.31</td>\n",
       "      <td>285727.63</td>\n",
       "      <td>1209935.31</td>\n",
       "      <td>5.00</td>\n",
       "      <td>NAD_1983_Alaska_Albers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kenai_glacial_weighted_flowacc.tif</td>\n",
       "      <td>147477.63</td>\n",
       "      <td>1116160.31</td>\n",
       "      <td>285727.63</td>\n",
       "      <td>1209935.31</td>\n",
       "      <td>5.00</td>\n",
       "      <td>NAD_1983_Alaska_Albers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kenai_elevation_weighted_flowacc.tif</td>\n",
       "      <td>147477.63</td>\n",
       "      <td>1116160.31</td>\n",
       "      <td>285727.63</td>\n",
       "      <td>1209935.31</td>\n",
       "      <td>5.00</td>\n",
       "      <td>NAD_1983_Alaska_Albers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kenai_flow_accumulation_07022020.tif</td>\n",
       "      <td>147477.63</td>\n",
       "      <td>1116160.31</td>\n",
       "      <td>285727.63</td>\n",
       "      <td>1209935.31</td>\n",
       "      <td>5.00</td>\n",
       "      <td>NAD_1983_Alaska_Albers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          XMin       YMin      XMax  \\\n",
       "raster                                                                \n",
       "Kenai_StrBrn_src.tif                 147477.63 1116160.31 285727.63   \n",
       "Kenai_StrBrn_2Int.tif                147477.63 1116160.31 285727.63   \n",
       "Kenai_glacial_weighted_flowacc.tif   147477.63 1116160.31 285727.63   \n",
       "Kenai_elevation_weighted_flowacc.tif 147477.63 1116160.31 285727.63   \n",
       "Kenai_flow_accumulation_07022020.tif 147477.63 1116160.31 285727.63   \n",
       "\n",
       "                                           YMax  Cell Size  \\\n",
       "raster                                                       \n",
       "Kenai_StrBrn_src.tif                 1209935.31       5.00   \n",
       "Kenai_StrBrn_2Int.tif                1209935.31       5.00   \n",
       "Kenai_glacial_weighted_flowacc.tif   1209935.31       5.00   \n",
       "Kenai_elevation_weighted_flowacc.tif 1209935.31       5.00   \n",
       "Kenai_flow_accumulation_07022020.tif 1209935.31       5.00   \n",
       "\n",
       "                                           Spatial Reference  \n",
       "raster                                                        \n",
       "Kenai_StrBrn_src.tif                  NAD_1983_Alaska_Albers  \n",
       "Kenai_StrBrn_2Int.tif                 NAD_1983_Alaska_Albers  \n",
       "Kenai_glacial_weighted_flowacc.tif    NAD_1983_Alaska_Albers  \n",
       "Kenai_elevation_weighted_flowacc.tif  NAD_1983_Alaska_Albers  \n",
       "Kenai_flow_accumulation_07022020.tif  NAD_1983_Alaska_Albers  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rasterlist = [streamrast, dem_copy, glimsw8flow, elevw8flow, flowacc]\n",
    "\n",
    "desc = arcpy.Describe(flowdirpath)\n",
    "ext1 =desc.extent # get extent of flow dir\n",
    "xm = ext1.XMin\n",
    "ym = ext1.YMin\n",
    "xM = ext1.XMax\n",
    "yM = ext1.YMax\n",
    "cS1 = desc.meanCellHeight\n",
    "spr = desc.SpatialReference.name\n",
    "\n",
    "print (\"Flow Direction Raster Information\")\n",
    "print(\"\")\n",
    "print(\"Raster name:      %s\" % desc.name)\n",
    "print(\"Projection:      %s\" % desc.SpatialReference.name)\n",
    "print(\"Compression Type: %s\" % desc.compressionType)\n",
    "print(\"Raster Format:    %s\" % desc.format)\n",
    "print(\"Height: %d\" % desc.height)\n",
    "print(\"Width:  %d\" % desc.width)\n",
    "print(\"Cellsize:  %f\" % desc.meanCellHeight)\n",
    "print(\"Integer Raster: %s\" % desc.isInteger)\n",
    "print(\"Raster stats: min = {:,.2f} max = {:,.2f} mean = {:,.2f}\".format(raster_min,raster_max,raster_mean))\n",
    "print (extent)\n",
    "print (\"\")\n",
    "\n",
    "import pandas as pd    \n",
    "data = []\n",
    "for r in rasterlist:\n",
    "    rdesc = arcpy.Describe(r)\n",
    "    ext = rdesc.extent\n",
    "    cS = rdesc.meanCellHeight\n",
    "    rn = rdesc.name\n",
    "    data.append([rn, ext.XMin, ext.YMin, ext.XMax, ext.YMax,cS,spr])\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data=data, columns=[\"raster\",'XMin','YMin','XMax','YMax', 'Cell Size','Spatial Reference'])\n",
    "df2 = df.set_index(['raster'])\n",
    "df2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Check that all extents, cellsizes, and projections match\n",
    " * Values should be true (match flowdir raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow Direction Raster Information\n",
      "\n",
      "Raster name:      Kenai_StrBrn_d8flowdir.tif\n",
      "Projection:      NAD_1983_Alaska_Albers\n",
      "Compression Type: LZW\n",
      "Raster Format:    TIFF\n",
      "Height: 18755\n",
      "Width:  27650\n",
      "Cellsize:  5.000000\n",
      "Integer Raster: True\n",
      "Raster stats: min = 0.00 max = 1,974.00 mean = 521.31\n",
      "147477.63147271 1116160.30748062 285727.63147271 1209935.30748062 NaN NaN NaN NaN\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XMin</th>\n",
       "      <th>YMin</th>\n",
       "      <th>XMax</th>\n",
       "      <th>YMax</th>\n",
       "      <th>Cell Size</th>\n",
       "      <th>Spatial Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Kenai_StrBrn_src.tif</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kenai_StrBrn_2Int.tif</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kenai_glacial_weighted_flowacc.tif</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kenai_elevation_weighted_flowacc.tif</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kenai_flow_accumulation_07022020.tif</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      XMin  YMin  XMax  YMax  Cell Size  \\\n",
       "raster                                                                    \n",
       "Kenai_StrBrn_src.tif                  True  True  True  True       True   \n",
       "Kenai_StrBrn_2Int.tif                 True  True  True  True       True   \n",
       "Kenai_glacial_weighted_flowacc.tif    True  True  True  True       True   \n",
       "Kenai_elevation_weighted_flowacc.tif  True  True  True  True       True   \n",
       "Kenai_flow_accumulation_07022020.tif  True  True  True  True       True   \n",
       "\n",
       "                                      Spatial Reference  \n",
       "raster                                                   \n",
       "Kenai_StrBrn_src.tif                               True  \n",
       "Kenai_StrBrn_2Int.tif                              True  \n",
       "Kenai_glacial_weighted_flowacc.tif                 True  \n",
       "Kenai_elevation_weighted_flowacc.tif               True  \n",
       "Kenai_flow_accumulation_07022020.tif               True  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rasterlist = [streamrast, dem_copy, glimsw8flow, elevw8flow, flowacc]\n",
    "\n",
    "desc = arcpy.Describe(flowdirpath)\n",
    "ext1 =desc.extent # get extent of flow dir\n",
    "xm = ext1.XMin\n",
    "ym = ext1.YMin\n",
    "xM = ext1.XMax\n",
    "yM = ext1.YMax\n",
    "cS1 = desc.meanCellHeight\n",
    "spr = desc.SpatialReference.name\n",
    "\n",
    "print (\"Flow Direction Raster Information\")\n",
    "print(\"\")\n",
    "print(\"Raster name:      %s\" % desc.name)\n",
    "print(\"Projection:      %s\" % desc.SpatialReference.name)\n",
    "print(\"Compression Type: %s\" % desc.compressionType)\n",
    "print(\"Raster Format:    %s\" % desc.format)\n",
    "print(\"Height: %d\" % desc.height)\n",
    "print(\"Width:  %d\" % desc.width)\n",
    "print(\"Cellsize:  %f\" % desc.meanCellHeight)\n",
    "print(\"Integer Raster: %s\" % desc.isInteger)\n",
    "print(\"Raster stats: min = {:,.2f} max = {:,.2f} mean = {:,.2f}\".format(raster_min,raster_max,raster_mean))\n",
    "print (extent)\n",
    "print (\"\")\n",
    "\n",
    "import pandas as pd    \n",
    "data = []\n",
    "for r in rasterlist:\n",
    "    rdesc = arcpy.Describe(r)\n",
    "    ext = rdesc.extent\n",
    "    cS = rdesc.meanCellHeight\n",
    "    rn = rdesc.name\n",
    "    data.append([rn, ext.XMin, ext.YMin, ext.XMax, ext.YMax,cS,spr])\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data=data, columns=[\"raster\",'XMin','YMin','XMax','YMax', 'Cell Size','Spatial Reference'])\n",
    "df2 = df.set_index(['raster'])\n",
    "df2.isin([xm,ym,xM,yM,cS1,spr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster name:      Kenai_StrBrn_src.tif\n",
      "Projection:      NAD_1983_Alaska_Albers\n",
      "Compression Type: LZW\n",
      "Raster Format:    TIFF\n",
      "Height: 18755\n",
      "Width:  27650\n",
      "Cellsize:  5.000000\n",
      "Integer Raster: True\n",
      "Raster stats: min = 0.00 max = 1.00 mean = 0.01\n",
      "147477.63147271 1116160.30748062 285727.63147271 1209935.30748062 NaN NaN NaN NaN\n",
      "\n",
      "Raster name:      Kenai_StrBrn_d8flowdir.tif\n",
      "Projection:      NAD_1983_Alaska_Albers\n",
      "Compression Type: LZW\n",
      "Raster Format:    TIFF\n",
      "Height: 18755\n",
      "Width:  27650\n",
      "Cellsize:  5.000000\n",
      "Integer Raster: True\n",
      "Raster stats: min = 1.00 max = 128.00 mean = 33.07\n",
      "147477.63147271 1116160.30748062 285727.63147271 1209935.30748062 NaN NaN NaN NaN\n",
      "\n",
      "Raster name:      Kenai_StrBrn_2Int.tif\n",
      "Projection:      NAD_1983_Alaska_Albers\n",
      "Compression Type: LZW\n",
      "Raster Format:    TIFF\n",
      "Height: 18755\n",
      "Width:  27650\n",
      "Cellsize:  5.000000\n",
      "Integer Raster: True\n",
      "Raster stats: min = 0.00 max = 1,974.00 mean = 521.31\n",
      "147477.63147271 1116160.30748062 285727.63147271 1209935.30748062 NaN NaN NaN NaN\n",
      "\n",
      "Raster name:      Kenai_glacial_weighted_flowacc.tif\n",
      "Projection:      NAD_1983_Alaska_Albers\n",
      "Compression Type: LZW\n",
      "Raster Format:    TIFF\n",
      "Height: 18755\n",
      "Width:  27650\n",
      "Cellsize:  5.000000\n",
      "Integer Raster: False\n",
      "Raster stats: min = 0.00 max = 21,924,732.00 mean = 3,351.35\n",
      "147477.63147271 1116160.30748062 285727.63147271 1209935.30748062 NaN NaN NaN NaN\n",
      "\n",
      "Raster name:      Kenai_elevation_weighted_flowacc.tif\n",
      "Projection:      NAD_1983_Alaska_Albers\n",
      "Compression Type: LZW\n",
      "Raster Format:    TIFF\n",
      "Height: 18755\n",
      "Width:  27650\n",
      "Cellsize:  5.000000\n",
      "Integer Raster: False\n",
      "Raster stats: min = 0.00 max = 111,034,826,752.00 mean = 13,686,566.95\n",
      "147477.63147271 1116160.30748062 285727.63147271 1209935.30748062 NaN NaN NaN NaN\n",
      "\n",
      "Raster name:      Kenai_flow_accumulation_07022020.tif\n",
      "Projection:      NAD_1983_Alaska_Albers\n",
      "Compression Type: LZW\n",
      "Raster Format:    TIFF\n",
      "Height: 18755\n",
      "Width:  27650\n",
      "Cellsize:  5.000000\n",
      "Integer Raster: False\n",
      "Raster stats: min = 0.00 max = 216,265,392.00 mean = 21,693.79\n",
      "147477.63147271 1116160.30748062 285727.63147271 1209935.30748062 NaN NaN NaN NaN\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rastlist = [streamrast, flowdirpath, dem_copy, glimsw8flow, elevw8flow, flowacc]\n",
    "extents = []\n",
    "\n",
    "for raster in rastlist:\n",
    "    desc = arcpy.Describe(raster)\n",
    "        \n",
    "    raster_min = arcpy.Raster(raster).minimum\n",
    "    raster_max = arcpy.Raster(raster).maximum\n",
    "    raster_mean = arcpy.Raster(raster).mean\n",
    "    extent = arcpy.Raster(raster).extent\n",
    "    extents.append(extent)\n",
    "    \n",
    "    print(\"Raster name:      %s\" % desc.name)\n",
    "    print(\"Projection:      %s\" % desc.SpatialReference.name)\n",
    "    print(\"Compression Type: %s\" % desc.compressionType)\n",
    "    print(\"Raster Format:    %s\" % desc.format)\n",
    "    print(\"Height: %d\" % desc.height)\n",
    "    print(\"Width:  %d\" % desc.width)\n",
    "    print(\"Cellsize:  %f\" % desc.meanCellHeight)\n",
    "    print(\"Integer Raster: %s\" % desc.isInteger)\n",
    "    print(\"Raster stats: min = {:,.2f} max = {:,.2f} mean = {:,.2f}\".format(raster_min,raster_max,raster_mean))\n",
    "    print (extent)\n",
    "    print (\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy to Network GDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying... kenai_rcas_temp_sites_attributed_07022020\n",
      "\n",
      "Copying... kenai_rcas_attributed_07022020\n",
      "\n",
      "Copying... Kenai_rca_outlets_attributed_07022020\n",
      "\n",
      "Copying kenai_rca_reaches\n",
      "\n",
      "All features copied\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = networkgdbfd\n",
    "\n",
    "arcpy.env.overwriteOutput = True\n",
    "arcpy.env.outputCoordinateSystem = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "spref = arcpy.SpatialReference(\"Alaska Albers Equal Area Conic\")\n",
    "\n",
    "exportfcs= []\n",
    "\n",
    "exportfcs = [tempfinal,finalrca,outcopy]\n",
    "\n",
    "for fc in exportfcs:\n",
    "    desc = arcpy.Describe(fc)\n",
    "    print(\"Copying...\", desc.name)\n",
    "    print(\"\")\n",
    "    \n",
    "    arcpy.CopyFeatures_management(fc,desc.name)\n",
    "\n",
    "reachdesc = arcpy.Describe(reachcopy)\n",
    "\n",
    "print (\"Copying\", reachdesc.name)\n",
    "print (\"\")\n",
    "\n",
    "reachcopyname = reachdesc.name + \"_attributed_\" + str(time_stamp)\n",
    "arcpy.CopyFeatures_management(reachcopy,reachcopyname)\n",
    "\n",
    "print (\"All features copied\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy Rasters\n",
    " * Tool will throw validation error but process completes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying ... C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenai_StrBrn_d8flowdir.tif\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ToolValidator' object has no attribute 'isLicensed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\dwmerrigan\\appdata\\local\\programs\\arcgis\\pro\\Resources\\ArcToolbox\\toolboxes\\Conversion Tools.tbx#RasterToGeodatabase_conversion.InitializeParameters.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ToolValidator' object has no attribute 'isLicensed'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ToolValidator' object has no attribute 'isLicensed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\dwmerrigan\\appdata\\local\\programs\\arcgis\\pro\\Resources\\ArcToolbox\\toolboxes\\Conversion Tools.tbx#RasterToGeodatabase_conversion.InitializeParameters.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ToolValidator' object has no attribute 'isLicensed'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying ... C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenai_glims_raster.tif\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ToolValidator' object has no attribute 'isLicensed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\dwmerrigan\\appdata\\local\\programs\\arcgis\\pro\\Resources\\ArcToolbox\\toolboxes\\Conversion Tools.tbx#RasterToGeodatabase_conversion.InitializeParameters.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ToolValidator' object has no attribute 'isLicensed'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ToolValidator' object has no attribute 'isLicensed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\dwmerrigan\\appdata\\local\\programs\\arcgis\\pro\\Resources\\ArcToolbox\\toolboxes\\Conversion Tools.tbx#RasterToGeodatabase_conversion.InitializeParameters.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ToolValidator' object has no attribute 'isLicensed'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying ... C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenai_flow_accumulation_07022020.tif\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ToolValidator' object has no attribute 'isLicensed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\dwmerrigan\\appdata\\local\\programs\\arcgis\\pro\\Resources\\ArcToolbox\\toolboxes\\Conversion Tools.tbx#RasterToGeodatabase_conversion.InitializeParameters.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ToolValidator' object has no attribute 'isLicensed'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ToolValidator' object has no attribute 'isLicensed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\dwmerrigan\\appdata\\local\\programs\\arcgis\\pro\\Resources\\ArcToolbox\\toolboxes\\Conversion Tools.tbx#RasterToGeodatabase_conversion.InitializeParameters.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ToolValidator' object has no attribute 'isLicensed'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying ... C:\\Users\\dwmerrigan\\Documents\\GitHub\\Watershed_Attributes\\Kenai\\Kenai_attributes\\Kenai_Attributes_07022020\\Kenai_StrBrn_2Int.tif\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ToolValidator' object has no attribute 'isLicensed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\dwmerrigan\\appdata\\local\\programs\\arcgis\\pro\\Resources\\ArcToolbox\\toolboxes\\Conversion Tools.tbx#RasterToGeodatabase_conversion.InitializeParameters.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ToolValidator' object has no attribute 'isLicensed'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ToolValidator' object has no attribute 'isLicensed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\dwmerrigan\\appdata\\local\\programs\\arcgis\\pro\\Resources\\ArcToolbox\\toolboxes\\Conversion Tools.tbx#RasterToGeodatabase_conversion.InitializeParameters.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ToolValidator' object has no attribute 'isLicensed'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raster copy complete\n"
     ]
    }
   ],
   "source": [
    "exportrasters = [flowdirpath, glimscon, flowacc, dem_copy]\n",
    "\n",
    "for r in exportrasters:\n",
    "       \n",
    "    print(\"Copying ...\", r)\n",
    "    print(\"\")\n",
    "    \n",
    "    arcpy.RasterToGeodatabase_conversion (r,networkgdb)\n",
    "\n",
    "print (\"Raster copy complete\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that exported rasters match original flow dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kenai_StrBrn_d8flowdir', 'Kenai_glims_raster', 'Kenai_flow_accumulation_07022020', 'Kenai_StrBrn_2Int', 'Kenai_StrBrn_d8flowdir_1', 'Kenai_glims_raster_1', 'Kenai_flow_accumulation_07022020_1', 'Kenai_StrBrn_2Int_1']\n",
      "\n",
      "Flow Direction Raster Information\n",
      "\n",
      "Raster name:      Kenai_StrBrn_d8flowdir.tif\n",
      "Projection:      NAD_1983_Alaska_Albers\n",
      "Compression Type: LZW\n",
      "Raster Format:    TIFF\n",
      "Height: 18755\n",
      "Width:  27650\n",
      "Cellsize:  5.000000\n",
      "Integer Raster: True\n",
      "Raster stats: min = 0.00 max = 216,265,392.00 mean = 21,693.79\n",
      "147477.63147271 1116160.30748062 285727.63147271 1209935.30748062 NaN NaN NaN NaN\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>XMin</th>\n",
       "      <th>YMin</th>\n",
       "      <th>XMax</th>\n",
       "      <th>YMax</th>\n",
       "      <th>Cell Size</th>\n",
       "      <th>Spatial Reference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raster</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Kenai_StrBrn_d8flowdir</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kenai_glims_raster</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kenai_flow_accumulation_07022020</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kenai_StrBrn_2Int</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kenai_StrBrn_d8flowdir_1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kenai_glims_raster_1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kenai_flow_accumulation_07022020_1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Kenai_StrBrn_2Int_1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    XMin  YMin  XMax  YMax  Cell Size  \\\n",
       "raster                                                                  \n",
       "Kenai_StrBrn_d8flowdir              True  True  True  True       True   \n",
       "Kenai_glims_raster                  True  True  True  True       True   \n",
       "Kenai_flow_accumulation_07022020    True  True  True  True       True   \n",
       "Kenai_StrBrn_2Int                   True  True  True  True       True   \n",
       "Kenai_StrBrn_d8flowdir_1            True  True  True  True       True   \n",
       "Kenai_glims_raster_1                True  True  True  True       True   \n",
       "Kenai_flow_accumulation_07022020_1  True  True  True  True       True   \n",
       "Kenai_StrBrn_2Int_1                 True  True  True  True       True   \n",
       "\n",
       "                                    Spatial Reference  \n",
       "raster                                                 \n",
       "Kenai_StrBrn_d8flowdir                           True  \n",
       "Kenai_glims_raster                               True  \n",
       "Kenai_flow_accumulation_07022020                 True  \n",
       "Kenai_StrBrn_2Int                                True  \n",
       "Kenai_StrBrn_d8flowdir_1                         True  \n",
       "Kenai_glims_raster_1                             True  \n",
       "Kenai_flow_accumulation_07022020_1               True  \n",
       "Kenai_StrBrn_2Int_1                              True  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arcpy.env.workspace = networkgdb\n",
    "rasterlist = []\n",
    "for raster in arcpy.ListRasters():\n",
    "    rasterlist.append(raster)\n",
    "\n",
    "print (rasterlist)\n",
    "print(\"\")\n",
    "    \n",
    "desc = arcpy.Describe(flowdirpath)\n",
    "ext1 =desc.extent # get extent of flow dir\n",
    "xm = ext1.XMin\n",
    "ym = ext1.YMin\n",
    "xM = ext1.XMax\n",
    "yM = ext1.YMax\n",
    "cS1 = desc.meanCellHeight\n",
    "spr = desc.SpatialReference.name\n",
    "\n",
    "print (\"Flow Direction Raster Information\")\n",
    "print(\"\")\n",
    "print(\"Raster name:      %s\" % desc.name)\n",
    "print(\"Projection:      %s\" % desc.SpatialReference.name)\n",
    "print(\"Compression Type: %s\" % desc.compressionType)\n",
    "print(\"Raster Format:    %s\" % desc.format)\n",
    "print(\"Height: %d\" % desc.height)\n",
    "print(\"Width:  %d\" % desc.width)\n",
    "print(\"Cellsize:  %f\" % desc.meanCellHeight)\n",
    "print(\"Integer Raster: %s\" % desc.isInteger)\n",
    "print(\"Raster stats: min = {:,.2f} max = {:,.2f} mean = {:,.2f}\".format(raster_min,raster_max,raster_mean))\n",
    "print (extent)\n",
    "print (\"\")\n",
    "\n",
    "import pandas as pd    \n",
    "data = []\n",
    "for r in rasterlist:\n",
    "    rdesc = arcpy.Describe(r)\n",
    "    ext = rdesc.extent\n",
    "    cS = rdesc.meanCellHeight\n",
    "    rn = rdesc.name\n",
    "    data.append([rn, ext.XMin, ext.YMin, ext.XMax, ext.YMax,cS,spr])\n",
    "\n",
    "df = pd.DataFrame(data=data, columns=[\"raster\",'XMin','YMin','XMax','YMax', 'Cell Size','Spatial Reference'])\n",
    "df2 = df.set_index(['raster'])\n",
    "df2.isin([xm,ym,xM,yM,cS1,spr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare output feature classes to inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kenai_rca_confluence has  1771  features\n",
      "kenai_waterbody_NHD has  1229  features\n",
      "kenai_streams_NHDP has  5738  features\n",
      "kenai_rcas_temp_sites_attributed_07022020 has  28  features\n",
      "kenai_rcas_attributed_07022020 has  3325  features\n",
      "Kenai_rca_outlets_attributed_07022020 has  3326  features\n",
      "kenai_rca_reaches_attributed_07022020 has  3544  features\n",
      "\n",
      "tempsites_Kenai has  28  features\n",
      "kenai_rcas has  3325  features\n",
      "kenai_rca_reaches has  3544  features\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = networkgdbfd\n",
    "\n",
    "ofclist = []\n",
    "ofclist = [tempsites,inrca,instreams]\n",
    "\n",
    "\n",
    "for fc in arcpy.ListFeatureClasses():\n",
    "    fcd = arcpy.Describe(fc)\n",
    "    count = arcpy.GetCount_management(fc)\n",
    "    print (fcd.name, \"has \", count, \" features\")\n",
    "    \n",
    "print(\"\")\n",
    "\n",
    "for ofc in ofclist:\n",
    "    ofcd = arcpy.Describe(ofc)\n",
    "    count = arcpy.GetCount_management(ofc)\n",
    "    print (ofcd.name, \"has \", count, \" features\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Identical outlet in Kenai\n",
    " * Not sure why this did not work in code above, the count even shows it deleted in this [section of code](#deleteid)\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kenai_rca_outlets_attributed_07022020 has  3326  features\n",
      "\n",
      "count after delete id 3325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "arcpy.env.workspace = networkgdbfd\n",
    "\n",
    "for fc in arcpy.ListFeatureClasses():\n",
    "    fcd = arcpy.Describe(fc)\n",
    "    if \"outlets\" in fcd.name:\n",
    "        \n",
    "        count = arcpy.GetCount_management(fc)\n",
    "        print (fcd.name, \"has \", count, \" features\")\n",
    "        print (\"\")\n",
    "        \n",
    "        outletfinalpath = os.path.join(fcd.path,fcd.name)\n",
    "        \n",
    "        arcpy.DeleteIdentical_management(fc, 'rca_id')\n",
    "        \n",
    "        count2 = arcpy.GetCount_management(fc)\n",
    "        \n",
    "        print (\"count after delete id\", count2)\n",
    "        print(\"\")\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'bottom'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jump to [top](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
